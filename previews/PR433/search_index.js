var documenterSearchIndex = {"docs":
[{"location":"functionindex/#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"functionindex/","page":"Index","title":"Index","text":"","category":"page"},{"location":"ffmpeg_reference/#FFmpeg-Low-Level-Reference","page":"FFmpeg Reference","title":"FFmpeg Low-Level Reference","text":"","category":"section"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"This page documents low-level FFmpeg constants, types, and functions that are available through VideoIO's libffmpeg module.","category":"page"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"Pages = [\"ffmpeg_reference.md\"]\nDepth = 2","category":"page"},{"location":"ffmpeg_reference/#Overview","page":"FFmpeg Reference","title":"Overview","text":"","category":"section"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"VideoIO provides Julia bindings to FFmpeg through the VideoIO.libffmpeg module. This module contains over 1,000 functions, constants, and types from FFmpeg's C libraries. While most users will use VideoIO's high-level API (see Reading Videos and Writing Videos), advanced users may need direct access to FFmpeg functionality.","category":"page"},{"location":"ffmpeg_reference/#FFmpeg-Subpackages","page":"FFmpeg Reference","title":"FFmpeg Subpackages","text":"","category":"section"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"Each FFmpeg library is exposed as a VideoIO subpackage:","category":"page"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"FFmpeg Library VideoIO Module Description\nlibavcodec AVCodecs Codec library - encoding/decoding\nlibavdevice AVDevice Device library - camera/screen capture\nlibavfilter AVFilters Filter library - video/audio processing\nlibavformat AVFormat Format library - muxing/demuxing\nlibavutil AVUtil Utility library - common functions\nlibswscale SWScale Scaling library - pixel format conversion\nlibswresample SWResample Resampling library - audio conversion","category":"page"},{"location":"ffmpeg_reference/#Usage-Example","page":"FFmpeg Reference","title":"Usage Example","text":"","category":"section"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"using VideoIO\n\n# Access low-level FFmpeg functionality\nimport VideoIO.libffmpeg\n\n# Check pixel format constant\npix_fmt = VideoIO.libffmpeg.AV_PIX_FMT_RGB24\n\n# Use AVRational for time base\ntime_base = VideoIO.libffmpeg.AVRational(1, 30)  # 1/30 second per frame\n\n# Convert to Julia Rational\njulia_rational = Rational(time_base.num, time_base.den)","category":"page"},{"location":"ffmpeg_reference/#Key-Concepts","page":"FFmpeg Reference","title":"Key Concepts","text":"","category":"section"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"Pixel Formats: FFmpeg supports numerous pixel formats via AV_PIX_FMT_* constants. Common ones include:","category":"page"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"AV_PIX_FMT_RGB24 - Packed RGB 8:8:8, 24bpp\nAV_PIX_FMT_GRAY8 - Grayscale, 8bpp\nAV_PIX_FMT_YUV420P - Planar YUV 4:2:0, 12bpp","category":"page"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"Media Types: Stream types are identified by AVMEDIA_TYPE_* constants:","category":"page"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"AVMEDIA_TYPE_VIDEO - Video stream\nAVMEDIA_TYPE_AUDIO - Audio stream\nAVMEDIA_TYPE_SUBTITLE - Subtitle stream","category":"page"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"Special Values:","category":"page"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"AV_NOPTS_VALUE - Indicates no presentation timestamp (0x8000000000000000)\nAVPROBE_SCORE_MAX - Maximum probe score (100)","category":"page"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"Codec Properties:","category":"page"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"AV_CODEC_PROP_FIELDS - Flag indicating field-based (interlaced) codec support","category":"page"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"For detailed information on FFmpeg 8 compatibility changes, see:","category":"page"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"FFmpeg ticksperframe deprecation\nAVCodecContext.time_base documentation","category":"page"},{"location":"ffmpeg_reference/#Complete-API-Reference","page":"FFmpeg Reference","title":"Complete API Reference","text":"","category":"section"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"The following sections provide auto-generated documentation for all exported items in VideoIO.libffmpeg.","category":"page"},{"location":"ffmpeg_reference/#Functions","page":"FFmpeg Reference","title":"Functions","text":"","category":"section"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_ac3_parse_header-Tuple{Any, UInt64, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_ac3_parse_header","text":"av_ac3_parse_header(buf, size::Csize_t, bitstream_id, frame_size)\n\nExtract the bitstream ID and the frame size from AC-3 data.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_add_index_entry-Tuple{Any, Int64, Int64, Integer, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_add_index_entry","text":"av_add_index_entry(st, pos::Int64, timestamp::Int64, size::Integer, distance::Integer, flags::Integer)\n\nAdd an index entry into a sorted list. Update the entry if the list already contains it.\n\nArguments\n\ntimestamp: timestamp in the time base of the given stream\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_add_q-Tuple{VideoIO.libffmpeg.AVRational, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_add_q","text":"av_add_q(b::AVRational, c::AVRational)\n\nAdd two rationals.\n\nArguments\n\nb: First rational\nc: Second rational\n\nReturns\n\nb+c\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_add_stable-Tuple{VideoIO.libffmpeg.AVRational, Int64, VideoIO.libffmpeg.AVRational, Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_add_stable","text":"av_add_stable(ts_tb::AVRational, ts::Int64, inc_tb::AVRational, inc::Int64)\n\nAdd a value to a timestamp.\n\nThis function guarantees that when the same value is repeatedly added that no accumulation of rounding errors occurs.\n\nArguments\n\nts:[in] Input timestamp\nts_tb:[in] Input timestamp time base\ninc:[in] Value to be added\ninc_tb:[in] Time base of inc\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_adler32_update-Tuple{UInt32, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_adler32_update","text":"av_adler32_update(adler::AVAdler, buf, len::Csize_t)\n\nCalculate the Adler32 checksum of a buffer.\n\nPassing the return value to a subsequent av_adler32_update() call allows the checksum of multiple buffers to be calculated as though they were concatenated.\n\nArguments\n\nadler: initial checksum value\nbuf: pointer to input buffer\nlen: size of input buffer\n\nReturns\n\nupdated checksum\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_adts_header_parse-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_adts_header_parse","text":"av_adts_header_parse(buf, samples, frames)\n\nExtract the number of samples and frames from AAC data.\n\nArguments\n\nbuf:[in] pointer to AAC data buffer\nsamples:[out] Pointer to where number of samples is written\nframes:[out] Pointer to where number of frames is written\n\nReturns\n\nReturns 0 on success, error code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_alloc","text":"av_aes_alloc()\n\nAllocate an AVAES context.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_crypt-Tuple{Any, Any, Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_crypt","text":"av_aes_crypt(a, dst, src, count::Integer, iv, decrypt::Integer)\n\nEncrypt or decrypt a buffer using a previously initialized context.\n\nArguments\n\na: The AVAES context\ndst: destination array, can be equal to src\nsrc: source array, can be equal to dst\ncount: number of 16 byte blocks\niv: initialization vector for CBC mode, if NULL then ECB will be used\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_ctr_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_ctr_alloc","text":"av_aes_ctr_alloc()\n\nAllocate an AVAESCTR context.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_ctr_crypt-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_ctr_crypt","text":"av_aes_ctr_crypt(a, dst, src, size::Integer)\n\nProcess a buffer using a previously initialized context.\n\nArguments\n\na: The AVAESCTR context\ndst: destination array, can be equal to src\nsrc: source array, can be equal to dst\nsize: the size of src and dst\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_ctr_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_ctr_free","text":"av_aes_ctr_free(a)\n\nRelease an AVAESCTR context.\n\nArguments\n\na: The AVAESCTR context\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_ctr_get_iv-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_ctr_get_iv","text":"av_aes_ctr_get_iv(a)\n\nGet the current iv\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_ctr_increment_iv-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_ctr_increment_iv","text":"av_aes_ctr_increment_iv(a)\n\nIncrement the top 64 bit of the iv (performed after each frame)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_ctr_init-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_ctr_init","text":"av_aes_ctr_init(a, key)\n\nInitialize an AVAESCTR context.\n\nArguments\n\na: The AVAESCTR context to initialize\nkey: encryption key, must have a length of AES_CTR_KEY_SIZE\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_ctr_set_full_iv-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_ctr_set_full_iv","text":"av_aes_ctr_set_full_iv(a, iv)\n\nForcefully change the \"full\" 16-byte iv, including the counter\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_ctr_set_iv-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_ctr_set_iv","text":"av_aes_ctr_set_iv(a, iv)\n\nForcefully change the 8-byte iv\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_ctr_set_random_iv-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_ctr_set_random_iv","text":"av_aes_ctr_set_random_iv(a)\n\nGenerate a random iv\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_aes_init-Tuple{Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_aes_init","text":"av_aes_init(a, key, key_bits::Integer, decrypt::Integer)\n\nInitialize an AVAES context.\n\nArguments\n\na: The AVAES context\nkey: Pointer to the key\nkey_bits: 128, 192 or 256\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_ambient_viewing_environment_alloc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_ambient_viewing_environment_alloc","text":"av_ambient_viewing_environment_alloc(size)\n\nAllocate an AVAmbientViewingEnvironment structure.\n\nReturns\n\nthe newly allocated struct or NULL on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_ambient_viewing_environment_create_side_data-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_ambient_viewing_environment_create_side_data","text":"av_ambient_viewing_environment_create_side_data(frame)\n\nAllocate and add an AVAmbientViewingEnvironment structure to an existing AVFrame as side data.\n\nReturns\n\nthe newly allocated struct, or NULL on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_append_packet-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_append_packet","text":"av_append_packet(s, pkt, size::Integer)\n\nRead data and append it to the current content of the AVPacket. If pkt->size is 0 this is identical to av_get_packet. Note that this uses av_grow_packet and thus involves a realloc which is inefficient. Thus this function should only be used when there is no reasonable way to know (an upper bound of) the final size.\n\nArguments\n\ns: associated IO context\npkt: packet\nsize: amount of data to read\n\nReturns\n\n0 (read size) if OK, AVERROR_xxx otherwise, previous data will not be lost even if an error occurs.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_append_path_component-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_append_path_component","text":"av_append_path_component(path, component)\n\nAppend path component to the existing path. Path separator '/' is placed between when needed. Resulting string have to be freed with av_free().\n\nArguments\n\npath: base path\ncomponent: component to be appended\n\nReturns\n\nnew path or NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_assert0_fpu-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_assert0_fpu","text":"av_assert0_fpu()\n\nAssert that floating point operations can be executed.\n\nThis will av_assert0() that the cpu is not in MMX state on X86\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_audio_fifo_alloc-Tuple{Int32, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_audio_fifo_alloc","text":"av_audio_fifo_alloc(sample_fmt::AVSampleFormat, channels::Integer, nb_samples::Integer)\n\nAllocate an AVAudioFifo.\n\nArguments\n\nsample_fmt: sample format\nchannels: number of channels\nnb_samples: initial allocation size, in samples\n\nReturns\n\nnewly allocated AVAudioFifo, or NULL on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_audio_fifo_drain-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_audio_fifo_drain","text":"av_audio_fifo_drain(af, nb_samples::Integer)\n\nDrain data from an AVAudioFifo.\n\nRemoves the data without reading it.\n\nArguments\n\naf: AVAudioFifo to drain\nnb_samples: number of samples to drain\n\nReturns\n\n0 if OK, or negative AVERROR code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_audio_fifo_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_audio_fifo_free","text":"av_audio_fifo_free(af)\n\nFree an AVAudioFifo.\n\nArguments\n\naf: AVAudioFifo to free\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_audio_fifo_peek-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_audio_fifo_peek","text":"av_audio_fifo_peek(af, data, nb_samples::Integer)\n\nPeek data from an AVAudioFifo.\n\nArguments\n\naf: AVAudioFifo to read from\ndata: audio data plane pointers\nnb_samples: number of samples to peek\n\nReturns\n\nnumber of samples actually peek, or negative AVERROR code on failure. The number of samples actually peek will not be greater than nb_samples, and will only be less than nb_samples if av_audio_fifo_size is less than nb_samples.\n\nSee also\n\nenum AVSampleFormat The documentation for AVSampleFormat describes the data layout.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_audio_fifo_peek_at-Tuple{Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_audio_fifo_peek_at","text":"av_audio_fifo_peek_at(af, data, nb_samples::Integer, offset::Integer)\n\nPeek data from an AVAudioFifo.\n\nArguments\n\naf: AVAudioFifo to read from\ndata: audio data plane pointers\nnb_samples: number of samples to peek\noffset: offset from current read position\n\nReturns\n\nnumber of samples actually peek, or negative AVERROR code on failure. The number of samples actually peek will not be greater than nb_samples, and will only be less than nb_samples if av_audio_fifo_size is less than nb_samples.\n\nSee also\n\nenum AVSampleFormat The documentation for AVSampleFormat describes the data layout.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_audio_fifo_read-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_audio_fifo_read","text":"av_audio_fifo_read(af, data, nb_samples::Integer)\n\nRead data from an AVAudioFifo.\n\nArguments\n\naf: AVAudioFifo to read from\ndata: audio data plane pointers\nnb_samples: number of samples to read\n\nReturns\n\nnumber of samples actually read, or negative AVERROR code on failure. The number of samples actually read will not be greater than nb_samples, and will only be less than nb_samples if av_audio_fifo_size is less than nb_samples.\n\nSee also\n\nenum AVSampleFormat The documentation for AVSampleFormat describes the data layout.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_audio_fifo_realloc-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_audio_fifo_realloc","text":"av_audio_fifo_realloc(af, nb_samples::Integer)\n\nReallocate an AVAudioFifo.\n\nArguments\n\naf: AVAudioFifo to reallocate\nnb_samples: new allocation size, in samples\n\nReturns\n\n0 if OK, or negative AVERROR code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_audio_fifo_reset-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_audio_fifo_reset","text":"av_audio_fifo_reset(af)\n\nReset the AVAudioFifo buffer.\n\nThis empties all data in the buffer.\n\nArguments\n\naf: AVAudioFifo to reset\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_audio_fifo_size-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_audio_fifo_size","text":"av_audio_fifo_size(af)\n\nGet the current number of samples in the AVAudioFifo available for reading.\n\nArguments\n\naf: the AVAudioFifo to query\n\nReturns\n\nnumber of samples available for reading\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_audio_fifo_space-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_audio_fifo_space","text":"av_audio_fifo_space(af)\n\nGet the current number of samples in the AVAudioFifo available for writing.\n\nArguments\n\naf: the AVAudioFifo to query\n\nReturns\n\nnumber of samples available for writing\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_audio_fifo_write-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_audio_fifo_write","text":"av_audio_fifo_write(af, data, nb_samples::Integer)\n\nWrite data to an AVAudioFifo.\n\nThe AVAudioFifo will be reallocated automatically if the available space is less than nb_samples.\n\nArguments\n\naf: AVAudioFifo to write to\ndata: audio data plane pointers\nnb_samples: number of samples to write\n\nReturns\n\nnumber of samples actually written, or negative AVERROR code on failure. If successful, the number of samples actually written will always be nb_samples.\n\nSee also\n\nenum AVSampleFormat The documentation for AVSampleFormat describes the data layout.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_base64_decode-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_base64_decode","text":"av_base64_decode(out, in, out_size::Integer)\n\nDecode a base64-encoded string.\n\nArguments\n\nout: buffer for decoded data\nin: null-terminated input string\nout_size: size in bytes of the out buffer, must be at least 3/4 of the length of in, that is AV_BASE64_DECODE_SIZE(strlen(in))\n\nReturns\n\nnumber of bytes written, or a negative value in case of invalid input\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_base64_encode-Tuple{Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_base64_encode","text":"av_base64_encode(out, out_size::Integer, in, in_size::Integer)\n\nEncode data to base64 and null-terminate.\n\nArguments\n\nout: buffer for encoded data\nout_size: size in bytes of the out buffer (including the null terminator), must be at least AV_BASE64_SIZE(in_size)\nin: input buffer containing the data to encode\nin_size: size in bytes of the in buffer\n\nReturns\n\nout or NULL in case of error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_basename-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_basename","text":"av_basename(path)\n\nThread safe basename.\n\nArguments\n\npath: the string to parse, on DOS both \\ and / are considered separators.\n\nReturns\n\npointer to the basename substring. If path does not contain a slash, the function returns a copy of path. If path is a NULL pointer or points to an empty string, a pointer to a string \".\" is returned.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bessel_i0-Tuple{Float64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bessel_i0","text":"av_bessel_i0(x::Cdouble)\n\n0th order modified bessel function of the first kind.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_blowfish_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_blowfish_alloc","text":"av_blowfish_alloc()\n\nAllocate an AVBlowfish context.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_blowfish_crypt-Tuple{Any, Any, Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_blowfish_crypt","text":"av_blowfish_crypt(ctx, dst, src, count::Integer, iv, decrypt::Integer)\n\nEncrypt or decrypt a buffer using a previously initialized context.\n\nArguments\n\nctx: an AVBlowfish context\ndst: destination array, can be equal to src\nsrc: source array, can be equal to dst\ncount: number of 8 byte blocks\niv: initialization vector for CBC mode, if NULL ECB will be used\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_blowfish_crypt_ecb-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_blowfish_crypt_ecb","text":"av_blowfish_crypt_ecb(ctx, xl, xr, decrypt::Integer)\n\nEncrypt or decrypt a buffer using a previously initialized context.\n\nArguments\n\nctx: an AVBlowfish context\nxl: left four bytes halves of input to be encrypted\nxr: right four bytes halves of input to be encrypted\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_blowfish_init-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_blowfish_init","text":"av_blowfish_init(ctx, key, key_len::Integer)\n\nInitialize an AVBlowfish context.\n\nArguments\n\nctx: an AVBlowfish context\nkey: a key\nkey_len: length of the key\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bmg_get-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bmg_get","text":"av_bmg_get(lfg, out)\n\nGet the next two numbers generated by a Box-Muller Gaussian generator using the random numbers issued by lfg.\n\nArguments\n\nlfg: pointer to the context structure\nout: array where the two generated numbers are placed\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bprint_append_data-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bprint_append_data","text":"av_bprint_append_data(buf, data, size::Integer)\n\nAppend data to a print buffer.\n\nArguments\n\nbuf: bprint buffer to use\ndata: pointer to data\nsize: size of data\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bprint_chars-Tuple{Any, Int8, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bprint_chars","text":"av_bprint_chars(buf, c::Cchar, n::Integer)\n\nAppend char c n times to a print buffer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bprint_clear-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bprint_clear","text":"av_bprint_clear(buf)\n\nReset the string to \"\" but keep internal allocated data.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bprint_escape-Tuple{Any, Any, Any, UInt32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bprint_escape","text":"av_bprint_escape(dstbuf, src, special_chars, mode::AVEscapeMode, flags::Integer)\n\nEscape the content in src and append it to dstbuf.\n\nArguments\n\ndstbuf: already inited destination bprint buffer\nsrc: string containing the text to escape\nspecial_chars: string containing the special characters which need to be escaped, can be NULL\nmode: escape mode to employ, see AV_ESCAPE_MODE_* macros. Any unknown value for mode will be considered equivalent to AV_ESCAPE_MODE_BACKSLASH, but this behaviour can change without notice.\nflags: flags which control how to escape, see AV_ESCAPE_FLAG_* macros\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bprint_finalize-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bprint_finalize","text":"av_bprint_finalize(buf, ret_str)\n\nFinalize a print buffer.\n\nThe print buffer can no longer be used afterwards, but the len and size fields are still valid.\n\n[out] ret_str if not NULL, used to return a permanent copy of the buffer contents, or NULL if memory allocation fails; if NULL, the buffer is discarded and freed\n\nReturns\n\n0 for success or error code (probably AVERROR(ENOMEM))\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bprint_get_buffer-Tuple{Any, Integer, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bprint_get_buffer","text":"av_bprint_get_buffer(buf, size::Integer, mem, actual_size)\n\nAllocate bytes in the buffer for external use.\n\nArguments\n\nbuf:[in] buffer structure\nsize:[in] required size\nmem:[out] pointer to the memory area\nactual_size:[out] size of the memory area after allocation; can be larger or smaller than size\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bprint_init-Tuple{Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bprint_init","text":"av_bprint_init(buf, size_init::Integer, size_max::Integer)\n\nInit a print buffer.\n\nArguments\n\nbuf: buffer to init\nsize_init: initial size (including the final 0)\nsize_max: maximum size; - 0 means do not write anything, just count the length - 1 is replaced by the maximum value for automatic storage any large value means that the internal buffer will be reallocated as needed up to that limit - -1 is converted to UINT_MAX, the largest limit possible. Check also AV\\_BPRINT\\_SIZE\\_* macros.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bprint_init_for_buffer-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bprint_init_for_buffer","text":"av_bprint_init_for_buffer(buf, buffer, size::Integer)\n\nInit a print buffer using a pre-existing buffer.\n\nThe buffer will not be reallocated. In case size equals zero, the AVBPrint will be initialized to use the internal buffer as if using AV_BPRINT_SIZE_COUNT_ONLY with av_bprint_init().\n\nArguments\n\nbuf: buffer structure to init\nbuffer: byte buffer to use for the string data\nsize: size of buffer\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bprint_is_complete-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bprint_is_complete","text":"av_bprint_is_complete(buf)\n\nTest if the print buffer is complete (not truncated).\n\nIt may have been truncated due to a memory allocation failure or the size_max limit (compare size and size_max if necessary).\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bprint_strftime-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bprint_strftime","text":"av_bprint_strftime(buf, fmt, tm_)\n\nAppend a formatted date and time to a print buffer.\n\nnote: Note\ndue to poor design of the standard strftime function, it may produce poor results if the format string expands to a very long text and the bprint buffer is near the limit stated by the size_max option.\n\nArguments\n\nbuf: bprint buffer to use\nfmt: date and time format string, see strftime()\ntm: broken-down time structure to translate\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_alloc-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_alloc","text":"av_bsf_alloc(filter, ctx)\n\nAllocate a context for a given bitstream filter. The caller must fill in the context parameters as described in the documentation and then call av_bsf_init() before sending any data to the filter.\n\nArguments\n\nfilter: the filter for which to allocate an instance.\nctx:[out] a pointer into which the pointer to the newly-allocated context will be written. It must be freed with av_bsf_free() after the filtering is done.\n\nReturns\n\n0 on success, a negative AVERROR code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_flush-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_flush","text":"av_bsf_flush(ctx)\n\nReset the internal bitstream filter state. Should be called e.g. when seeking.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_free","text":"av_bsf_free(ctx)\n\nFree a bitstream filter context and everything associated with it; write NULL into the supplied pointer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_get_by_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_get_by_name","text":"av_bsf_get_by_name(name)\n\nReturns\n\na bitstream filter with the specified name or NULL if no such bitstream filter exists.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_get_class-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_get_class","text":"av_bsf_get_class()\n\nGet the AVClass for AVBSFContext. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options.\n\nSee also\n\nav_opt_find().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_get_null_filter-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_get_null_filter","text":"av_bsf_get_null_filter(bsf)\n\nGet null/pass-through bitstream filter.\n\nArguments\n\nbsf:[out] Pointer to be set to new instance of pass-through bitstream filter\n\nReturns\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_init-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_init","text":"av_bsf_init(ctx)\n\nPrepare the filter for use, after all the parameters and options have been set.\n\nArguments\n\nctx: a AVBSFContext previously allocated with av_bsf_alloc()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_iterate-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_iterate","text":"av_bsf_iterate(opaque)\n\nIterate over all registered bitstream filters.\n\nArguments\n\nopaque: a pointer where libavcodec will store the iteration state. Must point to NULL to start the iteration.\n\nReturns\n\nthe next registered bitstream filter or NULL when the iteration is finished\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_list_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_list_alloc","text":"av_bsf_list_alloc()\n\nAllocate empty list of bitstream filters. The list must be later freed by av_bsf_list_free() or finalized by av_bsf_list_finalize().\n\nReturns\n\nPointer to AVBSFList on success, NULL in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_list_append-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_list_append","text":"av_bsf_list_append(lst, bsf)\n\nAppend bitstream filter to the list of bitstream filters.\n\nArguments\n\nlst: List to append to\nbsf: Filter context to be appended\n\nReturns\n\n=0 on success, negative AVERROR in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_list_append2-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_list_append2","text":"av_bsf_list_append2(lst, bsf_name, options)\n\nConstruct new bitstream filter context given it's name and options and append it to the list of bitstream filters.\n\nArguments\n\nlst: List to append to\nbsf_name: Name of the bitstream filter\noptions: Options for the bitstream filter, can be set to NULL\n\nReturns\n\n=0 on success, negative AVERROR in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_list_finalize-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_list_finalize","text":"av_bsf_list_finalize(lst, bsf)\n\nFinalize list of bitstream filters.\n\nThis function will transform AVBSFList to single AVBSFContext, so the whole chain of bitstream filters can be treated as single filter freshly allocated by av_bsf_alloc(). If the call is successful, AVBSFList structure is freed and lst will be set to NULL. In case of failure, caller is responsible for freeing the structure by av_bsf_list_free()\n\nArguments\n\nlst: Filter list structure to be transformed\nbsf:[out] Pointer to be set to newly created AVBSFContext structure representing the chain of bitstream filters\n\nReturns\n\n=0 on success, negative AVERROR in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_list_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_list_free","text":"av_bsf_list_free(lst)\n\nFree list of bitstream filters.\n\nArguments\n\nlst: Pointer to pointer returned by av_bsf_list_alloc()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_list_parse_str-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_list_parse_str","text":"av_bsf_list_parse_str(str, bsf)\n\nParse string describing list of bitstream filters and create single AVBSFContext describing the whole chain of bitstream filters. Resulting AVBSFContext can be treated as any other AVBSFContext freshly allocated by av_bsf_alloc().\n\nArguments\n\nstr: String describing chain of bitstream filters in format bsf1[=opt1=val1:opt2=val2][,bsf2]\nbsf:[out] Pointer to be set to newly created AVBSFContext structure representing the chain of bitstream filters\n\nReturns\n\n=0 on success, negative AVERROR in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_receive_packet-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_receive_packet","text":"av_bsf_receive_packet(ctx, pkt)\n\nRetrieve a filtered packet.\n\nnote: Note\none input packet may result in several output packets, so after sending a packet with av_bsf_send_packet(), this function needs to be called repeatedly until it stops returning 0. It is also possible for a filter to output fewer packets than were sent to it, so this function may return AVERROR(EAGAIN) immediately after a successful av_bsf_send_packet() call.\n\nArguments\n\nctx: an initialized AVBSFContext\npkt:[out] this struct will be filled with the contents of the filtered packet. It is owned by the caller and must be freed using av_packet_unref() when it is no longer needed. This parameter should be \"clean\" (i.e. freshly allocated with av_packet_alloc() or unreffed with av_packet_unref()) when this function is called. If this function returns successfully, the contents of pkt will be completely overwritten by the returned data. On failure, pkt is not touched.\n\nReturns\n\n0 on success. - AVERROR(EAGAIN) if more packets need to be sent to the filter (using av_bsf_send_packet()) to get more output. - AVERROR_EOF if there will be no further output from the filter. - Another negative AVERROR value if an error occurs.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_bsf_send_packet-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_bsf_send_packet","text":"av_bsf_send_packet(ctx, pkt)\n\nSubmit a packet for filtering.\n\nAfter sending each packet, the filter must be completely drained by calling av_bsf_receive_packet() repeatedly until it returns AVERROR(EAGAIN) or AVERROR_EOF.\n\nArguments\n\nctx: an initialized AVBSFContext\npkt: the packet to filter. The bitstream filter will take ownership of the packet and reset the contents of pkt. pkt is not touched if an error occurs. If pkt is empty (i.e. NULL, or pkt->data is NULL and pkt->side_data_elems zero), it signals the end of the stream (i.e. no more non-empty packets will be sent; sending more empty packets does nothing) and will cause the filter to output any packets it may have buffered internally.\n\nReturns\n\n0 on success. - AVERROR(EAGAIN) if packets need to be retrieved from the filter (using av_bsf_receive_packet()) before new input can be consumed. - Another negative AVERROR value if an error occurs.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_alloc-Tuple{UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_alloc","text":"av_buffer_alloc(size::Csize_t)\n\nAllocate an AVBuffer of the given size using av_malloc().\n\nReturns\n\nan AVBufferRef of given size or NULL when out of memory\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_allocz-Tuple{UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_allocz","text":"av_buffer_allocz(size::Csize_t)\n\nSame as av_buffer_alloc(), except the returned buffer will be initialized to zero.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_create-Tuple{Any, UInt64, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_create","text":"av_buffer_create(data, size::Csize_t, free, opaque, flags::Integer)\n\nCreate an AVBuffer from an existing array.\n\nIf this function is successful, data is owned by the AVBuffer. The caller may only access data through the returned AVBufferRef and references derived from it. If this function fails, data is left untouched.\n\nArguments\n\ndata: data array\nsize: size of data in bytes\nfree: a callback for freeing this buffer's data\nopaque: parameter to be got for processing or passed to free\nflags: a combination of AV_BUFFER_FLAG_*\n\nReturns\n\nan AVBufferRef referring to data on success, NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_default_free-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_default_free","text":"av_buffer_default_free(opaque, data)\n\nDefault free callback, which calls av_free() on the buffer data. This function is meant to be passed to av_buffer_create(), not called directly.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_get_opaque-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_get_opaque","text":"av_buffer_get_opaque(buf)\n\nReturns\n\nthe opaque parameter set by av_buffer_create.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_is_writable-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_is_writable","text":"av_buffer_is_writable(buf)\n\nReturns\n\n1 if the caller may write to the data referred to by buf (which is true if and only if buf is the only reference to the underlying AVBuffer). Return 0 otherwise. A positive answer is valid until av_buffer_ref() is called on buf.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_make_writable-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_make_writable","text":"av_buffer_make_writable(buf)\n\nCreate a writable reference from a given buffer reference, avoiding data copy if possible.\n\nArguments\n\nbuf: buffer reference to make writable. On success, buf is either left untouched, or it is unreferenced and a new writable AVBufferRef is written in its place. On failure, buf is left untouched.\n\nReturns\n\n0 on success, a negative AVERROR on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_pool_buffer_get_opaque-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_pool_buffer_get_opaque","text":"av_buffer_pool_buffer_get_opaque(ref)\n\nQuery the original opaque parameter of an allocated buffer in the pool.\n\nnote: Note\nthe opaque parameter of ref is used by the buffer pool implementation, therefore you have to use this function to access the original opaque parameter of an allocated buffer.\n\nArguments\n\nref: a buffer reference to a buffer returned by av_buffer_pool_get.\n\nReturns\n\nthe opaque parameter set by the buffer allocator function of the buffer pool.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_pool_get-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_pool_get","text":"av_buffer_pool_get(pool)\n\nAllocate a new AVBuffer, reusing an old buffer from the pool when available. This function may be called simultaneously from multiple threads.\n\nReturns\n\na reference to the new buffer on success, NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_pool_init-Tuple{UInt64, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_pool_init","text":"av_buffer_pool_init(size::Csize_t, alloc)\n\nAllocate and initialize a buffer pool.\n\nArguments\n\nsize: size of each buffer in this pool\nalloc: a function that will be used to allocate new buffers when the pool is empty. May be NULL, then the default allocator will be used (av_buffer_alloc()).\n\nReturns\n\nnewly created buffer pool on success, NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_pool_init2-Tuple{UInt64, Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_pool_init2","text":"av_buffer_pool_init2(size::Csize_t, opaque, alloc, pool_free)\n\nAllocate and initialize a buffer pool with a more complex allocator.\n\nArguments\n\nsize: size of each buffer in this pool\nopaque: arbitrary user data used by the allocator\nalloc: a function that will be used to allocate new buffers when the pool is empty. May be NULL, then the default allocator will be used (av_buffer_alloc()).\npool_free: a function that will be called immediately before the pool is freed. I.e. after av_buffer_pool_uninit() is called by the caller and all the frames are returned to the pool and freed. It is intended to uninitialize the user opaque data. May be NULL.\n\nReturns\n\nnewly created buffer pool on success, NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_pool_uninit-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_pool_uninit","text":"av_buffer_pool_uninit(pool)\n\nMark the pool as being available for freeing. It will actually be freed only once all the allocated buffers associated with the pool are released. Thus it is safe to call this function while some of the allocated buffers are still in use.\n\nArguments\n\npool: pointer to the pool to be freed. It will be set to NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_realloc-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_realloc","text":"av_buffer_realloc(buf, size::Csize_t)\n\nReallocate a given buffer.\n\nnote: Note\nthe buffer is actually reallocated with av_realloc() only if it was initially allocated through av_buffer_realloc(NULL) and there is only one reference to it (i.e. the one passed to this function). In all other cases a new buffer is allocated and the data is copied.\n\nArguments\n\nbuf: a buffer reference to reallocate. On success, buf will be unreferenced and a new reference with the required size will be written in its place. On failure buf will be left untouched. *buf may be NULL, then a new buffer is allocated.\nsize: required new buffer size.\n\nReturns\n\n0 on success, a negative AVERROR on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_ref-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_ref","text":"av_buffer_ref(buf)\n\nCreate a new reference to an AVBuffer.\n\nReturns\n\na new AVBufferRef referring to the same AVBuffer as buf or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_replace-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_replace","text":"av_buffer_replace(dst, src)\n\nEnsure dst refers to the same data as src.\n\nWhen *dst is already equivalent to src, do nothing. Otherwise unreference dst and replace it with a new reference to src.\n\nArguments\n\ndst: Pointer to either a valid buffer reference or NULL. On success, this will point to a buffer reference equivalent to src. On failure, dst will be left untouched.\nsrc: A buffer reference to replace dst with. May be NULL, then this function is equivalent to av_buffer_unref(dst).\n\nReturns\n\n0 on success AVERROR(ENOMEM) on memory allocation failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffer_unref-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffer_unref","text":"av_buffer_unref(buf)\n\nFree a given reference and automatically free the buffer if there are no more references to it.\n\nArguments\n\nbuf: the reference to be freed. The pointer is set to NULL on return.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersink_get_frame-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersink_get_frame","text":"av_buffersink_get_frame(ctx, frame)\n\nGet a frame with filtered data from sink and put it in frame.\n\nArguments\n\nctx: pointer to a context of a buffersink or abuffersink AVFilter.\nframe: pointer to an allocated frame that will be filled with data. The data must be freed using av_frame_unref() / av_frame_free()\n\nReturns\n\n= 0 if a frame was successfully returned. - AVERROR(EAGAIN) if no frames are available at this point; more input frames must be added to the filtergraph to get more output. - AVERROR_EOF if there will be no more output frames on this sink. - A different negative AVERROR code in other failure cases.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersink_get_frame_flags-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersink_get_frame_flags","text":"av_buffersink_get_frame_flags(ctx, frame, flags::Integer)\n\nGet a frame with filtered data from sink and put it in frame.\n\nArguments\n\nctx: pointer to a buffersink or abuffersink filter context.\nframe: pointer to an allocated frame that will be filled with data. The data must be freed using av_frame_unref() / av_frame_free()\nflags: a combination of AV_BUFFERSINK_FLAG_* flags\n\nReturns\n\n= 0 in for success, a negative AVERROR code for failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersink_get_samples-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersink_get_samples","text":"av_buffersink_get_samples(ctx, frame, nb_samples::Integer)\n\nSame as av_buffersink_get_frame(), but with the ability to specify the number of samples read. This function is less efficient than av_buffersink_get_frame(), because it copies the data around.\n\nwarning: Warning\ndo not mix this function with av_buffersink_get_frame(). Use only one or the other with a single sink, not both.\n\nArguments\n\nctx: pointer to a context of the abuffersink AVFilter.\nframe: pointer to an allocated frame that will be filled with data. The data must be freed using av_frame_unref() / av_frame_free() frame will contain exactly nb_samples audio samples, except at the end of stream, when it can contain less than nb_samples.\n\nReturns\n\nThe return codes have the same meaning as for av_buffersink_get_frame().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersink_get_type-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersink_get_type","text":"av_buffersink_get_type(ctx)\n\nlavfi_buffersink_accessors Buffer sink accessors\n\nGet the properties of the stream @{\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersink_set_frame_size-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersink_set_frame_size","text":"av_buffersink_set_frame_size(ctx, frame_size::Integer)\n\nSet the frame size for an audio buffer sink.\n\nAll calls to av_buffersink_get_buffer_ref will return a buffer with exactly the specified number of samples, or AVERROR(EAGAIN) if there is not enough. The last buffer at EOF will be padded with 0.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersrc_add_frame-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersrc_add_frame","text":"av_buffersrc_add_frame(ctx, frame)\n\nAdd a frame to the buffer source.\n\nnote: Note\nthe difference between this function and av_buffersrc_write_frame() is that av_buffersrc_write_frame() creates a new reference to the input frame, while this function takes ownership of the reference passed to it.\n\nThis function is equivalent to av_buffersrc_add_frame_flags() without the AV_BUFFERSRC_FLAG_KEEP_REF flag.\n\nArguments\n\nctx: an instance of the buffersrc filter\nframe: frame to be added. If the frame is reference counted, this function will take ownership of the reference(s) and reset the frame. Otherwise the frame data will be copied. If this function returns an error, the input frame is not touched.\n\nReturns\n\n0 on success, a negative AVERROR on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersrc_add_frame_flags-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersrc_add_frame_flags","text":"av_buffersrc_add_frame_flags(buffer_src, frame, flags::Integer)\n\nAdd a frame to the buffer source.\n\nBy default, if the frame is reference-counted, this function will take ownership of the reference(s) and reset the frame. This can be controlled using the flags.\n\nIf this function returns an error, the input frame is not touched.\n\nArguments\n\nbuffer_src: pointer to a buffer source context\nframe: a frame, or NULL to mark EOF\nflags: a combination of AV_BUFFERSRC_FLAG_*\n\nReturns\n\n= 0 in case of success, a negative AVERROR code in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersrc_close-Tuple{Any, Int64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersrc_close","text":"av_buffersrc_close(ctx, pts::Int64, flags::Integer)\n\nClose the buffer source after EOF.\n\nThis is similar to passing NULL to av_buffersrc_add_frame_flags() except it takes the timestamp of the EOF, i.e. the timestamp of the end of the last frame.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersrc_get_nb_failed_requests-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersrc_get_nb_failed_requests","text":"av_buffersrc_get_nb_failed_requests(buffer_src)\n\nGet the number of failed requests.\n\nA failed request is when the request_frame method is called while no frame is present in the buffer. The number is reset when a frame is added.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersrc_parameters_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersrc_parameters_alloc","text":"av_buffersrc_parameters_alloc()\n\nAllocate a new AVBufferSrcParameters instance. It should be freed by the caller with av_free().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersrc_parameters_set-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersrc_parameters_set","text":"av_buffersrc_parameters_set(ctx, param)\n\nInitialize the buffersrc or abuffersrc filter with the provided parameters. This function may be called multiple times, the later calls override the previous ones. Some of the parameters may also be set through AVOptions, then whatever method is used last takes precedence.\n\nArguments\n\nctx: an instance of the buffersrc or abuffersrc filter\nparam: the stream parameters. The frames later passed to this filter must conform to those parameters. All the allocated fields in param remain owned by the caller, libavfilter will make internal copies or references when necessary.\n\nReturns\n\n0 on success, a negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_buffersrc_write_frame-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_buffersrc_write_frame","text":"av_buffersrc_write_frame(ctx, frame)\n\nAdd a frame to the buffer source.\n\nThis function is equivalent to av_buffersrc_add_frame_flags() with the AV_BUFFERSRC_FLAG_KEEP_REF flag.\n\nArguments\n\nctx: an instance of the buffersrc filter\nframe: frame to be added. If the frame is reference counted, this function will make a new reference to it. Otherwise the frame data will be copied.\n\nReturns\n\n0 on success, a negative AVERROR on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_calloc-Tuple{UInt64, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_calloc","text":"av_calloc(nmemb::Csize_t, size::Csize_t)\n\nAllocate a memory block for an array with av_mallocz().\n\nThe allocated memory will have size size * nmemb bytes.\n\nArguments\n\nnmemb: Number of elements\nsize: Size of the single element\n\nReturns\n\nPointer to the allocated block, or NULL if the block cannot be allocated\n\nSee also\n\nav_mallocz(), av_malloc_array()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_camellia_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_camellia_alloc","text":"av_camellia_alloc()\n\nAllocate an AVCAMELLIA context To free the struct: av_free(ptr)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_camellia_crypt-Tuple{Any, Any, Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_camellia_crypt","text":"av_camellia_crypt(ctx, dst, src, count::Integer, iv, decrypt::Integer)\n\nEncrypt or decrypt a buffer using a previously initialized context\n\nArguments\n\nctx: an AVCAMELLIA context\ndst: destination array, can be equal to src\nsrc: source array, can be equal to dst\ncount: number of 16 byte blocks\niv: initialization vector for CBC mode, NULL for ECB mode\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_camellia_init-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_camellia_init","text":"av_camellia_init(ctx, key, key_bits::Integer)\n\nInitialize an AVCAMELLIA context.\n\nArguments\n\nctx: an AVCAMELLIA context\nkey: a key of 16, 24, 32 bytes used for encryption/decryption\nkey_bits: number of keybits: possible are 128, 192, 256\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_cast5_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_cast5_alloc","text":"av_cast5_alloc()\n\nAllocate an AVCAST5 context To free the struct: av_free(ptr)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_cast5_crypt-Tuple{Any, Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_cast5_crypt","text":"av_cast5_crypt(ctx, dst, src, count::Integer, decrypt::Integer)\n\nEncrypt or decrypt a buffer using a previously initialized context, ECB mode only\n\nArguments\n\nctx: an AVCAST5 context\ndst: destination array, can be equal to src\nsrc: source array, can be equal to dst\ncount: number of 8 byte blocks\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_cast5_crypt2-Tuple{Any, Any, Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_cast5_crypt2","text":"av_cast5_crypt2(ctx, dst, src, count::Integer, iv, decrypt::Integer)\n\nEncrypt or decrypt a buffer using a previously initialized context\n\nArguments\n\nctx: an AVCAST5 context\ndst: destination array, can be equal to src\nsrc: source array, can be equal to dst\ncount: number of 8 byte blocks\niv: initialization vector for CBC mode, NULL for ECB mode\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_cast5_init-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_cast5_init","text":"av_cast5_init(ctx, key, key_bits::Integer)\n\nInitialize an AVCAST5 context.\n\nArguments\n\nctx: an AVCAST5 context\nkey: a key of 5,6,...16 bytes used for encryption/decryption\nkey_bits: number of keybits: possible are 40,48,...,128\n\nReturns\n\n0 on success, less than 0 on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_ceil_log2_c-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_ceil_log2_c","text":"av_ceil_log2_c(x::Integer)\n\nCompute ceil(log2(x)).\n\nArguments\n\nx: value used to compute ceil(log2(x))\n\nReturns\n\ncomputed ceiling of log2(x)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_description-Tuple{Any, UInt64, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_description","text":"av_channel_description(buf, buf_size::Csize_t, channel::AVChannel)\n\nGet a human readable string describing a given channel.\n\nArguments\n\nbuf: pre-allocated buffer where to put the generated string\nbuf_size: size in bytes of the buffer.\nchannel: the AVChannel whose description to get\n\nReturns\n\namount of bytes needed to hold the output string, or a negative AVERROR on failure. If the returned value is bigger than buf_size, then the string was truncated.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_description_bprint-Tuple{Any, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_description_bprint","text":"av_channel_description_bprint(bp, channel_id::AVChannel)\n\nbprint variant of av_channel_description().\n\nnote: Note\nthe string will be appended to the bprint buffer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_from_string-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_from_string","text":"av_channel_from_string(name)\n\nThis is the inverse function of avchannelname().\n\nReturns\n\nthe channel with the given name AV_CHAN_NONE when name does not identify a known channel\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_ambisonic_order-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_ambisonic_order","text":"av_channel_layout_ambisonic_order(channel_layout)\n\nReturn the order if the layout is n-th order standard-order ambisonic. The presence of optional extra non-diegetic channels at the end is not taken into account.\n\nArguments\n\nchannel_layout: input channel layout\n\nReturns\n\nthe order of the layout, a negative error code otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_channel_from_index-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_channel_from_index","text":"av_channel_layout_channel_from_index(channel_layout, idx::Integer)\n\nGet the channel with the given index in a channel layout.\n\nArguments\n\nchannel_layout: input channel layout\nidx: index of the channel\n\nReturns\n\nchannel with the index idx in channel_layout on success or AV_CHAN_NONE on failure (if idx is not valid or the channel order is unspecified)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_channel_from_string-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_channel_from_string","text":"av_channel_layout_channel_from_string(channel_layout, name)\n\nGet a channel described by the given string.\n\nThis function accepts channel names in the same format as avchannelfrom_string().\n\nArguments\n\nchannel_layout: input channel layout\nname: string describing the channel to obtain\n\nReturns\n\na channel described by the given string in channel_layout on success or AV_CHAN_NONE on failure (if the string is not valid or the channel order is unspecified)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_check-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_check","text":"av_channel_layout_check(channel_layout)\n\nCheck whether a channel layout is valid, i.e. can possibly describe audio data.\n\nArguments\n\nchannel_layout: input channel layout\n\nReturns\n\n1 if channel_layout is valid, 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_compare-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_compare","text":"av_channel_layout_compare(chl, chl1)\n\nCheck whether two channel layouts are semantically the same, i.e. the same channels are present on the same positions in both.\n\nIf one of the channel layouts is AV_CHANNEL_ORDER_UNSPEC, while the other is not, they are considered to be unequal. If both are AV_CHANNEL_ORDER_UNSPEC, they are considered equal iff the channel counts are the same in both.\n\nArguments\n\nchl: input channel layout\nchl1: input channel layout\n\nReturns\n\n0 if chl and chl1 are equal, 1 if they are not equal. A negative AVERROR code if one or both are invalid.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_copy-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_copy","text":"av_channel_layout_copy(dst, src)\n\nMake a copy of a channel layout. This differs from just assigning src to dst in that it allocates and copies the map for AV_CHANNEL_ORDER_CUSTOM.\n\nnote: Note\nthe destination channel_layout will be always uninitialized before copy.\n\nArguments\n\ndst: destination channel layout\nsrc: source channel layout\n\nReturns\n\n0 on success, a negative AVERROR on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_custom_init-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_custom_init","text":"av_channel_layout_custom_init(channel_layout, nb_channels::Integer)\n\nInitialize a custom channel layout with the specified number of channels. The channel map will be allocated and the designation of all channels will be set to AV_CHAN_UNKNOWN.\n\nThis is only a convenience helper function, a custom channel layout can also be constructed without using this.\n\nArguments\n\nchannel_layout: the layout structure to be initialized\nnb_channels: the number of channels\n\nReturns\n\n0 on success AVERROR(EINVAL) if the number of channels <= 0 AVERROR(ENOMEM) if the channel map could not be allocated\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_default-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_default","text":"av_channel_layout_default(ch_layout, nb_channels::Integer)\n\nGet the default channel layout for a given number of channels.\n\nArguments\n\nch_layout: the layout structure to be initialized\nnb_channels: number of channels\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_describe-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_describe","text":"av_channel_layout_describe(channel_layout, buf, buf_size::Csize_t)\n\nGet a human-readable string describing the channel layout properties. The string will be in the same format that is accepted by avchannellayoutfromstring(), allowing to rebuild the same channel layout, except for opaque pointers.\n\nArguments\n\nchannel_layout: channel layout to be described\nbuf: pre-allocated buffer where to put the generated string\nbuf_size: size in bytes of the buffer.\n\nReturns\n\namount of bytes needed to hold the output string, or a negative AVERROR on failure. If the returned value is bigger than buf_size, then the string was truncated.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_describe_bprint-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_describe_bprint","text":"av_channel_layout_describe_bprint(channel_layout, bp)\n\nbprint variant of av_channel_layout_describe().\n\nnote: Note\nthe string will be appended to the bprint buffer.\n\nReturns\n\n0 on success, or a negative AVERROR value on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_from_mask-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_from_mask","text":"av_channel_layout_from_mask(channel_layout, mask::UInt64)\n\nInitialize a native channel layout from a bitmask indicating which channels are present.\n\nArguments\n\nchannel_layout: the layout structure to be initialized\nmask: bitmask describing the channel layout\n\nReturns\n\n0 on success AVERROR(EINVAL) for invalid mask values\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_from_string-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_from_string","text":"av_channel_layout_from_string(channel_layout, str)\n\nInitialize a channel layout from a given string description. The input string can be represented by: - the formal channel layout name (returned by av_channel_layout_describe()) - single or multiple channel names (returned by av_channel_name(), eg. \"FL\", or concatenated with \"+\", each optionally containing a custom name after a \"@\", eg. \"FL@Left+FR@Right+LFE\") - a decimal or hexadecimal value of a native channel layout (eg. \"4\" or \"0x4\") - the number of channels with default layout (eg. \"4c\") - the number of unordered channels (eg. \"4C\" or \"4 channels\") - the ambisonic order followed by optional non-diegetic channels (eg. \"ambisonic 2+stereo\") On error, the channel layout will remain uninitialized, but not necessarily untouched.\n\nArguments\n\nchannel_layout: uninitialized channel layout for the result\nstr: string describing the channel layout\n\nReturns\n\n0 on success parsing the channel layout AVERROR(EINVAL) if an invalid channel layout string was provided AVERROR(ENOMEM) if there was not enough memory\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_index_from_channel-Tuple{Any, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_index_from_channel","text":"av_channel_layout_index_from_channel(channel_layout, channel::AVChannel)\n\nGet the index of a given channel in a channel layout. In case multiple channels are found, only the first match will be returned.\n\nArguments\n\nchannel_layout: input channel layout\nchannel: the channel whose index to obtain\n\nReturns\n\nindex of channel in channel_layout on success or a negative number if channel is not present in channel_layout.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_index_from_string-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_index_from_string","text":"av_channel_layout_index_from_string(channel_layout, name)\n\nGet the index in a channel layout of a channel described by the given string. In case multiple channels are found, only the first match will be returned.\n\nThis function accepts channel names in the same format as avchannelfrom_string().\n\nArguments\n\nchannel_layout: input channel layout\nname: string describing the channel whose index to obtain\n\nReturns\n\na channel index described by the given string, or a negative AVERROR value.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_retype-Tuple{Any, UInt32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_retype","text":"av_channel_layout_retype(channel_layout, order::AVChannelOrder, flags::Integer)\n\nChange the AVChannelOrder of a channel layout.\n\nChange of AVChannelOrder can be either lossless or lossy. In case of a lossless conversion all the channel designations and the associated channel names (if any) are kept. On a lossy conversion the channel names and channel designations might be lost depending on the capabilities of the desired AVChannelOrder. Note that some conversions are simply not possible in which case this function returns AVERROR(ENOSYS).\n\nThe following conversions are supported:\n\nAny -> Custom : Always possible, always lossless. Any -> Unspecified: Always possible, lossless if channel designations are all unknown and channel names are not used, lossy otherwise. Custom -> Ambisonic : Possible if it contains ambisonic channels with optional non-diegetic channels in the end. Lossy if the channels have custom names, lossless otherwise. Custom -> Native : Possible if it contains native channels in native order. Lossy if the channels have custom names, lossless otherwise.\n\nOn error this function keeps the original channel layout untouched.\n\nArguments\n\nchannel_layout: channel layout which will be changed\norder: the desired channel layout order\nflags: a combination of AV_CHANNEL_LAYOUT_RETYPE_FLAG_* constants\n\nReturns\n\n0 if the conversion was successful and lossless or if the channel layout was already in the desired order >0 if the conversion was successful but lossy AVERROR(ENOSYS) if the conversion was not possible (or would be lossy and AV_CHANNEL_LAYOUT_RETYPE_FLAG_LOSSLESS was specified) AVERROR(EINVAL), AVERROR(ENOMEM) on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_standard-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_standard","text":"av_channel_layout_standard(opaque)\n\nIterate over all standard channel layouts.\n\nArguments\n\nopaque: a pointer where libavutil will store the iteration state. Must point to NULL to start the iteration.\n\nReturns\n\nthe standard channel layout or NULL when the iteration is finished\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_subset-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_subset","text":"av_channel_layout_subset(channel_layout, mask::UInt64)\n\nFind out what channels from a given set are present in a channel layout, without regard for their positions.\n\nArguments\n\nchannel_layout: input channel layout\nmask: a combination of AV_CH_* representing a set of channels\n\nReturns\n\na bitfield representing all the channels from mask that are present in channel_layout\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_layout_uninit-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_layout_uninit","text":"av_channel_layout_uninit(channel_layout)\n\nFree any allocated data in the channel layout and reset the channel count to 0.\n\nArguments\n\nchannel_layout: the layout structure to be uninitialized\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_name-Tuple{Any, UInt64, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_name","text":"av_channel_name(buf, buf_size::Csize_t, channel::AVChannel)\n\nGet a human readable string in an abbreviated form describing a given channel. This is the inverse function of avchannelfrom_string().\n\nArguments\n\nbuf: pre-allocated buffer where to put the generated string\nbuf_size: size in bytes of the buffer.\nchannel: the AVChannel whose name to get\n\nReturns\n\namount of bytes needed to hold the output string, or a negative AVERROR on failure. If the returned value is bigger than buf_size, then the string was truncated.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_channel_name_bprint-Tuple{Any, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_channel_name_bprint","text":"av_channel_name_bprint(bp, channel_id::AVChannel)\n\nbprint variant of av_channel_name().\n\nnote: Note\nthe string will be appended to the bprint buffer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_chroma_location_enum_to_pos-Tuple{Any, Any, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_chroma_location_enum_to_pos","text":"av_chroma_location_enum_to_pos(xpos, ypos, pos::AVChromaLocation)\n\nConverts AVChromaLocation to swscale x/y chroma position.\n\nThe positions represent the chroma (0,0) position in a coordinates system with luma (0,0) representing the origin and luma(1,1) representing 256,256\n\nArguments\n\nxpos: horizontal chroma sample position\nypos: vertical chroma sample position\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_chroma_location_from_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_chroma_location_from_name","text":"av_chroma_location_from_name(name)\n\nReturns\n\nthe AVChromaLocation value for name or an AVError if not found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_chroma_location_name-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_chroma_location_name","text":"av_chroma_location_name(location::AVChromaLocation)\n\nReturns\n\nthe name for provided chroma location or NULL if unknown.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_chroma_location_pos_to_enum-Tuple{Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_chroma_location_pos_to_enum","text":"av_chroma_location_pos_to_enum(xpos::Integer, ypos::Integer)\n\nConverts swscale x/y chroma position to AVChromaLocation.\n\nThe positions represent the chroma (0,0) position in a coordinates system with luma (0,0) representing the origin and luma(1,1) representing 256,256\n\nArguments\n\nxpos: horizontal chroma sample position\nypos: vertical chroma sample position\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_clip64_c-Tuple{Int64, Int64, Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_clip64_c","text":"av_clip64_c(a::Int64, amin::Int64, amax::Int64)\n\nClip a signed 64bit integer value into the amin-amax range.\n\nArguments\n\na: value to clip\namin: minimum value of the clip range\namax: maximum value of the clip range\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_clip_c-Tuple{Integer, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_clip_c","text":"av_clip_c(a::Integer, amin::Integer, amax::Integer)\n\nClip a signed integer value into the amin-amax range.\n\nArguments\n\na: value to clip\namin: minimum value of the clip range\namax: maximum value of the clip range\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_clip_int16_c-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_clip_int16_c","text":"av_clip_int16_c(a::Integer)\n\nClip a signed integer value into the -32768,32767 range.\n\nArguments\n\na: value to clip\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_clip_int8_c-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_clip_int8_c","text":"av_clip_int8_c(a::Integer)\n\nClip a signed integer value into the -128,127 range.\n\nArguments\n\na: value to clip\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_clip_intp2_c-Tuple{Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_clip_intp2_c","text":"av_clip_intp2_c(a::Integer, p::Integer)\n\nClip a signed integer into the -(2^p),(2^p-1) range.\n\nArguments\n\na: value to clip\np: bit position to clip at\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_clip_uint16_c-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_clip_uint16_c","text":"av_clip_uint16_c(a::Integer)\n\nClip a signed integer value into the 0-65535 range.\n\nArguments\n\na: value to clip\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_clip_uint8_c-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_clip_uint8_c","text":"av_clip_uint8_c(a::Integer)\n\nClip a signed integer value into the 0-255 range.\n\nArguments\n\na: value to clip\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_clip_uintp2_c-Tuple{Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_clip_uintp2_c","text":"av_clip_uintp2_c(a::Integer, p::Integer)\n\nClip a signed integer to an unsigned power of two range.\n\nArguments\n\na: value to clip\np: bit position to clip at\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_clipd_c-Tuple{Float64, Float64, Float64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_clipd_c","text":"av_clipd_c(a::Cdouble, amin::Cdouble, amax::Cdouble)\n\nClip a double value into the amin-amax range. If a is nan or -inf amin will be returned. If a is +inf amax will be returned.\n\nArguments\n\na: value to clip\namin: minimum value of the clip range\namax: maximum value of the clip range\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_clipf_c-Tuple{Float32, Float32, Float32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_clipf_c","text":"av_clipf_c(a::Cfloat, amin::Cfloat, amax::Cfloat)\n\nClip a float value into the amin-amax range. If a is nan or -inf amin will be returned. If a is +inf amax will be returned.\n\nArguments\n\na: value to clip\namin: minimum value of the clip range\namax: maximum value of the clip range\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_clipl_int32_c-Tuple{Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_clipl_int32_c","text":"av_clipl_int32_c(a::Int64)\n\nClip a signed 64-bit integer value into the -2147483648,2147483647 range.\n\nArguments\n\na: value to clip\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_cmp_q-Tuple{VideoIO.libffmpeg.AVRational, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_cmp_q","text":"av_cmp_q(a::AVRational, b::AVRational)\n\nCompare two rationals.\n\nArguments\n\na: First rational\nb: Second rational\n\nReturns\n\nOne of the following values: - 0 if a == b - 1 if a > b - -1 if a < b - INT_MIN if one of the values is of the form 0 / 0\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_codec_get_id-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_codec_get_id","text":"av_codec_get_id(tags, tag::Integer)\n\nGet the AVCodecID for the given codec tag tag. If no codec id is found returns AV_CODEC_ID_NONE.\n\nArguments\n\ntags: list of supported codec_id-codec_tag pairs, as stored in AVInputFormat.codec_tag and AVOutputFormat.codec_tag\ntag: codec tag to match to a codec ID\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_codec_get_tag-Tuple{Any, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_codec_get_tag","text":"av_codec_get_tag(tags, id::AVCodecID)\n\nGet the codec tag for the given codec id id. If no codec tag is found returns 0.\n\nArguments\n\ntags: list of supported codec_id-codec_tag pairs, as stored in AVInputFormat.codec_tag and AVOutputFormat.codec_tag\nid: codec ID to match to a codec tag\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_codec_get_tag2-Tuple{Any, UInt32, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_codec_get_tag2","text":"av_codec_get_tag2(tags, id::AVCodecID, tag)\n\nGet the codec tag for the given codec id.\n\nArguments\n\ntags: list of supported codec_id - codec_tag pairs, as stored in AVInputFormat.codec_tag and AVOutputFormat.codec_tag\nid: codec id that should be searched for in the list\ntag: A pointer to the found tag\n\nReturns\n\n0 if id was not found in tags, > 0 if it was found\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_codec_is_decoder-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_codec_is_decoder","text":"av_codec_is_decoder(codec)\n\nReturns\n\na non-zero number if codec is a decoder, zero otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_codec_is_encoder-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_codec_is_encoder","text":"av_codec_is_encoder(codec)\n\nReturns\n\na non-zero number if codec is an encoder, zero otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_codec_iterate-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_codec_iterate","text":"av_codec_iterate(opaque)\n\nIterate over all registered codecs.\n\nArguments\n\nopaque: a pointer where libavcodec will store the iteration state. Must point to NULL to start the iteration.\n\nReturns\n\nthe next registered codec or NULL when the iteration is finished\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_color_primaries_from_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_color_primaries_from_name","text":"av_color_primaries_from_name(name)\n\nReturns\n\nthe AVColorPrimaries value for name or an AVError if not found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_color_primaries_name-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_color_primaries_name","text":"av_color_primaries_name(primaries::AVColorPrimaries)\n\nReturns\n\nthe name for provided color primaries or NULL if unknown.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_color_range_from_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_color_range_from_name","text":"av_color_range_from_name(name)\n\nReturns\n\nthe AVColorRange value for name or an AVError if not found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_color_range_name-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_color_range_name","text":"av_color_range_name(range::AVColorRange)\n\nReturns\n\nthe name for provided color range or NULL if unknown.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_color_space_from_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_color_space_from_name","text":"av_color_space_from_name(name)\n\nReturns\n\nthe AVColorSpace value for name or an AVError if not found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_color_space_name-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_color_space_name","text":"av_color_space_name(space::AVColorSpace)\n\nReturns\n\nthe name for provided color space or NULL if unknown.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_color_transfer_from_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_color_transfer_from_name","text":"av_color_transfer_from_name(name)\n\nReturns\n\nthe AVColorTransferCharacteristic value for name or an AVError if not found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_color_transfer_name-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_color_transfer_name","text":"av_color_transfer_name(transfer::AVColorTransferCharacteristic)\n\nReturns\n\nthe name for provided color transfer or NULL if unknown.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_compare_mod-Tuple{UInt64, UInt64, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_compare_mod","text":"av_compare_mod(a::UInt64, b::UInt64, mod::UInt64)\n\nCompare the remainders of two integer operands divided by a common divisor.\n\nIn other words, compare the least significant log2(mod) bits of integers a and b.\n\n{.c}\n av_compare_mod(0x11, 0x02, 0x10) < 0 // since 0x11 % 0x10  (0x1) < 0x02 % 0x10  (0x2)\n av_compare_mod(0x11, 0x02, 0x20) > 0 // since 0x11 % 0x20 (0x11) > 0x02 % 0x20 (0x02)\n\nArguments\n\na: Operand\nb: Operand\nmod: Divisor; must be a power of 2\n\nReturns\n\na negative value if a % mod < b % mod - a positive value if a % mod > b % mod - zero if a % mod == b % mod\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_compare_ts-Tuple{Int64, VideoIO.libffmpeg.AVRational, Int64, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_compare_ts","text":"av_compare_ts(ts_a::Int64, tb_a::AVRational, ts_b::Int64, tb_b::AVRational)\n\nCompare two timestamps each in its own time base.\n\nwarning: Warning\nThe result of the function is undefined if one of the timestamps is outside the int64_t range when represented in the other's timebase.\n\nReturns\n\nOne of the following values: - -1 if ts_a is before ts_b - 1 if ts_a is after ts_b - 0 if they represent the same position\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_container_fifo_alloc-Tuple{Any, Any, Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_container_fifo_alloc","text":"av_container_fifo_alloc(opaque, container_alloc, container_reset, container_free, fifo_transfer, flags::Integer)\n\nAllocate a new AVContainerFifo for the container type defined by provided callbacks.\n\nArguments\n\nopaque: user data that will be passed to the callbacks provided to this function\ncontainer_alloc: allocate a new container instance and return a pointer to it, or NULL on failure\ncontainer_reset: reset the provided container instance to a clean state\ncontainer_free: free the provided container instance\nfifo_transfer: Transfer the contents of container src to dst.\nflags: currently unused\n\nReturns\n\nnewly allocated AVContainerFifo, or NULL on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_container_fifo_alloc_avframe-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_container_fifo_alloc_avframe","text":"av_container_fifo_alloc_avframe(flags::Integer)\n\nAllocate an AVContainerFifo instance for AVFrames.\n\nArguments\n\nflags: currently unused\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_container_fifo_alloc_avpacket-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_container_fifo_alloc_avpacket","text":"av_container_fifo_alloc_avpacket(flags::Integer)\n\nAllocate an AVContainerFifo instance for AVPacket.\n\nArguments\n\nflags: currently unused\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_container_fifo_can_read-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_container_fifo_can_read","text":"av_container_fifo_can_read(cf)\n\nReturns\n\nnumber of objects available for reading\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_container_fifo_drain-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_container_fifo_drain","text":"av_container_fifo_drain(cf, nb_elems::Csize_t)\n\nDiscard the specified number of elements from the FIFO.\n\nArguments\n\nnb_elems: number of elements to discard, MUST NOT be larger than av_fifo_can_read(f)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_container_fifo_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_container_fifo_free","text":"av_container_fifo_free(cf)\n\nFree a AVContainerFifo and everything in it.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_container_fifo_peek-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_container_fifo_peek","text":"av_container_fifo_peek(cf, pobj, offset::Csize_t)\n\nAccess objects stored in the FIFO without retrieving them. The fifo_transfer() callback will NOT be invoked and the FIFO state will not be modified.\n\n\\retval0 success, a pointer was written into pobj\n\n\\retvalAVERROR(EINVAL) invalid offset value\n\nArguments\n\npobj: Pointer to the object stored in the FIFO will be written here on success. The object remains owned by the FIFO and the caller may only access it as long as the FIFO is not modified.\noffset: Position of the object to retrieve - 0 is the next item that would be read, 1 the one after, etc. Must be smaller than av_container_fifo_can_read().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_container_fifo_read-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_container_fifo_read","text":"av_container_fifo_read(cf, obj, flags::Integer)\n\nRead the next available object from the FIFO into obj.\n\nThe fifo_read() callback previously provided to av_container_fifo_alloc() will be called with obj as dst in order to perform the actual transfer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_container_fifo_write-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_container_fifo_write","text":"av_container_fifo_write(cf, obj, flags::Integer)\n\nWrite the contents of obj to the FIFO.\n\nThe fifo_transfer() callback previously provided to av_container_fifo_alloc() will be called with obj as src in order to perform the actual transfer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_content_light_metadata_alloc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_content_light_metadata_alloc","text":"av_content_light_metadata_alloc(size)\n\nAllocate an AVContentLightMetadata structure and set its fields to default values. The resulting struct can be freed using av_freep().\n\nReturns\n\nAn AVContentLightMetadata filled with default values or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_content_light_metadata_create_side_data-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_content_light_metadata_create_side_data","text":"av_content_light_metadata_create_side_data(frame)\n\nAllocate a complete AVContentLightMetadata and add it to the frame.\n\nArguments\n\nframe: The frame which side data is added to.\n\nReturns\n\nThe AVContentLightMetadata structure to be filled by caller.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_cpb_properties_alloc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_cpb_properties_alloc","text":"av_cpb_properties_alloc(size)\n\nAllocate a CPB properties structure and initialize its fields to default values.\n\nArguments\n\nsize: if non-NULL, the size of the allocated struct will be written here. This is useful for embedding it in side data.\n\nReturns\n\nthe newly allocated struct or NULL on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_cpu_count-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_cpu_count","text":"av_cpu_count()\n\nReturns\n\nthe number of logical CPU cores present.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_cpu_force_count-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_cpu_force_count","text":"av_cpu_force_count(count::Integer)\n\nOverrides cpu count detection and forces the specified count. Count < 1 disables forcing of specific count.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_cpu_max_align-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_cpu_max_align","text":"av_cpu_max_align()\n\nGet the maximum data alignment that may be required by FFmpeg.\n\nNote that this is affected by the build configuration and the CPU flags mask, so e.g. if the CPU supports AVX, but libavutil has been built with –disable-avx or the AV_CPU_FLAG_AVX flag has been disabled through av_set_cpu_flags_mask(), then this function will behave as if AVX is not present.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_crc-Tuple{Any, Integer, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_crc","text":"av_crc(ctx, crc::Integer, buffer, length::Csize_t)\n\nCalculate the CRC of a block.\n\nArguments\n\nctx: initialized AVCRC array (see av_crc_init())\ncrc: CRC of previous blocks if any or initial value for CRC\nbuffer: buffer whose CRC to calculate\nlength: length of the buffer\n\nReturns\n\nCRC updated with the data from the given block\n\nSee also\n\nav_crc_init() \"le\" parameter\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_crc_get_table-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_crc_get_table","text":"av_crc_get_table(crc_id::AVCRCId)\n\nGet an initialized standard CRC table.\n\nArguments\n\ncrc_id: ID of a standard CRC\n\nReturns\n\na pointer to the CRC table or NULL on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_crc_init-Tuple{Any, Vararg{Integer, 4}}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_crc_init","text":"av_crc_init(ctx, le::Integer, bits::Integer, poly::Integer, ctx_size::Integer)\n\nInitialize a CRC table.\n\nArguments\n\nctx: must be an array of size sizeof(AVCRC)257 or sizeof(AVCRC)1024\nle: If 1, the lowest bit represents the coefficient for the highest exponent of the corresponding polynomial (both for poly and actual CRC). If 0, you must swap the CRC parameter and the result of av_crc if you need the standard representation (can be simplified in most cases to e.g. bswap16): av_bswap32(crc << (32-bits))\nbits: number of bits for the CRC\npoly: generator polynomial without the x**bits coefficient, in the representation as specified by le\nctx_size: size of ctx in bytes\n\nReturns\n\n<0 on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_csp_approximate_trc_gamma-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_csp_approximate_trc_gamma","text":"av_csp_approximate_trc_gamma(trc::AVColorTransferCharacteristic)\n\nDetermine a suitable 'gamma' value to match the supplied AVColorTransferCharacteristic.\n\nSee Apple Technical Note TN2257 (https://developer.apple.com/library/mac/technotes/tn2257/_index.html)\n\nThis function returns the gamma exponent for the OETF. For example, sRGB is approximated by gamma 2.2, not by gamma 0.45455.\n\nReturns\n\nWill return an approximation to the simple gamma function matching the supplied Transfer Characteristic, Will return 0.0 for any we cannot reasonably match against.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_csp_itu_eotf-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_csp_itu_eotf","text":"av_csp_itu_eotf(trc::AVColorTransferCharacteristic)\n\nReturns the ITU EOTF corresponding to a given TRC. This converts from the signal level [0,1] to the raw output display luminance in nits (cd/m^2). This is done per channel in RGB space, except for AVCOL_TRC_SMPTE428, which assumes CIE XYZ in- and output.\n\nnote: Note\nIn general, the resulting function is defined (wherever possible) for out-of-range values, even though these values do not have a physical meaning on the given display. Users should clamp inputs (or outputs) if this behavior is not desired.\n\nThis is also the case for functions like PQ, which are defined over an absolute signal range independent of the target display capabilities.\n\nReturns\n\nA pointer to the function implementing the given TRC, or NULL if no such function is defined.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_csp_itu_eotf_inv-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_csp_itu_eotf_inv","text":"av_csp_itu_eotf_inv(trc::AVColorTransferCharacteristic)\n\nReturns the mathematical inverse of the corresponding EOTF.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_csp_luma_coeffs_from_avcsp-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_csp_luma_coeffs_from_avcsp","text":"av_csp_luma_coeffs_from_avcsp(csp::AVColorSpace)\n\nRetrieves the Luma coefficients necessary to construct a conversion matrix from an enum constant describing the colorspace.\n\nArguments\n\ncsp: An enum constant indicating YUV or similar colorspace.\n\nReturns\n\nThe Luma coefficients associated with that colorspace, or NULL if the constant is unknown to libavutil.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_csp_primaries_desc_from_id-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_csp_primaries_desc_from_id","text":"av_csp_primaries_desc_from_id(prm::AVColorPrimaries)\n\nRetrieves a complete gamut description from an enum constant describing the color primaries.\n\nArguments\n\nprm: An enum constant indicating primaries\n\nReturns\n\nA description of the colorspace gamut associated with that enum constant, or NULL if the constant is unknown to libavutil.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_csp_primaries_id_from_desc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_csp_primaries_id_from_desc","text":"av_csp_primaries_id_from_desc(prm)\n\nDetects which enum AVColorPrimaries constant corresponds to the given complete gamut description.\n\nArguments\n\nprm: A description of the colorspace gamut\n\nReturns\n\nThe enum constant associated with this gamut, or AVCOL_PRI_UNSPECIFIED if no clear match can be identified.\n\nSee also\n\nenum AVColorPrimaries\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_csp_trc_func_from_id-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_csp_trc_func_from_id","text":"av_csp_trc_func_from_id(trc::AVColorTransferCharacteristic)\n\nDetermine the function needed to apply the given AVColorTransferCharacteristic to linear input.\n\nThe function returned should expect a nominal domain and range of [0.0-1.0] values outside of this range maybe valid depending on the chosen characteristic function.\n\nReturns\n\nWill return pointer to the function matching the supplied Transfer Characteristic. If unspecified will return NULL:\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_csp_trc_func_inv_from_id-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_csp_trc_func_inv_from_id","text":"av_csp_trc_func_inv_from_id(trc::AVColorTransferCharacteristic)\n\nReturns the mathematical inverse of the corresponding TRC function.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_d2q-Tuple{Float64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_d2q","text":"av_d2q(d::Cdouble, max::Integer)\n\nConvert a double precision floating point number to a rational.\n\nIn case of infinity, the returned value is expressed as {1, 0} or {-1, 0} depending on the sign.\n\nIn general rational numbers with |num| <= 1<<26 && |den| <= 1<<26 can be recovered exactly from their double representation. (no exceptions were found within 1B random ones)\n\nArguments\n\nd: double to convert\nmax: Maximum allowed numerator and denominator\n\nReturns\n\nd in AVRational form\n\nSee also\n\nav_q2d()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_d3d11va_alloc_context-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_d3d11va_alloc_context","text":"av_d3d11va_alloc_context()\n\nAllocate an AVD3D11VAContext.\n\nReturns\n\nNewly-allocated AVD3D11VAContext or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_default_item_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_default_item_name","text":"av_default_item_name(ctx)\n\nReturn the context name\n\nArguments\n\nctx: The AVClass context\n\nReturns\n\nThe AVClass class_name\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_demuxer_iterate-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_demuxer_iterate","text":"av_demuxer_iterate(opaque)\n\nIterate over all registered demuxers.\n\nArguments\n\nopaque: a pointer where libavformat will store the iteration state. Must point to NULL to start the iteration.\n\nReturns\n\nthe next registered demuxer or NULL when the iteration is finished\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_des_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_des_alloc","text":"av_des_alloc()\n\nAllocate an AVDES context.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_des_crypt-Tuple{Any, Any, Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_des_crypt","text":"av_des_crypt(d, dst, src, count::Integer, iv, decrypt::Integer)\n\nEncrypts / decrypts using the DES algorithm.\n\nArguments\n\nd: pointer to the AVDES structure\ndst: destination array, can be equal to src, must be 8-byte aligned\nsrc: source array, can be equal to dst, must be 8-byte aligned, may be NULL\ncount: number of 8 byte blocks\niv: initialization vector for CBC mode, if NULL then ECB will be used, must be 8-byte aligned\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_des_init-Tuple{Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_des_init","text":"av_des_init(d, key, key_bits::Integer, decrypt::Integer)\n\nInitializes an AVDES context.\n\nArguments\n\nd: pointer to a AVDES structure to initialize\nkey: pointer to the key to use\nkey_bits: must be 64 or 192\ndecrypt: 0 for encryption/CBC-MAC, 1 for decryption\n\nReturns\n\nzero on success, negative value otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_des_mac-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_des_mac","text":"av_des_mac(d, dst, src, count::Integer)\n\nCalculates CBC-MAC using the DES algorithm.\n\nArguments\n\nd: pointer to the AVDES structure\ndst: destination array, can be equal to src, must be 8-byte aligned\nsrc: source array, can be equal to dst, must be 8-byte aligned, may be NULL\ncount: number of 8 byte blocks\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_detection_bbox_alloc-Tuple{Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_detection_bbox_alloc","text":"av_detection_bbox_alloc(nb_bboxes::Integer, out_size)\n\nAllocates memory for AVDetectionBBoxHeader, plus an array of {\n\n nb_bboxes}\n AVDetectionBBox, and initializes the variables.\n Can be freed with a normal av_free() call.\n\n @param nb_bboxes number of AVDetectionBBox structures to allocate\n @param out_size if non-NULL, the size in bytes of the resulting data array is\n written here.\n \n\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_detection_bbox_create_side_data-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_detection_bbox_create_side_data","text":"av_detection_bbox_create_side_data(frame, nb_bboxes::Integer)\n\nAllocates memory for AVDetectionBBoxHeader, plus an array of {\n\n nb_bboxes}\n AVDetectionBBox, in the given AVFrame {@code frame} as AVFrameSideData of type\n AV_FRAME_DATA_DETECTION_BBOXES and initializes the variables.\n \n\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dict_copy-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dict_copy","text":"av_dict_copy(dst, src, flags::Integer)\n\nCopy entries from one AVDictionary struct into another.\n\nnote: Note\nMetadata is read using the ::AV_DICT_IGNORE_SUFFIX flag\n\nArguments\n\ndst: Pointer to a pointer to a AVDictionary struct to copy into. If *dst is NULL, this function will allocate a struct for you and put it in *dst\nsrc: Pointer to the source AVDictionary struct to copy items from.\nflags: Flags to use when setting entries in *dst\n\nReturns\n\n0 on success, negative AVERROR code on failure. If dst was allocated by this function, callers should free the associated memory.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dict_count-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dict_count","text":"av_dict_count(m)\n\nGet number of entries in dictionary.\n\nArguments\n\nm: dictionary\n\nReturns\n\nnumber of entries in dictionary\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dict_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dict_free","text":"av_dict_free(m)\n\nFree all the memory allocated for an AVDictionary struct and all keys and values.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dict_get-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dict_get","text":"av_dict_get(m, key, prev, flags::Integer)\n\nGet a dictionary entry with matching key.\n\nThe returned entry key or value must not be changed, or it will cause undefined behavior.\n\nArguments\n\nprev: Set to the previous matching element to find the next. If set to NULL the first matching element is returned.\nkey: Matching key\nflags: A collection of AV_DICT_* flags controlling how the entry is retrieved\n\nReturns\n\nFound entry or NULL in case no matching entry was found in the dictionary\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dict_get_string-Tuple{Any, Any, Int8, Int8}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dict_get_string","text":"av_dict_get_string(m, buffer, key_val_sep::Cchar, pairs_sep::Cchar)\n\nGet dictionary entries as a string.\n\nCreate a string containing dictionary's entries. Such string may be passed back to av_dict_parse_string().\n\nnote: Note\nString is escaped with backslashes ('\\').\n\nwarning: Warning\nSeparators cannot be neither '\\' nor '\\0'. They also cannot be the same.\n\nArguments\n\nm:[in] The dictionary\nbuffer:[out] Pointer to buffer that will be allocated with string containing entries. Buffer must be freed by the caller when is no longer needed.\nkey_val_sep:[in] Character used to separate key from value\npairs_sep:[in] Character used to separate two pairs from each other\n\nReturns\n\n= 0 on success, negative on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dict_iterate-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dict_iterate","text":"av_dict_iterate(m, prev)\n\nIterate over a dictionary\n\nIterates through all entries in the dictionary.\n\nwarning: Warning\nThe returned AVDictionaryEntry key/value must not be changed.\n\nwarning: Warning\nAs av_dict_set() invalidates all previous entries returned by this function, it must not be called while iterating over the dict.\n\nTypical usage:\n\n const AVDictionaryEntry *e = NULL;\n while ((e = av_dict_iterate(m, e))) {\n     // ...\n }\n\n\\retvalAVDictionaryEntry* The next element in the dictionary\n\n\\retvalNULL No more elements in the dictionary\n\nArguments\n\nm: The dictionary to iterate over\nprev: Pointer to the previous AVDictionaryEntry, NULL initially\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dict_parse_string-Tuple{Any, Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dict_parse_string","text":"av_dict_parse_string(pm, str, key_val_sep, pairs_sep, flags::Integer)\n\nParse the key/value pairs list and add the parsed entries to a dictionary.\n\nIn case of failure, all the successfully set entries are stored in *pm. You may need to manually free the created dictionary.\n\nArguments\n\nkey_val_sep: A 0-terminated list of characters used to separate key from value\npairs_sep: A 0-terminated list of characters used to separate two pairs from each other\nflags: Flags to use when adding to the dictionary. ::AV_DICT_DONT_STRDUP_KEY and ::AV_DICT_DONT_STRDUP_VAL are ignored since the key/value tokens will always be duplicated.\n\nReturns\n\n0 on success, negative AVERROR code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dict_set-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dict_set","text":"av_dict_set(pm, key, value, flags::Integer)\n\nSet the given entry in *pm, overwriting an existing entry.\n\nNote: If AV_DICT_DONT_STRDUP_KEY or AV_DICT_DONT_STRDUP_VAL is set, these arguments will be freed on error.\n\nwarning: Warning\nAdding a new entry to a dictionary invalidates all existing entries previously returned with av_dict_get() or av_dict_iterate().\n\nArguments\n\npm: Pointer to a pointer to a dictionary struct. If *pm is NULL a dictionary struct is allocated and put in *pm.\nkey: Entry key to add to *pm (will either be av_strduped or added as a new key depending on flags)\nvalue: Entry value to add to *pm (will be av_strduped or added as a new key depending on flags). Passing a NULL value will cause an existing entry to be deleted.\n\nReturns\n\n= 0 on success otherwise an error code <0\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dict_set_int-Tuple{Any, Any, Int64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dict_set_int","text":"av_dict_set_int(pm, key, value::Int64, flags::Integer)\n\nConvenience wrapper for av_dict_set() that converts the value to a string and stores it.\n\nNote: If ::AV_DICT_DONT_STRDUP_KEY is set, key will be freed on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dirac_parse_sequence_header-Tuple{Any, Any, UInt64, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dirac_parse_sequence_header","text":"av_dirac_parse_sequence_header(dsh, buf, buf_size::Csize_t, log_ctx)\n\nParse a Dirac sequence header.\n\nArguments\n\ndsh: this function will allocate and fill an AVDiracSeqHeader struct and write it into this pointer. The caller must free it with av_free().\nbuf: the data buffer\nbuf_size: the size of the data buffer in bytes\nlog_ctx: if non-NULL, this function will log errors here\n\nReturns\n\n0 on success, a negative AVERROR code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dirname-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dirname","text":"av_dirname(path)\n\nThread safe dirname.\n\nnote: Note\nthe function may modify the contents of the path, so copies should be passed.\n\nArguments\n\npath: the string to parse, on DOS both \\ and / are considered separators.\n\nReturns\n\nA pointer to a string that's the parent directory of path. If path is a NULL pointer or points to an empty string, a pointer to a string \".\" is returned.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_display_matrix_flip-Tuple{Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_display_matrix_flip","text":"av_display_matrix_flip(matrix, hflip::Integer, vflip::Integer)\n\nFlip the input matrix horizontally and/or vertically.\n\nArguments\n\nmatrix:[in,out] a transformation matrix\nhflip: whether the matrix should be flipped horizontally\nvflip: whether the matrix should be flipped vertically\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_display_rotation_get-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_display_rotation_get","text":"av_display_rotation_get(matrix)\n\nExtract the rotation component of the transformation matrix.\n\nnote: Note\nfloating point numbers are inherently inexact, so callers are recommended to round the return value to nearest integer before use.\n\nArguments\n\nmatrix: the transformation matrix\n\nReturns\n\nthe angle (in degrees) by which the transformation rotates the frame counterclockwise. The angle will be in range [-180.0, 180.0], or NaN if the matrix is singular.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_display_rotation_set-Tuple{Any, Float64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_display_rotation_set","text":"av_display_rotation_set(matrix, angle::Cdouble)\n\nInitialize a transformation matrix describing a pure clockwise rotation by the specified angle (in degrees).\n\nArguments\n\nmatrix:[out] a transformation matrix (will be fully overwritten by this function)\nangle: rotation angle in degrees.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_disposition_from_string-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_disposition_from_string","text":"av_disposition_from_string(disp)\n\nReturns\n\nThe AV_DISPOSITION_* flag corresponding to disp or a negative error code if disp does not correspond to a known stream disposition.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_disposition_to_string-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_disposition_to_string","text":"av_disposition_to_string(disposition::Integer)\n\nArguments\n\ndisposition: a combination of AV_DISPOSITION_* values\n\nReturns\n\nThe string description corresponding to the lowest set bit in disposition. NULL when the lowest set bit does not correspond to a known disposition or when disposition is 0.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_div_q-Tuple{VideoIO.libffmpeg.AVRational, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_div_q","text":"av_div_q(b::AVRational, c::AVRational)\n\nDivide one rational by another.\n\nArguments\n\nb: First rational\nc: Second rational\n\nReturns\n\nb/c\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_double2int-Tuple{Float64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_double2int","text":"av_double2int(f::Cdouble)\n\nReinterpret a double as a 64-bit integer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dovi_alloc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dovi_alloc","text":"av_dovi_alloc(size)\n\nAllocate a AVDOVIDecoderConfigurationRecord structure and initialize its fields to default values.\n\nReturns\n\nthe newly allocated struct or NULL on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dovi_find_level-Tuple{Any, UInt8}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dovi_find_level","text":"av_dovi_find_level(data, level::UInt8)\n\nFind an extension block with a given level, or NULL. In the case of multiple extension blocks, only the first is returned.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dovi_metadata_alloc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dovi_metadata_alloc","text":"av_dovi_metadata_alloc(size)\n\nAllocate an AVDOVIMetadata structure and initialize its fields to default values.\n\nArguments\n\nsize: If this parameter is non-NULL, the size in bytes of the allocated struct will be written here on success\n\nReturns\n\nthe newly allocated struct or NULL on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_downmix_info_update_side_data-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_downmix_info_update_side_data","text":"av_downmix_info_update_side_data(frame)\n\nGet a frame's AV_FRAME_DATA_DOWNMIX_INFO side data for editing.\n\nIf the side data is absent, it is created and added to the frame.\n\nArguments\n\nframe: the frame for which the side data is to be obtained or created\n\nReturns\n\nthe AVDownmixInfo structure to be edited by the caller, or NULL if the structure cannot be allocated.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dump_format-Tuple{Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dump_format","text":"av_dump_format(ic, index::Integer, url, is_output::Integer)\n\nPrint detailed information about the input or output format, such as duration, bitrate, streams, container, programs, metadata, side data, codec and time base.\n\nArguments\n\nic: the context to analyze\nindex: index of the stream to dump information about\nurl: the URL to print, such as source or destination file\nis_output: Select whether the specified context is an input(0) or output(1)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dv_codec_profile-Tuple{Integer, Integer, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dv_codec_profile","text":"av_dv_codec_profile(width::Integer, height::Integer, pix_fmt::AVPixelFormat)\n\nGet a DV profile for the provided stream parameters.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dv_codec_profile2-Tuple{Integer, Integer, Int32, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dv_codec_profile2","text":"av_dv_codec_profile2(width::Integer, height::Integer, pix_fmt::AVPixelFormat, frame_rate::AVRational)\n\nGet a DV profile for the provided stream parameters. The frame rate is used as a best-effort parameter.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dv_frame_profile-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dv_frame_profile","text":"av_dv_frame_profile(sys, frame, buf_size::Integer)\n\nGet a DV profile for the provided compressed frame.\n\nArguments\n\nsys: the profile used for the previous frame, may be NULL\nframe: the compressed data buffer\nbuf_size: size of the buffer in bytes\n\nReturns\n\nthe DV profile for the supplied data or NULL on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dynamic_hdr_plus_alloc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dynamic_hdr_plus_alloc","text":"av_dynamic_hdr_plus_alloc(size)\n\nAllocate an AVDynamicHDRPlus structure and set its fields to default values. The resulting struct can be freed using av_freep().\n\nReturns\n\nAn AVDynamicHDRPlus filled with default values or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dynamic_hdr_plus_create_side_data-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dynamic_hdr_plus_create_side_data","text":"av_dynamic_hdr_plus_create_side_data(frame)\n\nAllocate a complete AVDynamicHDRPlus and add it to the frame.\n\nArguments\n\nframe: The frame which side data is added to.\n\nReturns\n\nThe AVDynamicHDRPlus structure to be filled by caller or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dynamic_hdr_plus_from_t35-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dynamic_hdr_plus_from_t35","text":"av_dynamic_hdr_plus_from_t35(s, data, size::Csize_t)\n\nParse the user data registered ITU-T T.35 to AVbuffer (AVDynamicHDRPlus). The T.35 buffer must begin with the application mode, skipping the country code, terminal provider codes, and application identifier.\n\nArguments\n\ns: A pointer containing the decoded AVDynamicHDRPlus structure.\ndata: The byte array containing the raw ITU-T T.35 data.\nsize: Size of the data array in bytes.\n\nReturns\n\n= 0 on success. Otherwise, returns the appropriate AVERROR.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dynamic_hdr_plus_to_t35-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dynamic_hdr_plus_to_t35","text":"av_dynamic_hdr_plus_to_t35(s, data, size)\n\nSerialize dynamic HDR10+ metadata to a user data registered ITU-T T.35 buffer, excluding the first 48 bytes of the header, and beginning with the application mode.\n\nArguments\n\ns: A pointer containing the decoded AVDynamicHDRPlus structure.\ndata:[in,out] A pointer to pointer to a byte buffer to be filled with the serialized metadata. If *data is NULL, a buffer be will be allocated and a pointer to it stored in its place. The caller assumes ownership of the buffer. May be NULL, in which case the function will only store the required buffer size in *size.\nsize:[in,out] A pointer to a size to be set to the returned buffer's size. If *data is not NULL, *size must contain the size of the input buffer. May be NULL only if *data is NULL.\n\nReturns\n\n= 0 on success. Otherwise, returns the appropriate AVERROR.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dynamic_hdr_vivid_alloc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dynamic_hdr_vivid_alloc","text":"av_dynamic_hdr_vivid_alloc(size)\n\nAllocate an AVDynamicHDRVivid structure and set its fields to default values. The resulting struct can be freed using av_freep().\n\nReturns\n\nAn AVDynamicHDRVivid filled with default values or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dynamic_hdr_vivid_create_side_data-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dynamic_hdr_vivid_create_side_data","text":"av_dynamic_hdr_vivid_create_side_data(frame)\n\nAllocate a complete AVDynamicHDRVivid and add it to the frame.\n\nArguments\n\nframe: The frame which side data is added to.\n\nReturns\n\nThe AVDynamicHDRVivid structure to be filled by caller or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dynarray2_add-Tuple{Any, Any, UInt64, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dynarray2_add","text":"av_dynarray2_add(tab_ptr, nb_ptr, elem_size::Csize_t, elem_data)\n\nAdd an element of size elem_size to a dynamic array.\n\nThe array is reallocated when its number of elements reaches powers of 2. Therefore, the amortized cost of adding an element is constant.\n\nIn case of success, the pointer to the array is updated in order to point to the new grown array, and the number pointed to by nb_ptr is incremented. In case of failure, the array is freed, *tab\\_ptr is set to NULL and *nb\\_ptr is set to 0.\n\nArguments\n\ntab_ptr:[in,out] Pointer to the array to grow\nnb_ptr:[in,out] Pointer to the number of elements in the array\nelem_size:[in] Size in bytes of an element in the array\nelem_data:[in] Pointer to the data of the element to add. If NULL, the space of the newly added element is allocated but left uninitialized.\n\nReturns\n\nPointer to the data of the element to copy in the newly allocated space\n\nSee also\n\nav_dynarray_add(), av_dynarray_add_nofree()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dynarray_add-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dynarray_add","text":"av_dynarray_add(tab_ptr, nb_ptr, elem)\n\nAdd the pointer to an element to a dynamic array.\n\nThe array to grow is supposed to be an array of pointers to structures, and the element to add must be a pointer to an already allocated structure.\n\nThe array is reallocated when its size reaches powers of 2. Therefore, the amortized cost of adding an element is constant.\n\nIn case of success, the pointer to the array is updated in order to point to the new grown array, and the number pointed to by nb_ptr is incremented. In case of failure, the array is freed, *tab\\_ptr is set to NULL and *nb\\_ptr is set to 0.\n\nArguments\n\ntab_ptr:[in,out] Pointer to the array to grow\nnb_ptr:[in,out] Pointer to the number of elements in the array\nelem:[in] Element to add\n\nSee also\n\nav_dynarray_add_nofree(), av_dynarray2_add()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_dynarray_add_nofree-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_dynarray_add_nofree","text":"av_dynarray_add_nofree(tab_ptr, nb_ptr, elem)\n\nAdd an element to a dynamic array.\n\nFunction has the same functionality as av_dynarray_add(), but it doesn't free memory on fails. It returns error code instead and leave current buffer untouched.\n\nReturns\n\n=0 on success, negative otherwise\n\nSee also\n\nav_dynarray_add(), av_dynarray2_add()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_encryption_info_add_side_data-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_encryption_info_add_side_data","text":"av_encryption_info_add_side_data(info, side_data_size)\n\nAllocates and initializes side data that holds a copy of the given encryption info. The resulting pointer should be either freed using av_free or given to av_packet_add_side_data().\n\nReturns\n\nThe new side-data pointer, or NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_encryption_info_alloc-Tuple{Integer, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_encryption_info_alloc","text":"av_encryption_info_alloc(subsample_count::Integer, key_id_size::Integer, iv_size::Integer)\n\nAllocates an AVEncryptionInfo structure and sub-pointers to hold the given number of subsamples. This will allocate pointers for the key ID, IV, and subsample entries, set the size members, and zero-initialize the rest.\n\nArguments\n\nsubsample_count: The number of subsamples.\nkey_id_size: The number of bytes in the key ID, should be 16.\niv_size: The number of bytes in the IV, should be 16.\n\nReturns\n\nThe new AVEncryptionInfo structure, or NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_encryption_info_clone-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_encryption_info_clone","text":"av_encryption_info_clone(info)\n\nAllocates an AVEncryptionInfo structure with a copy of the given data.\n\nReturns\n\nThe new AVEncryptionInfo structure, or NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_encryption_info_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_encryption_info_free","text":"av_encryption_info_free(info)\n\nFrees the given encryption info object. This MUST NOT be used to free the side-data data pointer, that should use normal side-data methods.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_encryption_info_get_side_data-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_encryption_info_get_side_data","text":"av_encryption_info_get_side_data(side_data, side_data_size::Csize_t)\n\nCreates a copy of the AVEncryptionInfo that is contained in the given side data. The resulting object should be passed to av_encryption_info_free() when done.\n\nReturns\n\nThe new AVEncryptionInfo structure, or NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_encryption_init_info_add_side_data-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_encryption_init_info_add_side_data","text":"av_encryption_init_info_add_side_data(info, side_data_size)\n\nAllocates and initializes side data that holds a copy of the given encryption init info. The resulting pointer should be either freed using av_free or given to av_packet_add_side_data().\n\nReturns\n\nThe new side-data pointer, or NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_encryption_init_info_alloc-NTuple{4, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_encryption_init_info_alloc","text":"av_encryption_init_info_alloc(system_id_size::Integer, num_key_ids::Integer, key_id_size::Integer, data_size::Integer)\n\nAllocates an AVEncryptionInitInfo structure and sub-pointers to hold the given sizes. This will allocate pointers and set all the fields.\n\nReturns\n\nThe new AVEncryptionInitInfo structure, or NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_encryption_init_info_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_encryption_init_info_free","text":"av_encryption_init_info_free(info)\n\nFrees the given encryption init info object. This MUST NOT be used to free the side-data data pointer, that should use normal side-data methods.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_encryption_init_info_get_side_data-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_encryption_init_info_get_side_data","text":"av_encryption_init_info_get_side_data(side_data, side_data_size::Csize_t)\n\nCreates a copy of the AVEncryptionInitInfo that is contained in the given side data. The resulting object should be passed to av_encryption_init_info_free() when done.\n\nReturns\n\nThe new AVEncryptionInitInfo structure, or NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_escape-Tuple{Any, Any, Any, UInt32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_escape","text":"av_escape(dst, src, special_chars, mode::AVEscapeMode, flags::Integer)\n\nEscape string in src, and put the escaped string in an allocated string in *dst, which must be freed with av_free().\n\nArguments\n\ndst: pointer where an allocated string is put\nsrc: string to escape, must be non-NULL\nspecial_chars: string containing the special characters which need to be escaped, can be NULL\nmode: escape mode to employ, see AV_ESCAPE_MODE_* macros. Any unknown value for mode will be considered equivalent to AV_ESCAPE_MODE_BACKSLASH, but this behaviour can change without notice.\nflags: flags which control how to escape, see AV_ESCAPE_FLAG_ macros\n\nReturns\n\nthe length of the allocated string, or a negative error code in case of error\n\nSee also\n\nav_bprint_escape()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_executor_alloc-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_executor_alloc","text":"av_executor_alloc(callbacks, thread_count::Integer)\n\nAlloc executor\n\nArguments\n\ncallbacks: callback structure for executor\nthread_count: worker thread number, 0 for run on caller's thread directly\n\nReturns\n\nreturn the executor\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_executor_execute-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_executor_execute","text":"av_executor_execute(e, t)\n\nAdd task to executor\n\nArguments\n\ne: pointer to executor\nt: pointer to task. If NULL, it will wakeup one work thread\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_executor_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_executor_free","text":"av_executor_free(e)\n\nFree executor\n\nArguments\n\ne: pointer to executor\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_expr_count_func-Tuple{Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_expr_count_func","text":"av_expr_count_func(e, counter, size::Integer, arg::Integer)\n\nTrack the presence of user provided functions and their number of occurrences in a parsed expression.\n\nArguments\n\ne: the AVExpr to track user provided functions in\ncounter: a zero-initialized array where the count of each function will be stored if you passed 5 functions with 2 arguments to av_expr_parse() then for arg=2 this will use up to 5 entries.\nsize: size of array\narg: number of arguments the counted functions have\n\nReturns\n\n0 on success, a negative value indicates that no expression or array was passed or size was zero\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_expr_count_vars-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_expr_count_vars","text":"av_expr_count_vars(e, counter, size::Integer)\n\nTrack the presence of variables and their number of occurrences in a parsed expression\n\nArguments\n\ne: the AVExpr to track variables in\ncounter: a zero-initialized array where the count of each variable will be stored\nsize: size of array\n\nReturns\n\n0 on success, a negative value indicates that no expression or array was passed or size was zero\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_expr_eval-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_expr_eval","text":"av_expr_eval(e, const_values, opaque)\n\nEvaluate a previously parsed expression.\n\nArguments\n\ne: the AVExpr to evaluate\nconst_values: a zero terminated array of values for the identifiers from av_expr_parse() const_names\nopaque: a pointer which will be passed to all functions from funcs1 and funcs2\n\nReturns\n\nthe value of the expression\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_expr_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_expr_free","text":"av_expr_free(e)\n\nFree a parsed expression previously created with av_expr_parse().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_expr_parse-Tuple{Any, Any, Any, Any, Any, Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_expr_parse","text":"av_expr_parse(expr, s, const_names, func1_names, funcs1, func2_names, funcs2, log_offset::Integer, log_ctx)\n\nParse an expression.\n\nArguments\n\nexpr: a pointer where is put an AVExpr containing the parsed value in case of successful parsing, or NULL otherwise. The pointed to AVExpr must be freed with av_expr_free() by the user when it is not needed anymore.\ns: expression as a zero terminated string, for example \"1+2^3+5*5+sin(2/3)\"\nconst_names: NULL terminated array of zero terminated strings of constant identifiers, for example {\"PI\", \"E\", 0}\nfunc1_names: NULL terminated array of zero terminated strings of funcs1 identifiers\nfuncs1: NULL terminated array of function pointers for functions which take 1 argument\nfunc2_names: NULL terminated array of zero terminated strings of funcs2 identifiers\nfuncs2: NULL terminated array of function pointers for functions which take 2 arguments\nlog_offset: log level offset, can be used to silence error messages\nlog_ctx: parent logging context\n\nReturns\n\n= 0 in case of success, a negative value corresponding to an AVERROR code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_expr_parse_and_eval-Tuple{Any, Any, Any, Any, Any, Any, Any, Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_expr_parse_and_eval","text":"av_expr_parse_and_eval(res, s, const_names, const_values, func1_names, funcs1, func2_names, funcs2, opaque, log_offset::Integer, log_ctx)\n\nParse and evaluate an expression. Note, this is significantly slower than av_expr_eval().\n\nArguments\n\nres: a pointer to a double where is put the result value of the expression, or NAN in case of error\ns: expression as a zero terminated string, for example \"1+2^3+5*5+sin(2/3)\"\nconst_names: NULL terminated array of zero terminated strings of constant identifiers, for example {\"PI\", \"E\", 0}\nconst_values: a zero terminated array of values for the identifiers from const_names\nfunc1_names: NULL terminated array of zero terminated strings of funcs1 identifiers\nfuncs1: NULL terminated array of function pointers for functions which take 1 argument\nfunc2_names: NULL terminated array of zero terminated strings of funcs2 identifiers\nfuncs2: NULL terminated array of function pointers for functions which take 2 arguments\nopaque: a pointer which will be passed to all functions from funcs1 and funcs2\nlog_offset: log level offset, can be used to silence error messages\nlog_ctx: parent logging context\n\nReturns\n\n= 0 in case of success, a negative value corresponding to an AVERROR code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fast_malloc-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fast_malloc","text":"av_fast_malloc(ptr, size, min_size::Csize_t)\n\nAllocate a buffer, reusing the given one if large enough.\n\nContrary to av_fast_realloc(), the current buffer contents might not be preserved and on error the old buffer is freed, thus no special handling to avoid memleaks is necessary.\n\n*ptr is allowed to be NULL, in which case allocation always happens if size_needed is greater than 0.\n\n{.c}\n uint8_t *buf = ...;\n av_fast_malloc(&buf, &current_size, size_needed);\n if (!buf) {\n     // Allocation failed; buf already freed\n     return AVERROR(ENOMEM);\n }\n\nArguments\n\nptr:[in,out] Pointer to pointer to an already allocated buffer. *ptr will be overwritten with pointer to new buffer on success or NULL on failure\nsize:[in,out] Pointer to the size of buffer *ptr. *size is updated to the new allocated size, in particular 0 in case of failure.\nmin_size:[in] Desired minimal size of buffer *ptr\n\nSee also\n\nav_realloc(), av_fast_mallocz()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fast_mallocz-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fast_mallocz","text":"av_fast_mallocz(ptr, size, min_size::Csize_t)\n\nAllocate and clear a buffer, reusing the given one if large enough.\n\nLike av_fast_malloc(), but all newly allocated space is initially cleared. Reused buffer is not cleared.\n\n*ptr is allowed to be NULL, in which case allocation always happens if size_needed is greater than 0.\n\nArguments\n\nptr:[in,out] Pointer to pointer to an already allocated buffer. *ptr will be overwritten with pointer to new buffer on success or NULL on failure\nsize:[in,out] Pointer to the size of buffer *ptr. *size is updated to the new allocated size, in particular 0 in case of failure.\nmin_size:[in] Desired minimal size of buffer *ptr\n\nSee also\n\nav_fast_malloc()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fast_padded_malloc-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fast_padded_malloc","text":"av_fast_padded_malloc(ptr, size, min_size::Csize_t)\n\nSame behaviour av_fast_malloc but the buffer has additional AV_INPUT_BUFFER_PADDING_SIZE at the end which will always be 0.\n\nIn addition the whole buffer will initially and after resizes be 0-initialized so that no uninitialized data will ever appear.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fast_padded_mallocz-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fast_padded_mallocz","text":"av_fast_padded_mallocz(ptr, size, min_size::Csize_t)\n\nSame behaviour av_fast_padded_malloc except that buffer will always be 0-initialized after call.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fast_realloc-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fast_realloc","text":"av_fast_realloc(ptr, size, min_size::Csize_t)\n\nReallocate the given buffer if it is not large enough, otherwise do nothing.\n\nIf the given buffer is NULL, then a new uninitialized buffer is allocated.\n\nIf the given buffer is not large enough, and reallocation fails, NULL is returned and *size is set to 0, but the original buffer is not changed or freed.\n\nA typical use pattern follows:\n\n{.c}\n uint8_t *buf = ...;\n uint8_t *new_buf = av_fast_realloc(buf, &current_size, size_needed);\n if (!new_buf) {\n     // Allocation failed; clean up original buffer\n     av_freep(&buf);\n     return AVERROR(ENOMEM);\n }\n\nArguments\n\nptr:[in,out] Already allocated buffer, or NULL\nsize:[in,out] Pointer to the size of buffer ptr. *size is updated to the new allocated size, in particular 0 in case of failure.\nmin_size:[in] Desired minimal size of buffer ptr\n\nReturns\n\nptr if the buffer is large enough, a pointer to newly reallocated buffer if the buffer was not large enough, or NULL in case of error\n\nSee also\n\nav_realloc(), av_fast_malloc()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_alloc2-Tuple{UInt64, UInt64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_alloc2","text":"av_fifo_alloc2(elems::Csize_t, elem_size::Csize_t, flags::Integer)\n\nAllocate and initialize an AVFifo with a given element size.\n\nArguments\n\nelems: initial number of elements that can be stored in the FIFO\nelem_size: Size in bytes of a single element. Further operations on the returned FIFO will implicitly use this element size.\nflags: a combination of AV_FIFO_FLAG_*\n\nReturns\n\nnewly-allocated AVFifo on success, a negative error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_auto_grow_limit-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_auto_grow_limit","text":"av_fifo_auto_grow_limit(f, max_elems::Csize_t)\n\nSet the maximum size (in elements) to which the FIFO can be resized automatically. Has no effect unless AV_FIFO_FLAG_AUTO_GROW is used.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_can_read-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_can_read","text":"av_fifo_can_read(f)\n\nReturns\n\nnumber of elements available for reading from the given FIFO.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_can_write-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_can_write","text":"av_fifo_can_write(f)\n\nIn other words, this number of elements or less is guaranteed to fit into the FIFO. More data may be written when the AV_FIFO_FLAG_AUTO_GROW flag was specified at FIFO creation, but this may involve memory allocation, which can fail.\n\nReturns\n\nNumber of elements that can be written into the given FIFO without growing it.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_drain2-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_drain2","text":"av_fifo_drain2(f, size::Csize_t)\n\nDiscard the specified amount of data from an AVFifo.\n\nArguments\n\nsize: number of elements to discard, MUST NOT be larger than av_fifo_can_read(f)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_elem_size-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_elem_size","text":"av_fifo_elem_size(f)\n\nReturns\n\nElement size for FIFO operations. This element size is set at FIFO allocation and remains constant during its lifetime\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_freep2-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_freep2","text":"av_fifo_freep2(f)\n\nFree an AVFifo and reset pointer to NULL.\n\nArguments\n\nf: Pointer to an AVFifo to free. *f == NULL is allowed.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_grow2-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_grow2","text":"av_fifo_grow2(f, inc::Csize_t)\n\nEnlarge an AVFifo.\n\nOn success, the FIFO will be large enough to hold exactly inc + av_fifo_can_read() + av_fifo_can_write() elements. In case of failure, the old FIFO is kept unchanged.\n\nArguments\n\nf: AVFifo to resize\ninc: number of elements to allocate for, in addition to the current allocated size\n\nReturns\n\na non-negative number on success, a negative error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_peek-Tuple{Any, Any, UInt64, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_peek","text":"av_fifo_peek(f, buf, nb_elems::Csize_t, offset::Csize_t)\n\nRead data from a FIFO without modifying FIFO state.\n\nReturns an error if an attempt is made to peek to nonexistent elements (i.e. if offset + nb_elems is larger than av_fifo_can_read(f)).\n\nArguments\n\nf: the FIFO buffer\nbuf: Buffer to store the data. nb_elems * av_fifo_elem_size(f) bytes will be written into buf.\nnb_elems: number of elements to read from FIFO\noffset: number of initial elements to skip.\n\nReturns\n\na non-negative number on success, a negative error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_peek_to_cb-Tuple{Any, Nothing, Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_peek_to_cb","text":"av_fifo_peek_to_cb(f, write_cb::AVFifoCB, opaque, nb_elems, offset::Csize_t)\n\nFeed data from a FIFO into a user-provided callback.\n\nArguments\n\nf: the FIFO buffer\nwrite_cb: Callback the data will be supplied to. May be called multiple times.\nopaque: opaque user data to be provided to write_cb\nnb_elems: Should point to the maximum number of elements that can be read. Will be updated to contain the total number of elements actually sent to the callback.\noffset: number of initial elements to skip; offset + *nb_elems must not be larger than av_fifo_can_read(f).\n\nReturns\n\na non-negative number on success, a negative error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_read-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_read","text":"av_fifo_read(f, buf, nb_elems::Csize_t)\n\nRead data from a FIFO.\n\nIn case nb_elems > av_fifo_can_read(f), nothing is read and an error is returned.\n\nArguments\n\nf: the FIFO buffer\nbuf: Buffer to store the data. nb_elems * av_fifo_elem_size(f) bytes will be written into buf on success.\nnb_elems: number of elements to read from FIFO\n\nReturns\n\na non-negative number on success, a negative error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_read_to_cb-Tuple{Any, Nothing, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_read_to_cb","text":"av_fifo_read_to_cb(f, write_cb::AVFifoCB, opaque, nb_elems)\n\nFeed data from a FIFO into a user-provided callback.\n\nArguments\n\nf: the FIFO buffer\nwrite_cb: Callback the data will be supplied to. May be called multiple times.\nopaque: opaque user data to be provided to write_cb\nnb_elems: Should point to the maximum number of elements that can be read. Will be updated to contain the total number of elements actually sent to the callback.\n\nReturns\n\nnon-negative number on success, a negative error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_write-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_write","text":"av_fifo_write(f, buf, nb_elems::Csize_t)\n\nWrite data into a FIFO.\n\nIn case nb_elems > av_fifo_can_write(f) and the AV_FIFO_FLAG_AUTO_GROW flag was not specified at FIFO creation, nothing is written and an error is returned.\n\nCalling function is guaranteed to succeed if nb_elems <= av_fifo_can_write(f).\n\nArguments\n\nf: the FIFO buffer\nbuf: Data to be written. nb_elems * av_fifo_elem_size(f) bytes will be read from buf on success.\nnb_elems: number of elements to write into FIFO\n\nReturns\n\na non-negative number on success, a negative error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fifo_write_from_cb-Tuple{Any, Nothing, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fifo_write_from_cb","text":"av_fifo_write_from_cb(f, read_cb::AVFifoCB, opaque, nb_elems)\n\nWrite data from a user-provided callback into a FIFO.\n\nArguments\n\nf: the FIFO buffer\nread_cb: Callback supplying the data to the FIFO. May be called multiple times.\nopaque: opaque user data to be provided to read_cb\nnb_elems: Should point to the maximum number of elements that can be written. Will be updated to contain the number of elements actually written.\n\nReturns\n\nnon-negative number on success, a negative error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_file_map-Tuple{Any, Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_file_map","text":"av_file_map(filename, bufptr, size, log_offset::Integer, log_ctx)\n\nRead the file with name filename, and put its content in a newly allocated buffer or map it with mmap() when available. In case of success set *bufptr to the read or mmapped buffer, and *size to the size in bytes of the buffer in *bufptr. Unlike mmap this function succeeds with zero sized files, in this case *bufptr will be set to NULL and *size will be set to 0. The returned buffer must be released with av_file_unmap().\n\nArguments\n\nfilename: path to the file\nbufptr:[out] pointee is set to the mapped or allocated buffer\nsize:[out] pointee is set to the size in bytes of the buffer\nlog_offset: loglevel offset used for logging\nlog_ctx: context used for logging\n\nReturns\n\na non negative number in case of success, a negative value corresponding to an AVERROR error code in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_file_unmap-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_file_unmap","text":"av_file_unmap(bufptr, size::Csize_t)\n\nUnmap or free the buffer bufptr created by av_file_map().\n\nArguments\n\nbufptr: the buffer previously created with av_file_map()\nsize: size in bytes of bufptr, must be the same as returned by av_file_map()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_filename_number_test-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_filename_number_test","text":"av_filename_number_test(filename)\n\nCheck whether filename actually is a numbered sequence generator.\n\nArguments\n\nfilename: possible numbered sequence string\n\nReturns\n\n1 if a valid numbered sequence string, 0 otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_film_grain_params_alloc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_film_grain_params_alloc","text":"av_film_grain_params_alloc(size)\n\nAllocate an AVFilmGrainParams structure and set its fields to default values. The resulting struct can be freed using av_freep(). If size is not NULL it will be set to the number of bytes allocated.\n\nReturns\n\nAn AVFilmGrainParams filled with default values or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_film_grain_params_create_side_data-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_film_grain_params_create_side_data","text":"av_film_grain_params_create_side_data(frame)\n\nAllocate a complete AVFilmGrainParams and add it to the frame.\n\nArguments\n\nframe: The frame which side data is added to.\n\nReturns\n\nThe AVFilmGrainParams structure to be filled by caller.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_film_grain_params_select-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_film_grain_params_select","text":"av_film_grain_params_select(frame)\n\nSelect the most appropriate film grain parameters set for the frame, taking into account the frame's format, resolution and video signal characteristics.\n\nnote: Note\n, for H.274, this may select a film grain parameter set with greater chroma resolution than the frame. Users should take care to correctly adjust the chroma grain frequency to the frame.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_filter_iterate-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_filter_iterate","text":"av_filter_iterate(opaque)\n\nIterate over all registered filters.\n\nArguments\n\nopaque: a pointer where libavfilter will store the iteration state. Must point to NULL to start the iteration.\n\nReturns\n\nthe next registered filter or NULL when the iteration is finished\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_find_best_pix_fmt_of_2-Tuple{Int32, Int32, Int32, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_find_best_pix_fmt_of_2","text":"av_find_best_pix_fmt_of_2(dst_pix_fmt1::AVPixelFormat, dst_pix_fmt2::AVPixelFormat, src_pix_fmt::AVPixelFormat, has_alpha::Integer, loss_ptr)\n\nCompute what kind of losses will occur when converting from one specific pixel format to another. When converting from one pixel format to another, information loss may occur. For example, when converting from RGB24 to GRAY, the color information will be lost. Similarly, other losses occur when converting from some formats to other formats. These losses can involve loss of chroma, but also loss of resolution, loss of color depth, loss due to the color space conversion, loss of the alpha bits or loss due to color quantization. av_get_fix_fmt_loss() informs you about the various types of losses which will occur when converting from one pixel format to another.\n\nArguments\n\ndst_pix_fmt:[in] destination pixel format\nsrc_pix_fmt:[in] source pixel format\nhas_alpha:[in] Whether the source pixel format alpha channel is used.\n\nReturns\n\nCombination of flags informing you what kind of losses will occur (maximum loss for an invalid dst_pix_fmt).\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_find_best_stream-Tuple{Any, Int32, Integer, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_find_best_stream","text":"av_find_best_stream(ic, type::AVMediaType, wanted_stream_nb::Integer, related_stream::Integer, decoder_ret, flags::Integer)\n\nFind the \"best\" stream in the file. The best stream is determined according to various heuristics as the most likely to be what the user expects. If the decoder parameter is non-NULL, av_find_best_stream will find the default decoder for the stream's codec; streams for which no decoder can be found are ignored.\n\nnote: Note\nIf av_find_best_stream returns successfully and decoder_ret is not NULL, then *decoder_ret is guaranteed to be set to a valid AVCodec.\n\nArguments\n\nic: media file handle\ntype: stream type: video, audio, subtitles, etc.\nwanted_stream_nb: user-requested stream number, or -1 for automatic selection\nrelated_stream: try to find a stream related (eg. in the same program) to this one, or -1 if none\ndecoder_ret: if non-NULL, returns the decoder for the selected stream\nflags: flags; none are currently defined\n\nReturns\n\nthe non-negative stream number in case of success, AVERROR_STREAM_NOT_FOUND if no stream with the requested type could be found, AVERROR_DECODER_NOT_FOUND if streams were found but no decoder\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_find_info_tag-Tuple{Any, Integer, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_find_info_tag","text":"av_find_info_tag(arg, arg_size::Integer, tag1, info)\n\nAttempt to find a specific tag in a URL.\n\nsyntax: '?tag1=val1&tag2=val2...'. Little URL decoding is done. Return 1 if found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_find_input_format-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_find_input_format","text":"av_find_input_format(short_name)\n\nFind AVInputFormat based on the short name of the input format.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_find_nearest_q_idx-Tuple{VideoIO.libffmpeg.AVRational, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_find_nearest_q_idx","text":"av_find_nearest_q_idx(q::AVRational, q_list)\n\nFind the value in a list of rationals nearest a given reference rational.\n\nArguments\n\nq: Reference rational\nq_list: Array of rationals terminated by {0, 0}\n\nReturns\n\nIndex of the nearest value found in the array\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_find_program_from_stream-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_find_program_from_stream","text":"av_find_program_from_stream(ic, last, s::Integer)\n\nFind the programs which belong to a given stream.\n\nArguments\n\nic: media file handle\nlast: the last found program, the search will start after this program, or from the beginning if it is NULL\ns: stream index\n\nReturns\n\nthe next program which belongs to s, NULL if no program is found or the last program is not among the programs of ic.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_float2int-Tuple{Float32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_float2int","text":"av_float2int(f::Cfloat)\n\nReinterpret a float as a 32-bit integer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_force_cpu_flags-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_force_cpu_flags","text":"av_force_cpu_flags(flags::Integer)\n\nDisables cpu detection and forces the specified flags. -1 is a special case that disables forcing of specific flags.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_fourcc_make_string-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_fourcc_make_string","text":"av_fourcc_make_string(buf, fourcc::Integer)\n\nFill the provided buffer with a string containing a FourCC (four-character code) representation.\n\nArguments\n\nbuf: a buffer with size in bytes of at least AV_FOURCC_MAX_STRING_SIZE\nfourcc: the fourcc to represent\n\nReturns\n\nthe buffer in input\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_alloc","text":"av_frame_alloc()\n\nAllocate an AVFrame and set its fields to default values. The resulting struct must be freed using av_frame_free().\n\nnote: Note\nthis only allocates the AVFrame itself, not the data buffers. Those must be allocated through other means, e.g. with av_frame_get_buffer() or manually.\n\nReturns\n\nAn AVFrame filled with default values or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_apply_cropping-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_apply_cropping","text":"av_frame_apply_cropping(frame, flags::Integer)\n\nCrop the given video AVFrame according to its crop_left/crop_top/crop_right/ crop_bottom fields. If cropping is successful, the function will adjust the data pointers and the width/height fields, and set the crop fields to 0.\n\nIn all cases, the cropping boundaries will be rounded to the inherent alignment of the pixel format. In some cases, such as for opaque hwaccel formats, the left/top cropping is ignored. The crop fields are set to 0 even if the cropping was rounded or ignored.\n\nArguments\n\nframe: the frame which should be cropped\nflags: Some combination of AV_FRAME_CROP_* flags, or 0.\n\nReturns\n\n= 0 on success, a negative AVERROR on error. If the cropping fields were invalid, AVERROR(ERANGE) is returned, and nothing is changed.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_clone-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_clone","text":"av_frame_clone(src)\n\nCreate a new frame that references the same data as src.\n\nThis is a shortcut for av_frame_alloc()+av_frame_ref().\n\nReturns\n\nnewly created AVFrame on success, NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_copy-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_copy","text":"av_frame_copy(dst, src)\n\nCopy the frame data from src to dst.\n\nThis function does not allocate anything, dst must be already initialized and allocated with the same parameters as src.\n\nThis function only copies the frame data (i.e. the contents of the data / extended data arrays), not any other properties.\n\nReturns\n\n= 0 on success, a negative AVERROR on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_copy_props-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_copy_props","text":"av_frame_copy_props(dst, src)\n\nCopy only \"metadata\" fields from src to dst.\n\nMetadata for the purpose of this function are those fields that do not affect the data layout in the buffers. E.g. pts, sample rate (for audio) or sample aspect ratio (for video), but not width/height or channel layout. Side data is also copied.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_free","text":"av_frame_free(frame)\n\nFree the frame and any dynamically allocated objects in it, e.g. extended_data. If the frame is reference counted, it will be unreferenced first.\n\nArguments\n\nframe: frame to be freed. The pointer will be set to NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_get_buffer-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_get_buffer","text":"av_frame_get_buffer(frame, align::Integer)\n\nAllocate new buffer(s) for audio or video data.\n\nThe following fields must be set on frame before calling this function: - format (pixel format for video, sample format for audio) - width and height for video - nb_samples and ch_layout for audio\n\nThis function will fill AVFrame.data and AVFrame.buf arrays and, if necessary, allocate and fill AVFrame.extended_data and AVFrame.extended_buf. For planar formats, one buffer will be allocated for each plane.\n\nwarning: Warning\n: if frame already has been allocated, calling this function will leak memory. In addition, undefined behavior can occur in certain cases.\n\nArguments\n\nframe: frame in which to store the new buffers.\nalign: Required buffer size and data pointer alignment. If equal to 0, alignment will be chosen automatically for the current CPU. It is highly recommended to pass 0 here unless you know what you are doing.\n\nReturns\n\n0 on success, a negative AVERROR on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_get_plane_buffer-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_get_plane_buffer","text":"av_frame_get_plane_buffer(frame, plane::Integer)\n\nGet the buffer reference a given data plane is stored in.\n\nArguments\n\nframe: the frame to get the plane's buffer from\nplane: index of the data plane of interest in frame->extended_data.\n\nReturns\n\nthe buffer reference that contains the plane or NULL if the input frame is not valid.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_get_side_data-Tuple{Any, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_get_side_data","text":"av_frame_get_side_data(frame, type::AVFrameSideDataType)\n\nReturns\n\na pointer to the side data of a given type on success, NULL if there is no side data with such type in this frame.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_is_writable-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_is_writable","text":"av_frame_is_writable(frame)\n\nCheck if the frame data is writable.\n\nIf 1 is returned the answer is valid until av_buffer_ref() is called on any of the underlying AVBufferRefs (e.g. through av_frame_ref() or directly).\n\nReturns\n\nA positive value if the frame data is writable (which is true if and only if each of the underlying buffers has only one reference, namely the one stored in this frame). Return 0 otherwise.\n\nSee also\n\nav_frame_make_writable(), av_buffer_is_writable()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_make_writable-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_make_writable","text":"av_frame_make_writable(frame)\n\nEnsure that the frame data is writable, avoiding data copy if possible.\n\nDo nothing if the frame is writable, allocate new buffers and copy the data if it is not. Non-refcounted frames behave as non-writable, i.e. a copy is always made.\n\nReturns\n\n0 on success, a negative AVERROR on error.\n\nSee also\n\nav_frame_is_writable(), av_buffer_is_writable(), av_buffer_make_writable()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_move_ref-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_move_ref","text":"av_frame_move_ref(dst, src)\n\nMove everything contained in src to dst and reset src.\n\nwarning: Warning\n: dst is not unreferenced, but directly overwritten without reading or deallocating its contents. Call av_frame_unref(dst) manually before calling this function to ensure that no memory is leaked.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_new_side_data-Tuple{Any, UInt32, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_new_side_data","text":"av_frame_new_side_data(frame, type::AVFrameSideDataType, size::Csize_t)\n\nAdd a new side data to a frame.\n\nArguments\n\nframe: a frame to which the side data should be added\ntype: type of the added side data\nsize: size of the side data\n\nReturns\n\nnewly added side data on success, NULL on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_new_side_data_from_buf-Tuple{Any, UInt32, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_new_side_data_from_buf","text":"av_frame_new_side_data_from_buf(frame, type::AVFrameSideDataType, buf)\n\nAdd a new side data to a frame from an existing AVBufferRef\n\nArguments\n\nframe: a frame to which the side data should be added\ntype: the type of the added side data\nbuf: an AVBufferRef to add as side data. The ownership of the reference is transferred to the frame.\n\nReturns\n\nnewly added side data on success, NULL on error. On failure the frame is unchanged and the AVBufferRef remains owned by the caller.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_ref-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_ref","text":"av_frame_ref(dst, src)\n\nSet up a new reference to the data described by the source frame.\n\nCopy frame properties from src to dst and create a new reference for each AVBufferRef from src.\n\nIf src is not reference counted, new buffers are allocated and the data is copied.\n\nwarning: Warning\n: dst MUST have been either unreferenced with av_frame_unref(dst), or newly allocated with av_frame_alloc() before calling this function, or undefined behavior will occur.\n\nReturns\n\n0 on success, a negative AVERROR on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_remove_side_data-Tuple{Any, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_remove_side_data","text":"av_frame_remove_side_data(frame, type::AVFrameSideDataType)\n\nRemove and free all side data instances of the given type.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_replace-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_replace","text":"av_frame_replace(dst, src)\n\nEnsure the destination frame refers to the same data described by the source frame, either by creating a new reference for each AVBufferRef from src if they differ from those in dst, by allocating new buffers and copying data if src is not reference counted, or by unrefencing it if src is empty.\n\nFrame properties on dst will be replaced by those from src.\n\nReturns\n\n0 on success, a negative AVERROR on error. On error, dst is unreferenced.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_side_data_add-Tuple{Any, Any, UInt32, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_side_data_add","text":"av_frame_side_data_add(sd, nb_sd, type::AVFrameSideDataType, buf, flags::Integer)\n\nAdd a new side data entry to an array from an existing AVBufferRef.\n\nnote: Note\nIn case of AV_FRAME_SIDE_DATA_FLAG_UNIQUE being set, entries of matching AVFrameSideDataType will be removed before the addition is attempted.\n\nnote: Note\nIn case of AV_FRAME_SIDE_DATA_FLAG_REPLACE being set, if an entry of the same type already exists, it will be replaced instead.\n\nArguments\n\nsd: pointer to array of side data to which to add another entry, or to NULL in order to start a new array.\nnb_sd: pointer to an integer containing the number of entries in the array.\ntype: type of the added side data\nbuf: Pointer to AVBufferRef to add to the array. On success, the function takes ownership of the AVBufferRef and *buf is set to NULL, unless AV_FRAME_SIDE_DATA_FLAG_NEW_REF is set in which case the ownership will remain with the caller.\nflags: Some combination of AV_FRAME_SIDE_DATA_FLAG_* flags, or 0.\n\nReturns\n\nnewly added side data on success, NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_side_data_clone-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_side_data_clone","text":"av_frame_side_data_clone(sd, nb_sd, src, flags::Integer)\n\nAdd a new side data entry to an array based on existing side data, taking a reference towards the contained AVBufferRef.\n\nnote: Note\nIn case of AV_FRAME_SIDE_DATA_FLAG_UNIQUE being set, entries of matching AVFrameSideDataType will be removed before the addition is attempted.\n\nnote: Note\nIn case of AV_FRAME_SIDE_DATA_FLAG_REPLACE being set, if an entry of the same type already exists, it will be replaced instead.\n\nArguments\n\nsd: pointer to array of side data to which to add another entry, or to NULL in order to start a new array.\nnb_sd: pointer to an integer containing the number of entries in the array.\nsrc: side data to be cloned, with a new reference utilized for the buffer.\nflags: Some combination of AV_FRAME_SIDE_DATA_FLAG_* flags, or 0.\n\nReturns\n\nnegative error code on failure, >=0 on success.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_side_data_desc-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_side_data_desc","text":"av_frame_side_data_desc(type::AVFrameSideDataType)\n\nReturns\n\nside data descriptor corresponding to a given side data type, NULL when not available.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_side_data_free-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_side_data_free","text":"av_frame_side_data_free(sd, nb_sd)\n\nFree all side data entries and their contents, then zeroes out the values which the pointers are pointing to.\n\nArguments\n\nsd: pointer to array of side data to free. Will be set to NULL upon return.\nnb_sd: pointer to an integer containing the number of entries in the array. Will be set to 0 upon return.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_side_data_get-Tuple{Any, Integer, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_side_data_get","text":"av_frame_side_data_get(sd, nb_sd::Integer, type::AVFrameSideDataType)\n\nWrapper around av_frame_side_data_get_c() to workaround the limitation that for any type T the conversion from T * const * to const T * const * is not performed automatically in C.\n\nSee also\n\nav_frame_side_data_get_c()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_side_data_get_c-Tuple{Any, Integer, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_side_data_get_c","text":"av_frame_side_data_get_c(sd, nb_sd::Integer, type::AVFrameSideDataType)\n\nGet a side data entry of a specific type from an array.\n\nArguments\n\nsd: array of side data.\nnb_sd: integer containing the number of entries in the array.\ntype: type of side data to be queried\n\nReturns\n\na pointer to the side data of a given type on success, NULL if there is no side data with such type in this set.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_side_data_name-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_side_data_name","text":"av_frame_side_data_name(type::AVFrameSideDataType)\n\nReturns\n\na string identifying the side data type\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_side_data_new-Tuple{Any, Any, UInt32, UInt64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_side_data_new","text":"av_frame_side_data_new(sd, nb_sd, type::AVFrameSideDataType, size::Csize_t, flags::Integer)\n\nAdd new side data entry to an array.\n\nnote: Note\nIn case of AV_FRAME_SIDE_DATA_FLAG_UNIQUE being set, entries of matching AVFrameSideDataType will be removed before the addition is attempted.\n\nnote: Note\nIn case of AV_FRAME_SIDE_DATA_FLAG_REPLACE being set, if an entry of the same type already exists, it will be replaced instead.\n\nArguments\n\nsd: pointer to array of side data to which to add another entry, or to NULL in order to start a new array.\nnb_sd: pointer to an integer containing the number of entries in the array.\ntype: type of the added side data\nsize: size of the side data\nflags: Some combination of AV_FRAME_SIDE_DATA_FLAG_* flags, or 0.\n\nReturns\n\nnewly added side data on success, NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_side_data_remove-Tuple{Any, Any, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_side_data_remove","text":"av_frame_side_data_remove(sd, nb_sd, type::AVFrameSideDataType)\n\nRemove and free all side data instances of the given type from an array.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_side_data_remove_by_props-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_side_data_remove_by_props","text":"av_frame_side_data_remove_by_props(sd, nb_sd, props::Integer)\n\nRemove and free all side data instances that match any of the given side data properties. (See enum AVSideDataProps)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_frame_unref-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_frame_unref","text":"av_frame_unref(frame)\n\nUnreference all the buffers referenced by frame and reset the frame fields.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_free","text":"av_free(ptr)\n\nFree a memory block which has been allocated with a function of av_malloc() or av_realloc() family.\n\nnote: Note\nptr = NULL is explicitly allowed.\n\nnote: Note\nIt is recommended that you use av_freep() instead, to prevent leaving behind dangling pointers.\n\nArguments\n\nptr: Pointer to the memory block which should be freed.\n\nSee also\n\nav_freep()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_freep-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_freep","text":"av_freep(ptr)\n\nFree a memory block which has been allocated with a function of av_malloc() or av_realloc() family, and set the pointer pointing to it to NULL.\n\n{.c}\n uint8_t *buf = av_malloc(16);\n av_free(buf);\n // buf now contains a dangling pointer to freed memory, and accidental\n // dereference of buf will result in a use-after-free, which may be a\n // security risk.\n\n uint8_t *buf = av_malloc(16);\n av_freep(&buf);\n // buf is now NULL, and accidental dereference will only result in a\n // NULL-pointer dereference.\n\nnote: Note\n*ptr = NULL is safe and leads to no action.\n\nArguments\n\nptr: Pointer to the pointer to the memory block which should be freed\n\nSee also\n\nav_free()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_gcd-Tuple{Int64, Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_gcd","text":"av_gcd(a::Int64, b::Int64)\n\nCompute the greatest common divisor of two integer operands.\n\nArguments\n\na: Operand\nb: Operand\n\nReturns\n\nGCD of a and b up to sign; if a >= 0 and b >= 0, return value is >= 0; if a == 0 and b == 0, returns 0.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_gcd_q-Tuple{VideoIO.libffmpeg.AVRational, VideoIO.libffmpeg.AVRational, Integer, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_gcd_q","text":"av_gcd_q(a::AVRational, b::AVRational, max_den::Integer, def::AVRational)\n\nReturn the best rational so that a and b are multiple of it. If the resulting denominator is larger than max_den, return def.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_alt_sample_fmt-Tuple{Int32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_alt_sample_fmt","text":"av_get_alt_sample_fmt(sample_fmt::AVSampleFormat, planar::Integer)\n\nReturn the planar<->packed alternative form of the given sample format, or AV_SAMPLE_FMT_NONE on error. If the passed sample_fmt is already in the requested planar/packed format, the format returned is the same as the input.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_audio_frame_duration-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_audio_frame_duration","text":"av_get_audio_frame_duration(avctx, frame_bytes::Integer)\n\nReturn audio frame duration.\n\nArguments\n\navctx: codec context\nframe_bytes: size of the frame, or 0 if unknown\n\nReturns\n\nframe duration, in samples, if known. 0 if not able to determine.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_audio_frame_duration2-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_audio_frame_duration2","text":"av_get_audio_frame_duration2(par, frame_bytes::Integer)\n\nThis function is the same as av_get_audio_frame_duration(), except it works with AVCodecParameters instead of an AVCodecContext.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_bits_per_pixel-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_bits_per_pixel","text":"av_get_bits_per_pixel(pixdesc)\n\nReturn the number of bits per pixel used by the pixel format described by pixdesc. Note that this is not the same as the number of bits per sample.\n\nThe returned number of bits refers to the number of bits actually used for storing the pixel information, that is padding bits are not counted.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_bits_per_sample-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_bits_per_sample","text":"av_get_bits_per_sample(codec_id::AVCodecID)\n\nReturn codec bits per sample.\n\nArguments\n\ncodec_id:[in] the codec\n\nReturns\n\nNumber of bits per sample or zero if unknown for the given codec.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_bytes_per_sample-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_bytes_per_sample","text":"av_get_bytes_per_sample(sample_fmt::AVSampleFormat)\n\nReturn number of bytes per sample.\n\nArguments\n\nsample_fmt: the sample format\n\nReturns\n\nnumber of bytes per sample or zero if unknown for the given sample format\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_cpu_flags-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_cpu_flags","text":"av_get_cpu_flags()\n\nReturn the flags which specify extensions supported by the CPU. The returned value is affected by av_force_cpu_flags() if that was used before. So av_get_cpu_flags() can easily be used in an application to detect the enabled cpu flags.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_exact_bits_per_sample-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_exact_bits_per_sample","text":"av_get_exact_bits_per_sample(codec_id::AVCodecID)\n\nReturn codec bits per sample. Only return non-zero if the bits per sample is exactly correct, not an approximation.\n\nArguments\n\ncodec_id:[in] the codec\n\nReturns\n\nNumber of bits per sample or zero if unknown for the given codec.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_frame_filename2-Tuple{Any, Integer, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_frame_filename2","text":"av_get_frame_filename2(buf, buf_size::Integer, path, number::Integer, flags::Integer)\n\nReturn in 'buf' the path with 'd' replaced by a number.\n\nAlso handles the '0nd' format where 'n' is the total number of digits and '%%'.\n\nArguments\n\nbuf: destination buffer\nbuf_size: destination buffer size\npath: numbered sequence string\nnumber: frame number\nflags: AV_FRAME_FILENAME_FLAGS_*\n\nReturns\n\n0 if OK, -1 on format error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_known_color_name-Tuple{Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_known_color_name","text":"av_get_known_color_name(color_idx::Integer, rgb)\n\nGet the name of a color from the internal table of hard-coded named colors.\n\nThis function is meant to enumerate the color names recognized by av_parse_color().\n\nArguments\n\ncolor_idx: index of the requested color, starting from 0\nrgb: if not NULL, will point to a 3-elements array with the color value in RGB\n\nReturns\n\nthe color name string or NULL if color_idx is not in the array\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_media_type_string-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_media_type_string","text":"av_get_media_type_string(media_type::AVMediaType)\n\nReturn a string describing the media_type enum, NULL if media_type is unknown.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_output_timestamp-Tuple{Any, Integer, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_output_timestamp","text":"av_get_output_timestamp(s, stream::Integer, dts, wall)\n\nGet timing information for the data currently output. The exact meaning of \"currently output\" depends on the format. It is mostly relevant for devices that have an internal buffer and/or work in real time.\n\n\\retval0 Success\n\n\\retvalAVERROR(ENOSYS) The format does not support it\n\nnote: Note\nSome formats or devices may not allow to measure dts and wall atomically.\n\nArguments\n\ns: media file handle\nstream: stream in the media file\ndts:[out] DTS of the last packet output for the stream, in stream time_base units\nwall:[out] absolute time when that packet whas output, in microsecond\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_packed_sample_fmt-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_packed_sample_fmt","text":"av_get_packed_sample_fmt(sample_fmt::AVSampleFormat)\n\nGet the packed alternative form of the given sample format.\n\nIf the passed sample_fmt is already in packed format, the format returned is the same as the input.\n\nReturns\n\nthe packed alternative form of the given sample format or AV_SAMPLE_FMT_NONE on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_packet-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_packet","text":"av_get_packet(s, pkt, size::Integer)\n\nAllocate and read the payload of a packet and initialize its fields with default values.\n\nArguments\n\ns: associated IO context\npkt: packet\nsize: desired payload size\n\nReturns\n\n0 (read size) if OK, AVERROR_xxx otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_padded_bits_per_pixel-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_padded_bits_per_pixel","text":"av_get_padded_bits_per_pixel(pixdesc)\n\nReturn the number of bits per pixel for the pixel format described by pixdesc, including any padding or unused bits.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_pcm_codec-Tuple{Int32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_pcm_codec","text":"av_get_pcm_codec(fmt::AVSampleFormat, be::Integer)\n\nReturn the PCM codec associated with a sample format.\n\nArguments\n\nbe: endianness, 0 for little, 1 for big, -1 (or anything else) for native\n\nReturns\n\nAV_CODEC_ID_PCM_* or AV_CODEC_ID_NONE\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_picture_type_char-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_picture_type_char","text":"av_get_picture_type_char(pict_type::AVPictureType)\n\nReturn a single letter to describe the given picture type pict_type.\n\nArguments\n\npict_type:[in] the picture type\n\nReturns\n\na single character representing the picture type, '?' if pict_type is unknown\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_pix_fmt-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_pix_fmt","text":"av_get_pix_fmt(name)\n\nReturn the pixel format corresponding to name.\n\nIf there is no pixel format with name name, then looks for a pixel format with the name corresponding to the native endian format of name. For example in a little-endian system, first looks for \"gray16\", then for \"gray16le\".\n\nFinally if no pixel format has been found, returns AV_PIX_FMT_NONE.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_pix_fmt_loss-Tuple{Int32, Int32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_pix_fmt_loss","text":"av_get_pix_fmt_loss(dst_pix_fmt::AVPixelFormat, src_pix_fmt::AVPixelFormat, has_alpha::Integer)\n\nCompute what kind of losses will occur when converting from one specific pixel format to another. When converting from one pixel format to another, information loss may occur. For example, when converting from RGB24 to GRAY, the color information will be lost. Similarly, other losses occur when converting from some formats to other formats. These losses can involve loss of chroma, but also loss of resolution, loss of color depth, loss due to the color space conversion, loss of the alpha bits or loss due to color quantization. av_get_fix_fmt_loss() informs you about the various types of losses which will occur when converting from one pixel format to another.\n\nArguments\n\ndst_pix_fmt:[in] destination pixel format\nsrc_pix_fmt:[in] source pixel format\nhas_alpha:[in] Whether the source pixel format alpha channel is used.\n\nReturns\n\nCombination of flags informing you what kind of losses will occur (maximum loss for an invalid dst_pix_fmt).\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_pix_fmt_name-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_pix_fmt_name","text":"av_get_pix_fmt_name(pix_fmt::AVPixelFormat)\n\nReturn the short name for a pixel format, NULL in case pix_fmt is unknown.\n\nSee also\n\nav_get_pix_fmt(), av_get_pix_fmt_string()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_pix_fmt_string-Tuple{Any, Integer, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_pix_fmt_string","text":"av_get_pix_fmt_string(buf, buf_size::Integer, pix_fmt::AVPixelFormat)\n\nPrint in buf the string corresponding to the pixel format with number pix_fmt, or a header if pix_fmt is negative.\n\nArguments\n\nbuf: the buffer where to write the string\nbuf_size: the size of buf\npix_fmt: the number of the pixel format to print the corresponding info string, or a negative value to print the corresponding header.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_planar_sample_fmt-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_planar_sample_fmt","text":"av_get_planar_sample_fmt(sample_fmt::AVSampleFormat)\n\nGet the planar alternative form of the given sample format.\n\nIf the passed sample_fmt is already in planar format, the format returned is the same as the input.\n\nReturns\n\nthe planar alternative form of the given sample format or AV_SAMPLE_FMT_NONE on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_profile_name-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_profile_name","text":"av_get_profile_name(codec, profile::Integer)\n\nReturn a name for the specified profile, if available.\n\nArguments\n\ncodec: the codec that is searched for the given profile\nprofile: the profile value for which a name is requested\n\nReturns\n\nA name for the profile if found, NULL otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_random_seed-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_random_seed","text":"av_get_random_seed()\n\nGet a seed to use in conjunction with random functions. This function tries to provide a good seed at a best effort bases. Its possible to call this function multiple times if more bits are needed. It can be quite slow, which is why it should only be used as seed for a faster PRNG. The quality of the seed depends on the platform.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_sample_fmt-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_sample_fmt","text":"av_get_sample_fmt(name)\n\nReturn a sample format corresponding to name, or AV_SAMPLE_FMT_NONE on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_sample_fmt_name-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_sample_fmt_name","text":"av_get_sample_fmt_name(sample_fmt::AVSampleFormat)\n\nReturn the name of sample_fmt, or NULL if sample_fmt is not recognized.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_sample_fmt_string-Tuple{Any, Integer, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_sample_fmt_string","text":"av_get_sample_fmt_string(buf, buf_size::Integer, sample_fmt::AVSampleFormat)\n\nGenerate a string corresponding to the sample format with sample_fmt, or a header if sample_fmt is negative.\n\nArguments\n\nbuf: the buffer where to write the string\nbuf_size: the size of buf\nsample_fmt: the number of the sample format to print the corresponding info string, or a negative value to print the corresponding header.\n\nReturns\n\nthe pointer to the filled buffer or NULL if sample_fmt is unknown or in case of other errors\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_time_base_q-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_time_base_q","text":"av_get_time_base_q()\n\nReturn the fractional representation of the internal time base.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_get_token-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_get_token","text":"av_get_token(buf, term)\n\nUnescape the given string until a non escaped terminating char, and return the token corresponding to the unescaped string.\n\nThe normal \\ and ' escaping is supported. Leading and trailing whitespaces are removed, unless they are escaped with '\\' or are enclosed between ''.\n\nArguments\n\nbuf: the buffer to parse, buf will be updated to point to the terminating char\nterm: a 0-terminated list of terminating chars\n\nReturns\n\nthe malloced unescaped string, which must be av_freed by the user, NULL in case of allocation failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_gettime-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_gettime","text":"av_gettime()\n\nGet the current time in microseconds.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_gettime_relative-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_gettime_relative","text":"av_gettime_relative()\n\nGet the current time in microseconds since some unspecified starting point. On platforms that support it, the time comes from a monotonic clock This property makes this time source ideal for measuring relative time. The returned values may not be monotonic on platforms where a monotonic clock is not available.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_gettime_relative_is_monotonic-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_gettime_relative_is_monotonic","text":"av_gettime_relative_is_monotonic()\n\nIndicates with a boolean result if the av_gettime_relative() time source is monotonic.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_grow_packet-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_grow_packet","text":"av_grow_packet(pkt, grow_by::Integer)\n\nIncrease packet size, correctly zeroing padding\n\nArguments\n\npkt: packet\ngrow_by: number of bytes by which to increase the size of the packet\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_guess_codec-Tuple{Any, Any, Any, Any, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_guess_codec","text":"av_guess_codec(fmt, short_name, filename, mime_type, type::AVMediaType)\n\nGuess the codec ID based upon muxer and filename.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_guess_format-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_guess_format","text":"av_guess_format(short_name, filename, mime_type)\n\nReturn the output format in the list of registered output formats which best matches the provided parameters, or return NULL if there is no match.\n\nArguments\n\nshort_name: if non-NULL checks if short_name matches with the names of the registered formats\nfilename: if non-NULL checks if filename terminates with the extensions of the registered formats\nmime_type: if non-NULL checks if mime_type matches with the MIME type of the registered formats\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_guess_frame_rate-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_guess_frame_rate","text":"av_guess_frame_rate(ctx, stream, frame)\n\nGuess the frame rate, based on both the container and codec information.\n\nArguments\n\nctx: the format context which the stream is part of\nstream: the stream which the frame is part of\nframe: the frame for which the frame rate should be determined, may be NULL\n\nReturns\n\nthe guessed (valid) frame rate, 0/1 if no idea\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_guess_sample_aspect_ratio-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_guess_sample_aspect_ratio","text":"av_guess_sample_aspect_ratio(format, stream, frame)\n\nGuess the sample aspect ratio of a frame, based on both the stream and the frame aspect ratio.\n\nSince the frame aspect ratio is set by the codec but the stream aspect ratio is set by the demuxer, these two may not be equal. This function tries to return the value that you should use if you would like to display the frame.\n\nBasic logic is to use the stream aspect ratio if it is set to something sane otherwise use the frame aspect ratio. This way a container setting, which is usually easy to modify can override the coded value in the frames.\n\nArguments\n\nformat: the format context which the stream is part of\nstream: the stream which the frame is part of\nframe: the frame with the aspect ratio to be determined\n\nReturns\n\nthe guessed (valid) sample_aspect_ratio, 0/1 if no idea\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hash_alloc-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hash_alloc","text":"av_hash_alloc(ctx, name)\n\nAllocate a hash context for the algorithm specified by name.\n\nnote: Note\nThe context is not initialized after a call to this function; you must call av_hash_init() to do so.\n\nReturns\n\n= 0 for success, a negative error code for failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hash_final-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hash_final","text":"av_hash_final(ctx, dst)\n\nFinalize a hash context and compute the actual hash value.\n\nThe minimum size of dst buffer is given by av_hash_get_size() or #AV_HASH_MAX_SIZE. The use of the latter macro is discouraged.\n\nIt is not safe to update or finalize a hash context again, if it has already been finalized.\n\nArguments\n\nctx:[in,out] Hash context\ndst:[out] Where the final hash value will be stored\n\nSee also\n\nav_hash_final_bin() provides an alternative API\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hash_final_b64-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hash_final_b64","text":"av_hash_final_b64(ctx, dst, size::Integer)\n\nFinalize a hash context and store the Base64 representation of the actual hash value as a string.\n\nIt is not safe to update or finalize a hash context again, if it has already been finalized.\n\nThe string is always 0-terminated.\n\nIf size is smaller than AV_BASE64_SIZE(hash_size), where hash_size is the value returned by av_hash_get_size(), the string will be truncated.\n\nArguments\n\nctx:[in,out] Hash context\ndst:[out] Where the final hash value will be stored\nsize:[in] Maximum number of bytes to write to dst\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hash_final_bin-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hash_final_bin","text":"av_hash_final_bin(ctx, dst, size::Integer)\n\nFinalize a hash context and store the actual hash value in a buffer.\n\nIt is not safe to update or finalize a hash context again, if it has already been finalized.\n\nIf size is smaller than the hash size (given by av_hash_get_size()), the hash is truncated; if size is larger, the buffer is padded with 0.\n\nArguments\n\nctx:[in,out] Hash context\ndst:[out] Where the final hash value will be stored\nsize:[in] Number of bytes to write to dst\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hash_final_hex-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hash_final_hex","text":"av_hash_final_hex(ctx, dst, size::Integer)\n\nFinalize a hash context and store the hexadecimal representation of the actual hash value as a string.\n\nIt is not safe to update or finalize a hash context again, if it has already been finalized.\n\nThe string is always 0-terminated.\n\nIf size is smaller than 2 * hash\\_size + 1, where hash_size is the value returned by av_hash_get_size(), the string will be truncated.\n\nArguments\n\nctx:[in,out] Hash context\ndst:[out] Where the string will be stored\nsize:[in] Maximum number of bytes to write to dst\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hash_freep-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hash_freep","text":"av_hash_freep(ctx)\n\nFree hash context and set hash context pointer to NULL.\n\nArguments\n\nctx:[in,out] Pointer to hash context\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hash_get_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hash_get_name","text":"av_hash_get_name(ctx)\n\nGet the name of the algorithm corresponding to the given hash context.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hash_get_size-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hash_get_size","text":"av_hash_get_size(ctx)\n\nGet the size of the resulting hash value in bytes.\n\nThe maximum value this function will currently return is available as macro #AV_HASH_MAX_SIZE.\n\nArguments\n\nctx:[in] Hash context\n\nReturns\n\nSize of the hash value in bytes\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hash_init-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hash_init","text":"av_hash_init(ctx)\n\nInitialize or reset a hash context.\n\nArguments\n\nctx:[in,out] Hash context\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hash_names-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hash_names","text":"av_hash_names(i::Integer)\n\nGet the names of available hash algorithms.\n\nThis function can be used to enumerate the algorithms.\n\nArguments\n\ni:[in] Index of the hash algorithm, starting from 0\n\nReturns\n\nPointer to a static string or NULL if i is out of range\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hash_update-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hash_update","text":"av_hash_update(ctx, src, len::Csize_t)\n\nUpdate a hash context with additional data.\n\nArguments\n\nctx:[in,out] Hash context\nsrc:[in] Data to be added to the hash context\nlen:[in] Size of the additional data\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hex_dump-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hex_dump","text":"av_hex_dump(f, buf, size::Integer)\n\nSend a nice hexadecimal dump of a buffer to the specified file stream.\n\nArguments\n\nf: The file stream pointer where the dump should be sent to.\nbuf: buffer\nsize: buffer size\n\nSee also\n\nav_hex_dump_log, av_pkt_dump2, av_pkt_dump_log2\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hex_dump_log-Tuple{Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hex_dump_log","text":"av_hex_dump_log(avcl, level::Integer, buf, size::Integer)\n\nSend a nice hexadecimal dump of a buffer to the log.\n\nArguments\n\navcl: A pointer to an arbitrary struct of which the first field is a pointer to an AVClass struct.\nlevel: The importance level of the message, lower values signifying higher importance.\nbuf: buffer\nsize: buffer size\n\nSee also\n\nav_hex_dump, av_pkt_dump2, av_pkt_dump_log2\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hmac_alloc-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hmac_alloc","text":"av_hmac_alloc(type::AVHMACType)\n\nAllocate an AVHMAC context.\n\nArguments\n\ntype: The hash function used for the HMAC.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hmac_calc-Tuple{Any, Any, Integer, Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hmac_calc","text":"av_hmac_calc(ctx, data, len::Integer, key, keylen::Integer, out, outlen::Integer)\n\nHash an array of data with a key.\n\nArguments\n\nctx: The HMAC context\ndata: The data to hash\nlen: The length of the data, in bytes\nkey: The authentication key\nkeylen: The length of the key, in bytes\nout: The output buffer to write the digest into\noutlen: The length of the out buffer, in bytes\n\nReturns\n\nThe number of bytes written to out, or a negative error code.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hmac_final-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hmac_final","text":"av_hmac_final(ctx, out, outlen::Integer)\n\nFinish hashing and output the HMAC digest.\n\nArguments\n\nctx: The HMAC context\nout: The output buffer to write the digest into\noutlen: The length of the out buffer, in bytes\n\nReturns\n\nThe number of bytes written to out, or a negative error code.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hmac_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hmac_free","text":"av_hmac_free(ctx)\n\nFree an AVHMAC context.\n\nArguments\n\nctx: The context to free, may be NULL\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hmac_init-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hmac_init","text":"av_hmac_init(ctx, key, keylen::Integer)\n\nInitialize an AVHMAC context with an authentication key.\n\nArguments\n\nctx: The HMAC context\nkey: The authentication key\nkeylen: The length of the key, in bytes\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hmac_update-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hmac_update","text":"av_hmac_update(ctx, data, len::Integer)\n\nHash data with the HMAC.\n\nArguments\n\nctx: The HMAC context\ndata: The data to hash\nlen: The length of the data, in bytes\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwdevice_ctx_alloc-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwdevice_ctx_alloc","text":"av_hwdevice_ctx_alloc(type::AVHWDeviceType)\n\nAllocate an AVHWDeviceContext for a given hardware type.\n\nArguments\n\ntype: the type of the hardware device to allocate.\n\nReturns\n\na reference to the newly created AVHWDeviceContext on success or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwdevice_ctx_create-Tuple{Any, UInt32, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwdevice_ctx_create","text":"av_hwdevice_ctx_create(device_ctx, type::AVHWDeviceType, device, opts, flags::Integer)\n\nOpen a device of the specified type and create an AVHWDeviceContext for it.\n\nThis is a convenience function intended to cover the simple cases. Callers who need to fine-tune device creation/management should open the device manually and then wrap it in an AVHWDeviceContext using av_hwdevice_ctx_alloc()/av_hwdevice_ctx_init().\n\nThe returned context is already initialized and ready for use, the caller should not call av_hwdevice_ctx_init() on it. The user_opaque/free fields of the created AVHWDeviceContext are set by this function and should not be touched by the caller.\n\nArguments\n\ndevice_ctx: On success, a reference to the newly-created device context will be written here. The reference is owned by the caller and must be released with av_buffer_unref() when no longer needed. On failure, NULL will be written to this pointer.\ntype: The type of the device to create.\ndevice: A type-specific string identifying the device to open.\nopts: A dictionary of additional (type-specific) options to use in opening the device. The dictionary remains owned by the caller.\nflags: currently unused\n\nReturns\n\n0 on success, a negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwdevice_ctx_create_derived-Tuple{Any, UInt32, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwdevice_ctx_create_derived","text":"av_hwdevice_ctx_create_derived(dst_ctx, type::AVHWDeviceType, src_ctx, flags::Integer)\n\nCreate a new device of the specified type from an existing device.\n\nIf the source device is a device of the target type or was originally derived from such a device (possibly through one or more intermediate devices of other types), then this will return a reference to the existing device of the same type as is requested.\n\nOtherwise, it will attempt to derive a new device from the given source device. If direct derivation to the new type is not implemented, it will attempt the same derivation from each ancestor of the source device in turn looking for an implemented derivation method.\n\nArguments\n\ndst_ctx: On success, a reference to the newly-created AVHWDeviceContext.\ntype: The type of the new device to create.\nsrc_ctx: A reference to an existing AVHWDeviceContext which will be used to create the new device.\nflags: Currently unused; should be set to zero.\n\nReturns\n\nZero on success, a negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwdevice_ctx_create_derived_opts-Tuple{Any, UInt32, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwdevice_ctx_create_derived_opts","text":"av_hwdevice_ctx_create_derived_opts(dst_ctx, type::AVHWDeviceType, src_ctx, options, flags::Integer)\n\nCreate a new device of the specified type from an existing device.\n\nThis function performs the same action as av_hwdevice_ctx_create_derived, however, it is able to set options for the new device to be derived.\n\nArguments\n\ndst_ctx: On success, a reference to the newly-created AVHWDeviceContext.\ntype: The type of the new device to create.\nsrc_ctx: A reference to an existing AVHWDeviceContext which will be used to create the new device.\noptions: Options for the new device to create, same format as in av_hwdevice_ctx_create.\nflags: Currently unused; should be set to zero.\n\nReturns\n\nZero on success, a negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwdevice_ctx_init-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwdevice_ctx_init","text":"av_hwdevice_ctx_init(ref)\n\nFinalize the device context before use. This function must be called after the context is filled with all the required information and before it is used in any way.\n\nArguments\n\nref: a reference to the AVHWDeviceContext\n\nReturns\n\n0 on success, a negative AVERROR code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwdevice_find_type_by_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwdevice_find_type_by_name","text":"av_hwdevice_find_type_by_name(name)\n\nLook up an AVHWDeviceType by name.\n\nArguments\n\nname: String name of the device type (case-insensitive).\n\nReturns\n\nThe type from enum AVHWDeviceType, or AV_HWDEVICE_TYPE_NONE if not found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwdevice_get_hwframe_constraints-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwdevice_get_hwframe_constraints","text":"av_hwdevice_get_hwframe_constraints(ref, hwconfig)\n\nGet the constraints on HW frames given a device and the HW-specific configuration to be used with that device. If no HW-specific configuration is provided, returns the maximum possible capabilities of the device.\n\nArguments\n\nref: a reference to the associated AVHWDeviceContext.\nhwconfig: a filled HW-specific configuration structure, or NULL to return the maximum possible capabilities of the device.\n\nReturns\n\nAVHWFramesConstraints structure describing the constraints on the device, or NULL if not available.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwdevice_get_type_name-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwdevice_get_type_name","text":"av_hwdevice_get_type_name(type::AVHWDeviceType)\n\nGet the string name of an AVHWDeviceType.\n\nArguments\n\ntype: Type from enum AVHWDeviceType.\n\nReturns\n\nPointer to a static string containing the name, or NULL if the type is not valid.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwdevice_hwconfig_alloc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwdevice_hwconfig_alloc","text":"av_hwdevice_hwconfig_alloc(device_ctx)\n\nAllocate a HW-specific configuration structure for a given HW device. After use, the user must free all members as required by the specific hardware structure being used, then free the structure itself with av_free().\n\nArguments\n\ndevice_ctx: a reference to the associated AVHWDeviceContext.\n\nReturns\n\nThe newly created HW-specific configuration structure on success or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwdevice_iterate_types-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwdevice_iterate_types","text":"av_hwdevice_iterate_types(prev::AVHWDeviceType)\n\nIterate over supported device types.\n\nArguments\n\nprev: AV_HWDEVICE_TYPE_NONE initially, then the previous type returned by this function in subsequent iterations.\n\nReturns\n\nThe next usable device type from enum AVHWDeviceType, or AV_HWDEVICE_TYPE_NONE if there are no more.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwframe_constraints_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwframe_constraints_free","text":"av_hwframe_constraints_free(constraints)\n\nFree an AVHWFrameConstraints structure.\n\nArguments\n\nconstraints: The (filled or unfilled) AVHWFrameConstraints structure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwframe_ctx_alloc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwframe_ctx_alloc","text":"av_hwframe_ctx_alloc(device_ctx)\n\nAllocate an AVHWFramesContext tied to a given device context.\n\nArguments\n\ndevice_ctx: a reference to a AVHWDeviceContext. This function will make a new reference for internal use, the one passed to the function remains owned by the caller.\n\nReturns\n\na reference to the newly created AVHWFramesContext on success or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwframe_ctx_create_derived-Tuple{Any, Int32, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwframe_ctx_create_derived","text":"av_hwframe_ctx_create_derived(derived_frame_ctx, format::AVPixelFormat, derived_device_ctx, source_frame_ctx, flags::Integer)\n\nCreate and initialise an AVHWFramesContext as a mapping of another existing AVHWFramesContext on a different device.\n\nav_hwframe_ctx_init() should not be called after this.\n\nArguments\n\nderived_frame_ctx: On success, a reference to the newly created AVHWFramesContext.\nformat: The AVPixelFormat for the derived context.\nderived_device_ctx: A reference to the device to create the new AVHWFramesContext on.\nsource_frame_ctx: A reference to an existing AVHWFramesContext which will be mapped to the derived context.\nflags: Some combination of AV_HWFRAME_MAP_* flags, defining the mapping parameters to apply to frames which are allocated in the derived device.\n\nReturns\n\nZero on success, negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwframe_ctx_init-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwframe_ctx_init","text":"av_hwframe_ctx_init(ref)\n\nFinalize the context before use. This function must be called after the context is filled with all the required information and before it is attached to any frames.\n\nArguments\n\nref: a reference to the AVHWFramesContext\n\nReturns\n\n0 on success, a negative AVERROR code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwframe_get_buffer-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwframe_get_buffer","text":"av_hwframe_get_buffer(hwframe_ctx, frame, flags::Integer)\n\nAllocate a new frame attached to the given AVHWFramesContext.\n\nArguments\n\nhwframe_ctx: a reference to an AVHWFramesContext\nframe: an empty (freshly allocated or unreffed) frame to be filled with newly allocated buffers.\nflags: currently unused, should be set to zero\n\nReturns\n\n0 on success, a negative AVERROR code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwframe_map-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwframe_map","text":"av_hwframe_map(dst, src, flags::Integer)\n\nMap a hardware frame.\n\nThis has a number of different possible effects, depending on the format and origin of the src and dst frames. On input, src should be a usable frame with valid buffers and dst should be blank (typically as just created by av_frame_alloc()). src should have an associated hwframe context, and dst may optionally have a format and associated hwframe context.\n\nIf src was created by mapping a frame from the hwframe context of dst, then this function undoes the mapping - dst is replaced by a reference to the frame that src was originally mapped from.\n\nIf both src and dst have an associated hwframe context, then this function attempts to map the src frame from its hardware context to that of dst and then fill dst with appropriate data to be usable there. This will only be possible if the hwframe contexts and associated devices are compatible - given compatible devices, av_hwframe_ctx_create_derived() can be used to create a hwframe context for dst in which mapping should be possible.\n\nIf src has a hwframe context but dst does not, then the src frame is mapped to normal memory and should thereafter be usable as a normal frame. If the format is set on dst, then the mapping will attempt to create dst with that format and fail if it is not possible. If format is unset (is AV_PIX_FMT_NONE) then dst will be mapped with whatever the most appropriate format to use is (probably the sw_format of the src hwframe context).\n\nA return value of AVERROR(ENOSYS) indicates that the mapping is not possible with the given arguments and hwframe setup, while other return values indicate that it failed somehow.\n\nOn failure, the destination frame will be left blank, except for the hw_frames_ctx/format fields they may have been set by the caller - those will be preserved as they were.\n\nArguments\n\ndst: Destination frame, to contain the mapping.\nsrc: Source frame, to be mapped.\nflags: Some combination of AV_HWFRAME_MAP_* flags.\n\nReturns\n\nZero on success, negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwframe_transfer_data-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwframe_transfer_data","text":"av_hwframe_transfer_data(dst, src, flags::Integer)\n\nCopy data to or from a hw surface. At least one of dst/src must have an AVHWFramesContext attached.\n\nIf src has an AVHWFramesContext attached, then the format of dst (if set) must use one of the formats returned by av_hwframe_transfer_get_formats(src, AV_HWFRAME_TRANSFER_DIRECTION_FROM). If dst has an AVHWFramesContext attached, then the format of src must use one of the formats returned by av_hwframe_transfer_get_formats(dst, AV_HWFRAME_TRANSFER_DIRECTION_TO)\n\ndst may be \"clean\" (i.e. with data/buf pointers unset), in which case the data buffers will be allocated by this function using av_frame_get_buffer(). If dst->format is set, then this format will be used, otherwise (when dst->format is AV_PIX_FMT_NONE) the first acceptable format will be chosen.\n\nThe two frames must have matching allocated dimensions (i.e. equal to AVHWFramesContext.width/height), since not all device types support transferring a sub-rectangle of the whole surface. The display dimensions (i.e. AVFrame.width/height) may be smaller than the allocated dimensions, but also have to be equal for both frames. When the display dimensions are smaller than the allocated dimensions, the content of the padding in the destination frame is unspecified.\n\nArguments\n\ndst: the destination frame. dst is not touched on failure.\nsrc: the source frame.\nflags: currently unused, should be set to zero\n\nReturns\n\n0 on success, a negative AVERROR error code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_hwframe_transfer_get_formats-Tuple{Any, UInt32, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_hwframe_transfer_get_formats","text":"av_hwframe_transfer_get_formats(hwframe_ctx, dir::AVHWFrameTransferDirection, formats, flags::Integer)\n\nGet a list of possible source or target formats usable in av_hwframe_transfer_data().\n\nArguments\n\nhwframe_ctx: the frame context to obtain the information for\ndir: the direction of the transfer\nformats: the pointer to the output format list will be written here. The list is terminated with AV_PIX_FMT_NONE and must be freed by the caller when no longer needed using av_free(). If this function returns successfully, the format list will have at least one item (not counting the terminator). On failure, the contents of this pointer are unspecified.\nflags: currently unused, should be set to zero\n\nReturns\n\n0 on success, a negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_iamf_audio_element_add_layer-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_iamf_audio_element_add_layer","text":"av_iamf_audio_element_add_layer(audio_element)\n\nAllocate a layer and add it to a given AVIAMFAudioElement. It is freed by av_iamf_audio_element_free() alongside the rest of the parent AVIAMFAudioElement.\n\nReturns\n\na pointer to the allocated layer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_iamf_audio_element_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_iamf_audio_element_alloc","text":"av_iamf_audio_element_alloc()\n\nAllocates a AVIAMFAudioElement, and initializes its fields with default values. No layers are allocated. Must be freed with av_iamf_audio_element_free().\n\nSee also\n\nav_iamf_audio_element_add_layer()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_iamf_audio_element_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_iamf_audio_element_free","text":"av_iamf_audio_element_free(audio_element)\n\nFree an AVIAMFAudioElement and all its contents.\n\nArguments\n\naudio_element: pointer to pointer to an allocated AVIAMFAudioElement. upon return, *audio_element will be set to NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_iamf_mix_presentation_add_submix-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_iamf_mix_presentation_add_submix","text":"av_iamf_mix_presentation_add_submix(mix_presentation)\n\nAllocate a submix and add it to a given AVIAMFMixPresentation. It is freed by av_iamf_mix_presentation_free() alongside the rest of the parent AVIAMFMixPresentation.\n\nReturns\n\na pointer to the allocated submix.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_iamf_mix_presentation_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_iamf_mix_presentation_alloc","text":"av_iamf_mix_presentation_alloc()\n\nAllocates a AVIAMFMixPresentation, and initializes its fields with default values. No submixes are allocated. Must be freed with av_iamf_mix_presentation_free().\n\nSee also\n\nav_iamf_mix_presentation_add_submix()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_iamf_mix_presentation_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_iamf_mix_presentation_free","text":"av_iamf_mix_presentation_free(mix_presentation)\n\nFree an AVIAMFMixPresentation and all its contents.\n\nArguments\n\nmix_presentation: pointer to pointer to an allocated AVIAMFMixPresentation. upon return, *mix_presentation will be set to NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_iamf_param_definition_alloc-Tuple{UInt32, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_iamf_param_definition_alloc","text":"av_iamf_param_definition_alloc(type::AVIAMFParamDefinitionType, nb_subblocks::Integer, size)\n\nAllocates memory for AVIAMFParamDefinition, plus an array of {\n\n nb_subblocks}\n amount of subblocks of the given type and initializes the variables. Can be\n freed with a normal av_free() call.\n\n @param size if non-NULL, the size in bytes of the resulting data array is written here.\n \n\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_iamf_param_definition_get_subblock-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_iamf_param_definition_get_subblock","text":"av_iamf_param_definition_get_subblock(par, idx::Integer)\n\nGet the subblock at the specified {\n\n idx}. Must be between 0 and nb_subblocks - 1.\n\n The @ref AVIAMFParamDefinition.type \"param definition type\" defines\n the struct type of the returned pointer.\n \n\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_iamf_submix_add_element-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_iamf_submix_add_element","text":"av_iamf_submix_add_element(submix)\n\nAllocate a submix element and add it to a given AVIAMFSubmix. It is freed by av_iamf_mix_presentation_free() alongside the rest of the parent AVIAMFSubmix.\n\nReturns\n\na pointer to the allocated submix.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_iamf_submix_add_layout-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_iamf_submix_add_layout","text":"av_iamf_submix_add_layout(submix)\n\nAllocate a submix layout and add it to a given AVIAMFSubmix. It is freed by av_iamf_mix_presentation_free() alongside the rest of the parent AVIAMFSubmix.\n\nReturns\n\na pointer to the allocated submix.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_alloc-Tuple{Any, Any, Integer, Integer, Int32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_alloc","text":"av_image_alloc(pointers, linesizes, w::Integer, h::Integer, pix_fmt::AVPixelFormat, align::Integer)\n\nAllocate an image with size w and h and pixel format pix_fmt, and fill pointers and linesizes accordingly. The allocated image buffer has to be freed by using av_freep(&pointers[0]).\n\nArguments\n\npointers: array to be filled with the pointer for each image plane\nlinesizes: the array filled with the linesize for each plane\nw: width of the image in pixels\nh: height of the image in pixels\npix_fmt: the AVPixelFormat of the image\nalign: the value to use for buffer size alignment\n\nReturns\n\nthe size in bytes required for the image buffer, a negative error code in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_check_sar-Tuple{Integer, Integer, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_check_sar","text":"av_image_check_sar(w::Integer, h::Integer, sar::AVRational)\n\nCheck if the given sample aspect ratio of an image is valid.\n\nIt is considered invalid if the denominator is 0 or if applying the ratio to the image size would make the smaller dimension less than 1. If the sar numerator is 0, it is considered unknown and will return as valid.\n\nArguments\n\nw: width of the image\nh: height of the image\nsar: sample aspect ratio of the image\n\nReturns\n\n0 if valid, a negative AVERROR code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_check_size-Tuple{Integer, Integer, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_check_size","text":"av_image_check_size(w::Integer, h::Integer, log_offset::Integer, log_ctx)\n\nCheck if the given dimension of an image is valid, meaning that all bytes of the image can be addressed with a signed int.\n\nArguments\n\nw: the width of the picture\nh: the height of the picture\nlog_offset: the offset to sum to the log level for logging with log_ctx\nlog_ctx: the parent logging context, it may be NULL\n\nReturns\n\n= 0 if valid, a negative error code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_check_size2-Tuple{Integer, Integer, Int64, Int32, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_check_size2","text":"av_image_check_size2(w::Integer, h::Integer, max_pixels::Int64, pix_fmt::AVPixelFormat, log_offset::Integer, log_ctx)\n\nCheck if the given dimension of an image is valid, meaning that all bytes of a plane of an image with the specified pix_fmt can be addressed with a signed int.\n\nArguments\n\nw: the width of the picture\nh: the height of the picture\nmax_pixels: the maximum number of pixels the user wants to accept\npix_fmt: the pixel format, can be AV_PIX_FMT_NONE if unknown.\nlog_offset: the offset to sum to the log level for logging with log_ctx\nlog_ctx: the parent logging context, it may be NULL\n\nReturns\n\n= 0 if valid, a negative error code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_copy-Tuple{Any, Any, Any, Any, Int32, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_copy","text":"av_image_copy(dst_data, dst_linesizes, src_data, src_linesizes, pix_fmt::AVPixelFormat, width::Integer, height::Integer)\n\nCopy image in src_data to dst_data.\n\nArguments\n\ndst_data: destination image data buffer to copy to\ndst_linesizes: linesizes for the image in dst_data\nsrc_data: source image data buffer to copy from\nsrc_linesizes: linesizes for the image in src_data\npix_fmt: the AVPixelFormat of the image\nwidth: width of the image in pixels\nheight: height of the image in pixels\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_copy2-Tuple{Any, Any, Any, Any, Int32, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_copy2","text":"av_image_copy2(dst_data, dst_linesizes, src_data, src_linesizes, pix_fmt::AVPixelFormat, width::Integer, height::Integer)\n\nWrapper around av_image_copy() to workaround the limitation that the conversion from uint8_t * const * to const uint8_t * const * is not performed automatically in C.\n\nSee also\n\nav_image_copy()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_copy_plane-Tuple{Any, Integer, Any, Integer, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_copy_plane","text":"av_image_copy_plane(dst, dst_linesize::Integer, src, src_linesize::Integer, bytewidth::Integer, height::Integer)\n\nCopy image plane from src to dst. That is, copy \"height\" number of lines of \"bytewidth\" bytes each. The first byte of each successive line is separated by *_linesize bytes.\n\nbytewidth must be contained by both absolute values of dst_linesize and src_linesize, otherwise the function behavior is undefined.\n\nArguments\n\ndst: destination plane to copy to\ndst_linesize: linesize for the image plane in dst\nsrc: source plane to copy from\nsrc_linesize: linesize for the image plane in src\nheight: height (number of lines) of the plane\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_copy_plane_uc_from-Tuple{Any, Int64, Any, Int64, Int64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_copy_plane_uc_from","text":"av_image_copy_plane_uc_from(dst, dst_linesize::Cptrdiff_t, src, src_linesize::Cptrdiff_t, bytewidth::Cptrdiff_t, height::Integer)\n\nCopy image data located in uncacheable (e.g. GPU mapped) memory. Where available, this function will use special functionality for reading from such memory, which may result in greatly improved performance compared to plain av_image_copy_plane().\n\nbytewidth must be contained by both absolute values of dst_linesize and src_linesize, otherwise the function behavior is undefined.\n\nnote: Note\nThe linesize parameters have the type ptrdiff_t here, while they are int for av_image_copy_plane().\n\nnote: Note\nOn x86, the linesizes currently need to be aligned to the cacheline size (i.e. 64) to get improved performance.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_copy_to_buffer-Tuple{Any, Integer, Any, Any, Int32, Integer, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_copy_to_buffer","text":"av_image_copy_to_buffer(dst, dst_size::Integer, src_data, src_linesize, pix_fmt::AVPixelFormat, width::Integer, height::Integer, align::Integer)\n\nCopy image data from an image into a buffer.\n\nav_image_get_buffer_size() can be used to compute the required size for the buffer to fill.\n\nArguments\n\ndst: a buffer into which picture data will be copied\ndst_size: the size in bytes of dst\nsrc_data: pointers containing the source image data\nsrc_linesize: linesizes for the image in src_data\npix_fmt: the pixel format of the source image\nwidth: the width of the source image in pixels\nheight: the height of the source image in pixels\nalign: the assumed linesize alignment for dst\n\nReturns\n\nthe number of bytes written to dst, or a negative value (error code) on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_copy_uc_from-Tuple{Any, Any, Any, Any, Int32, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_copy_uc_from","text":"av_image_copy_uc_from(dst_data, dst_linesizes, src_data, src_linesizes, pix_fmt::AVPixelFormat, width::Integer, height::Integer)\n\nCopy image data located in uncacheable (e.g. GPU mapped) memory. Where available, this function will use special functionality for reading from such memory, which may result in greatly improved performance compared to plain av_image_copy().\n\nThe data pointers and the linesizes must be aligned to the maximum required by the CPU architecture.\n\nnote: Note\nThe linesize parameters have the type ptrdiff_t here, while they are int for av_image_copy().\n\nnote: Note\nOn x86, the linesizes currently need to be aligned to the cacheline size (i.e. 64) to get improved performance.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_fill_arrays-Tuple{Any, Any, Any, Int32, Integer, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_fill_arrays","text":"av_image_fill_arrays(dst_data, dst_linesize, src, pix_fmt::AVPixelFormat, width::Integer, height::Integer, align::Integer)\n\nSetup the data pointers and linesizes based on the specified image parameters and the provided array.\n\nThe fields of the given image are filled in by using the src address which points to the image data buffer. Depending on the specified pixel format, one or multiple image data pointers and line sizes will be set. If a planar format is specified, several pointers will be set pointing to the different picture planes and the line sizes of the different planes will be stored in the lines_sizes array. Call with src == NULL to get the required size for the src buffer.\n\nTo allocate the buffer and fill in the dst_data and dst_linesize in one call, use av_image_alloc().\n\nArguments\n\ndst_data: data pointers to be filled in\ndst_linesize: linesizes for the image in dst_data to be filled in\nsrc: buffer which will contain or contains the actual image data, can be NULL\npix_fmt: the pixel format of the image\nwidth: the width of the image in pixels\nheight: the height of the image in pixels\nalign: the value used in src for linesize alignment\n\nReturns\n\nthe size in bytes required for src, a negative error code in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_fill_black-Tuple{Any, Any, Int32, UInt32, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_fill_black","text":"av_image_fill_black(dst_data, dst_linesize, pix_fmt::AVPixelFormat, range::AVColorRange, width::Integer, height::Integer)\n\nOverwrite the image data with black. This is suitable for filling a sub-rectangle of an image, meaning the padding between the right most pixel and the left most pixel on the next line will not be overwritten. For some formats, the image size might be rounded up due to inherent alignment.\n\nIf the pixel format has alpha, the alpha is cleared to opaque.\n\nThis can return an error if the pixel format is not supported. Normally, all non-hwaccel pixel formats should be supported.\n\nPassing NULL for dst_data is allowed. Then the function returns whether the operation would have succeeded. (It can return an error if the pix_fmt is not supported.)\n\nArguments\n\ndst_data: data pointers to destination image\ndst_linesize: linesizes for the destination image\npix_fmt: the pixel format of the image\nrange: the color range of the image (important for colorspaces such as YUV)\nwidth: the width of the image in pixels\nheight: the height of the image in pixels\n\nReturns\n\n0 if the image data was cleared, a negative AVERROR code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_fill_color-Tuple{Any, Any, Int32, Any, Integer, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_fill_color","text":"av_image_fill_color(dst_data, dst_linesize, pix_fmt::AVPixelFormat, color, width::Integer, height::Integer, flags::Integer)\n\nOverwrite the image data with a color. This is suitable for filling a sub-rectangle of an image, meaning the padding between the right most pixel and the left most pixel on the next line will not be overwritten. For some formats, the image size might be rounded up due to inherent alignment.\n\nIf the pixel format has alpha, it is also replaced. Color component values are interpreted as native integers (or intfloats) regardless of actual pixel format endianness.\n\nThis can return an error if the pixel format is not supported. Normally, all non-hwaccel pixel formats should be supported.\n\nPassing NULL for dst_data is allowed. Then the function returns whether the operation would have succeeded. (It can return an error if the pix_fmt is not supported.)\n\nArguments\n\ndst_data: data pointers to destination image\ndst_linesize: linesizes for the destination image\npix_fmt: the pixel format of the image\ncolor: the color components to be used for the fill\nwidth: the width of the image in pixels\nheight: the height of the image in pixels\nflags: currently unused\n\nReturns\n\n0 if the image data was filled, a negative AVERROR code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_fill_linesizes-Tuple{Any, Int32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_fill_linesizes","text":"av_image_fill_linesizes(linesizes, pix_fmt::AVPixelFormat, width::Integer)\n\nFill plane linesizes for an image with pixel format pix_fmt and width width.\n\nArguments\n\nlinesizes: array to be filled with the linesize for each plane\npix_fmt: the AVPixelFormat of the image\nwidth: width of the image in pixels\n\nReturns\n\n= 0 in case of success, a negative error code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_fill_max_pixsteps-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_fill_max_pixsteps","text":"av_image_fill_max_pixsteps(max_pixsteps, max_pixstep_comps, pixdesc)\n\nCompute the max pixel step for each plane of an image with a format described by pixdesc.\n\nThe pixel step is the distance in bytes between the first byte of the group of bytes which describe a pixel component and the first byte of the successive group in the same plane for the same component.\n\nArguments\n\nmax_pixsteps: an array which is filled with the max pixel step for each plane. Since a plane may contain different pixel components, the computed max_pixsteps[plane] is relative to the component in the plane with the max pixel step.\nmax_pixstep_comps: an array which is filled with the component for each plane which has the max pixel step. May be NULL.\npixdesc: the AVPixFmtDescriptor for the image, describing its format\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_fill_plane_sizes-Tuple{Any, Int32, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_fill_plane_sizes","text":"av_image_fill_plane_sizes(size, pix_fmt::AVPixelFormat, height::Integer, linesizes)\n\nFill plane sizes for an image with pixel format pix_fmt and height height.\n\nnote: Note\nThe linesize parameters have the type ptrdiff_t here, while they are int for av_image_fill_linesizes().\n\nArguments\n\nsize: the array to be filled with the size of each image plane\npix_fmt: the AVPixelFormat of the image\nheight: height of the image in pixels\nlinesizes: the array containing the linesize for each plane, should be filled by av_image_fill_linesizes()\n\nReturns\n\n= 0 in case of success, a negative error code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_fill_pointers-Tuple{Any, Int32, Integer, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_fill_pointers","text":"av_image_fill_pointers(data, pix_fmt::AVPixelFormat, height::Integer, ptr, linesizes)\n\nFill plane data pointers for an image with pixel format pix_fmt and height height.\n\nArguments\n\ndata: pointers array to be filled with the pointer for each image plane\npix_fmt: the AVPixelFormat of the image\nheight: height of the image in pixels\nptr: the pointer to a buffer which will contain the image\nlinesizes: the array containing the linesize for each plane, should be filled by av_image_fill_linesizes()\n\nReturns\n\nthe size in bytes required for the image buffer, a negative error code in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_get_buffer_size-Tuple{Int32, Integer, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_get_buffer_size","text":"av_image_get_buffer_size(pix_fmt::AVPixelFormat, width::Integer, height::Integer, align::Integer)\n\nReturn the size in bytes of the amount of data required to store an image with the given parameters.\n\nArguments\n\npix_fmt: the pixel format of the image\nwidth: the width of the image in pixels\nheight: the height of the image in pixels\nalign: the assumed linesize alignment\n\nReturns\n\nthe buffer size in bytes, a negative error code in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_image_get_linesize-Tuple{Int32, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_image_get_linesize","text":"av_image_get_linesize(pix_fmt::AVPixelFormat, width::Integer, plane::Integer)\n\nCompute the size of an image line with format pix_fmt and width width for the plane plane.\n\nReturns\n\nthe computed size in bytes\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_index_search_timestamp-Tuple{Any, Int64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_index_search_timestamp","text":"av_index_search_timestamp(st, timestamp::Int64, flags::Integer)\n\nGet the index for a specific timestamp.\n\nArguments\n\nst: stream that the timestamp belongs to\ntimestamp: timestamp to retrieve the index for\nflags: if AVSEEK_FLAG_BACKWARD then the returned index will correspond to the timestamp which is <= the requested one, if backward is 0, then it will be >= if AVSEEK_FLAG_ANY seek to any frame, only keyframes otherwise\n\nReturns\n\n< 0 if no such timestamp could be found\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_init_packet-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_init_packet","text":"av_init_packet(pkt)\n\nInitialize optional fields of a packet with default values.\n\nNote, this does not touch the data and size members, which have to be initialized separately.\n\ncompat: Deprecated\nThis function is deprecated. Once it's removed, sizeof(AVPacket) will not be a part of the ABI anymore.\n\nArguments\n\npkt: packet\n\nSee also\n\nav_packet_alloc, av_packet_unref\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_input_audio_device_next-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_input_audio_device_next","text":"av_input_audio_device_next(d)\n\nAudio input devices iterator.\n\nIf d is NULL, returns the first registered input audio/video device, if d is non-NULL, returns the next registered input audio/video device after d or NULL if d is the last one.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_input_video_device_next-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_input_video_device_next","text":"av_input_video_device_next(d)\n\nVideo input devices iterator.\n\nIf d is NULL, returns the first registered input audio/video device, if d is non-NULL, returns the next registered input audio/video device after d or NULL if d is the last one.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_int2double-Tuple{UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_int2double","text":"av_int2double(i::UInt64)\n\nReinterpret a 64-bit integer as a double.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_int2float-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_int2float","text":"av_int2float(i::Integer)\n\nReinterpret a 32-bit integer as a float.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_int_list_length_for_size-Tuple{Integer, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_int_list_length_for_size","text":"av_int_list_length_for_size(elsize::Integer, list, term::UInt64)\n\nCompute the length of an integer list.\n\nArguments\n\nelsize: size in bytes of each list element (only 1, 2, 4 or 8)\nterm: list terminator (usually 0 or -1)\nlist: pointer to the list\n\nReturns\n\nlength of the list, in elements, not counting the terminator\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_interleaved_write_frame-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_interleaved_write_frame","text":"av_interleaved_write_frame(s, pkt)\n\nWrite a packet to an output media file ensuring correct interleaving.\n\nThis function will buffer the packets internally as needed to make sure the packets in the output file are properly interleaved, usually ordered by increasing dts. Callers doing their own interleaving should call av_write_frame() instead of this function.\n\nUsing this function instead of av_write_frame() can give muxers advance knowledge of future packets, improving e.g. the behaviour of the mp4 muxer for VFR content in fragmenting mode.\n\nArguments\n\ns: media file handle\npkt: The packet containing the data to be written. <br> If the packet is reference-counted, this function will take ownership of this reference and unreference it later when it sees fit. If the packet is not reference-counted, libavformat will make a copy. The returned packet will be blank (as if returned from av_packet_alloc()), even on error. <br> This parameter can be NULL (at any time, not just at the end), to flush the interleaving queues. <br> Packet's AVPacket.streamindex \"stream\\index\" field must be set to the index of the corresponding stream in AVFormatContext.streams \"s->streams\". <br> The timestamps (AVPacket.pts \"pts\", AVPacket.dts \"dts\") must be set to correct values in the stream's timebase (unless the output format is flagged with the AVFMT_NOTIMESTAMPS flag, then they can be set to AV_NOPTS_VALUE). The dts for subsequent packets in one stream must be strictly increasing (unless the output format is flagged with the AVFMT_TS_NONSTRICT, then they merely have to be nondecreasing). AVPacket.duration \"duration\" should also be set if known.\n\nReturns\n\n0 on success, a negative AVERROR on error.\n\nSee also\n\nav_write_frame(), AVFormatContext.max_interleave_delta\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_interleaved_write_uncoded_frame-Tuple{Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_interleaved_write_uncoded_frame","text":"av_interleaved_write_uncoded_frame(s, stream_index::Integer, frame)\n\nWrite an uncoded frame to an output media file.\n\nIf the muxer supports it, this function makes it possible to write an AVFrame structure directly, without encoding it into a packet. It is mostly useful for devices and similar special muxers that use raw video or PCM data and will not serialize it into a byte stream.\n\nTo test whether it is possible to use it with a given muxer and stream, use av_write_uncoded_frame_query().\n\nThe caller gives up ownership of the frame and must not access it afterwards.\n\nReturns\n\n=0 for success, a negative code on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_inv_q-Tuple{VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_inv_q","text":"av_inv_q(q::AVRational)\n\nInvert a rational.\n\nArguments\n\nq: value\n\nReturns\n\n1 / q\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_isdigit-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_isdigit","text":"av_isdigit(c::Integer)\n\nLocale-independent conversion of ASCII isdigit.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_isgraph-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_isgraph","text":"av_isgraph(c::Integer)\n\nLocale-independent conversion of ASCII isgraph.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_isspace-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_isspace","text":"av_isspace(c::Integer)\n\nLocale-independent conversion of ASCII isspace.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_isxdigit-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_isxdigit","text":"av_isxdigit(c::Integer)\n\nLocale-independent conversion of ASCII isxdigit.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_lfg_get-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_lfg_get","text":"av_lfg_get(c)\n\nGet the next random unsigned 32-bit number using an ALFG.\n\nPlease also consider a simple LCG like state= state*1664525+1013904223, it may be good enough and faster for your specific use case.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_lfg_init_from_data-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_lfg_init_from_data","text":"av_lfg_init_from_data(c, data, length::Integer)\n\nSeed the state of the ALFG using binary data.\n\nReturns\n\n0 on success, negative value (AVERROR) on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_log_get_level-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_log_get_level","text":"av_log_get_level()\n\nGet the current log level\n\nReturns\n\nCurrent log level\n\nSee also\n\nlavu_log_constants\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_log_set_callback-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_log_set_callback","text":"av_log_set_callback(callback)\n\nSet the logging callback\n\nnote: Note\nThe callback must be thread safe, even if the application does not use threads itself as some codecs are multithreaded.\n\nArguments\n\ncallback: A logging function with a compatible signature.\n\nSee also\n\nav_log_default_callback\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_log_set_level-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_log_set_level","text":"av_log_set_level(level::Integer)\n\nSet the log level\n\nArguments\n\nlevel: Logging level\n\nSee also\n\nlavu_log_constants\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_lzo1x_decode-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_lzo1x_decode","text":"av_lzo1x_decode(out, outlen, in, inlen)\n\nDecodes LZO 1x compressed data.\n\nMake sure all buffers are appropriately padded, in must provide AV_LZO_INPUT_PADDING, out must provide AV_LZO_OUTPUT_PADDING additional bytes.\n\nArguments\n\nout: output buffer\noutlen: size of output buffer, number of bytes left are returned here\nin: input buffer\ninlen: size of input buffer, number of bytes left are returned here\n\nReturns\n\n0 on success, otherwise a combination of the error flags above\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_make_error_string-Tuple{Any, UInt64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_make_error_string","text":"av_make_error_string(errbuf, errbuf_size::Csize_t, errnum::Integer)\n\nFill the provided buffer with a string containing an error string corresponding to the AVERROR code errnum.\n\nArguments\n\nerrbuf: a buffer\nerrbuf_size: size in bytes of errbuf\nerrnum: error code to describe\n\nReturns\n\nthe buffer in input, filled with the error description\n\nSee also\n\nav_strerror()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_make_q-Tuple{Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_make_q","text":"av_make_q(num::Integer, den::Integer)\n\nCreate an AVRational.\n\nUseful for compilers that do not support compound literals.\n\nnote: Note\nThe return value is not reduced.\n\nSee also\n\nav_reduce()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_malloc-Tuple{UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_malloc","text":"av_malloc(size::Csize_t)\n\nAllocate a memory block with alignment suitable for all memory accesses (including vectors if available on the CPU).\n\nArguments\n\nsize: Size in bytes for the memory block to be allocated\n\nReturns\n\nPointer to the allocated block, or NULL if the block cannot be allocated\n\nSee also\n\nav_mallocz()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_malloc_array-Tuple{UInt64, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_malloc_array","text":"av_malloc_array(nmemb::Csize_t, size::Csize_t)\n\nAllocate a memory block for an array with av_malloc().\n\nThe allocated memory will have size size * nmemb bytes.\n\nArguments\n\nnmemb: Number of element\nsize: Size of a single element\n\nReturns\n\nPointer to the allocated block, or NULL if the block cannot be allocated\n\nSee also\n\nav_malloc()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_mallocz-Tuple{UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_mallocz","text":"av_mallocz(size::Csize_t)\n\nAllocate a memory block with alignment suitable for all memory accesses (including vectors if available on the CPU) and zero all the bytes of the block.\n\nArguments\n\nsize: Size in bytes for the memory block to be allocated\n\nReturns\n\nPointer to the allocated block, or NULL if it cannot be allocated\n\nSee also\n\nav_malloc()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_map_videotoolbox_format_from_pixfmt-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_map_videotoolbox_format_from_pixfmt","text":"av_map_videotoolbox_format_from_pixfmt(pix_fmt::AVPixelFormat)\n\nConvert an AVPixelFormat to a VideoToolbox (actually CoreVideo) format. Returns 0 if no known equivalent was found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_map_videotoolbox_format_to_pixfmt-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_map_videotoolbox_format_to_pixfmt","text":"av_map_videotoolbox_format_to_pixfmt(cv_fmt::Integer)\n\nConvert a VideoToolbox (actually CoreVideo) format to AVPixelFormat. Returns AV_PIX_FMT_NONE if no known equivalent was found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_mastering_display_metadata_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_mastering_display_metadata_alloc","text":"av_mastering_display_metadata_alloc()\n\nAllocate an AVMasteringDisplayMetadata structure and set its fields to default values. The resulting struct can be freed using av_freep().\n\nReturns\n\nAn AVMasteringDisplayMetadata filled with default values or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_mastering_display_metadata_alloc_size-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_mastering_display_metadata_alloc_size","text":"av_mastering_display_metadata_alloc_size(size)\n\nAllocate an AVMasteringDisplayMetadata structure and set its fields to default values. The resulting struct can be freed using av_freep().\n\nReturns\n\nAn AVMasteringDisplayMetadata filled with default values or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_mastering_display_metadata_create_side_data-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_mastering_display_metadata_create_side_data","text":"av_mastering_display_metadata_create_side_data(frame)\n\nAllocate a complete AVMasteringDisplayMetadata and add it to the frame.\n\nArguments\n\nframe: The frame which side data is added to.\n\nReturns\n\nThe AVMasteringDisplayMetadata structure to be filled by caller.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_match_ext-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_match_ext","text":"av_match_ext(filename, extensions)\n\nReturn a positive value if the given filename has one of the given extensions, 0 otherwise.\n\nArguments\n\nfilename: file name to check against the given extensions\nextensions: a comma-separated list of filename extensions\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_match_list-Tuple{Any, Any, Int8}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_match_list","text":"av_match_list(name, list, separator::Cchar)\n\nCheck if a name is in a list.\n\nReturns\n\n0 if not found, or the 1 based index where it has been found in the list.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_match_name-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_match_name","text":"av_match_name(name, names)\n\nMatch instances of a name in a comma-separated list of names. List entries are checked from the start to the end of the names list, the first match ends further processing. If an entry prefixed with '-' matches, then 0 is returned. The \"ALL\" list entry is considered to match all names.\n\nArguments\n\nname: Name to look for.\nnames: List of names.\n\nReturns\n\n1 on match, 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_max_alloc-Tuple{UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_max_alloc","text":"av_max_alloc(max::Csize_t)\n\nSet the maximum size that may be allocated in one block.\n\nThe value specified with this function is effective for all libavutil's lavumemfuncs \"heap management functions.\"\n\nBy default, the max value is defined as INT_MAX.\n\nwarning: Warning\nExercise extreme caution when using this function. Don't touch this if you do not understand the full consequence of doing so.\n\nArguments\n\nmax: Value to be set as the new maximum size\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_md5_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_md5_alloc","text":"av_md5_alloc()\n\nAllocate an AVMD5 context.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_md5_final-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_md5_final","text":"av_md5_final(ctx, dst)\n\nFinish hashing and output digest value.\n\nArguments\n\nctx: hash function context\ndst: buffer where output digest value is stored\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_md5_init-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_md5_init","text":"av_md5_init(ctx)\n\nInitialize MD5 hashing.\n\nArguments\n\nctx: pointer to the function context (of size av_md5_size)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_md5_sum-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_md5_sum","text":"av_md5_sum(dst, src, len::Csize_t)\n\nHash an array of data.\n\nArguments\n\ndst: The output buffer to write the digest into\nsrc: The data to hash\nlen: The length of the data, in bytes\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_md5_update-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_md5_update","text":"av_md5_update(ctx, src, len::Csize_t)\n\nUpdate hash value.\n\nArguments\n\nctx: hash function context\nsrc: input data to update hash with\nlen: input data length\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_mediacodec_alloc_context-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_mediacodec_alloc_context","text":"av_mediacodec_alloc_context()\n\nAllocate and initialize a MediaCodec context.\n\nWhen decoding with MediaCodec is finished, the caller must free the MediaCodec context with av_mediacodec_default_free.\n\nReturns\n\na pointer to a newly allocated AVMediaCodecContext on success, NULL otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_mediacodec_default_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_mediacodec_default_free","text":"av_mediacodec_default_free(avctx)\n\nThis function must be called to free the MediaCodec context initialized with av_mediacodec_default_init().\n\nArguments\n\navctx: codec context\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_mediacodec_default_init-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_mediacodec_default_init","text":"av_mediacodec_default_init(avctx, ctx, surface)\n\nConvenience function that sets up the MediaCodec context.\n\nArguments\n\navctx: codec context\nctx: MediaCodec context to initialize\nsurface: reference to an android/view/Surface\n\nReturns\n\n0 on success, < 0 otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_mediacodec_release_buffer-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_mediacodec_release_buffer","text":"av_mediacodec_release_buffer(buffer, render::Integer)\n\nRelease a MediaCodec buffer and render it to the surface that is associated with the decoder. This function should only be called once on a given buffer, once released the underlying buffer returns to the codec, thus subsequent calls to this function will have no effect.\n\nArguments\n\nbuffer: the buffer to render\nrender: 1 to release and render the buffer to the surface or 0 to discard the buffer\n\nReturns\n\n0 on success, < 0 otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_mediacodec_render_buffer_at_time-Tuple{Any, Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_mediacodec_render_buffer_at_time","text":"av_mediacodec_render_buffer_at_time(buffer, time::Int64)\n\nRelease a MediaCodec buffer and render it at the given time to the surface that is associated with the decoder. The timestamp must be within one second of the current java/lang/System#nanoTime() (which is implemented using CLOCK_MONOTONIC on Android). See the Android MediaCodec documentation of [android/media/MediaCodec#releaseOutputBuffer(int,long)][0] for more details.\n\n[0]: https://developer.android.com/reference/android/media/MediaCodec#releaseOutputBuffer(int,20long)\n\nArguments\n\nbuffer: the buffer to render\ntime: timestamp in nanoseconds of when to render the buffer\n\nReturns\n\n0 on success, < 0 otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_memcpy_backptr-Tuple{Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_memcpy_backptr","text":"av_memcpy_backptr(dst, back::Integer, cnt::Integer)\n\nOverlapping memcpy() implementation.\n\nnote: Note\ncnt > back is valid, this will copy the bytes we just copied, thus creating a repeating pattern with a period length of back.\n\nArguments\n\ndst: Destination buffer\nback: Number of bytes back to start copying (i.e. the initial size of the overlapping window); must be > 0\ncnt: Number of bytes to copy; must be >= 0\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_memdup-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_memdup","text":"av_memdup(p, size::Csize_t)\n\nDuplicate a buffer with av_malloc().\n\nArguments\n\np: Buffer to be duplicated\nsize: Size in bytes of the buffer copied\n\nReturns\n\nPointer to a newly allocated buffer containing a copy of p or NULL if the buffer cannot be allocated\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_mlfg_get-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_mlfg_get","text":"av_mlfg_get(c)\n\nGet the next random unsigned 32-bit number using a MLFG.\n\nPlease also consider av_lfg_get() above, it is faster.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_mul_q-Tuple{VideoIO.libffmpeg.AVRational, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_mul_q","text":"av_mul_q(b::AVRational, c::AVRational)\n\nMultiply two rationals.\n\nArguments\n\nb: First rational\nc: Second rational\n\nReturns\n\nb*c\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_murmur3_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_murmur3_alloc","text":"av_murmur3_alloc()\n\nAllocate an AVMurMur3 hash context.\n\nReturns\n\nUninitialized hash context or NULL in case of error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_murmur3_final-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_murmur3_final","text":"av_murmur3_final(c, dst)\n\nFinish hashing and output digest value.\n\nArguments\n\nc:[in,out] Hash context\ndst:[out] Buffer where output digest value is stored\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_murmur3_init-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_murmur3_init","text":"av_murmur3_init(c)\n\nInitialize or reinitialize an AVMurMur3 hash context.\n\nEquivalent to av_murmur3_init_seeded() with a built-in seed.\n\nArguments\n\nc:[out] Hash context\n\nSee also\n\nav_murmur3_init_seeded(), lavumurmur3seedinfo \"Detailed description\" on a discussion of seeds for MurmurHash3.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_murmur3_init_seeded-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_murmur3_init_seeded","text":"av_murmur3_init_seeded(c, seed::UInt64)\n\nInitialize or reinitialize an AVMurMur3 hash context with a seed.\n\nArguments\n\nc:[out] Hash context\nseed:[in] Random seed\n\nSee also\n\nav_murmur3_init(), lavumurmur3seedinfo \"Detailed description\" on a discussion of seeds for MurmurHash3.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_murmur3_update-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_murmur3_update","text":"av_murmur3_update(c, src, len::Csize_t)\n\nUpdate hash context with new data.\n\nArguments\n\nc:[out] Hash context\nsrc:[in] Input data to update hash with\nlen:[in] Number of bytes to read from src\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_muxer_iterate-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_muxer_iterate","text":"av_muxer_iterate(opaque)\n\nIterate over all registered muxers.\n\nArguments\n\nopaque: a pointer where libavformat will store the iteration state. Must point to NULL to start the iteration.\n\nReturns\n\nthe next registered muxer or NULL when the iteration is finished\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_nearer_q-Tuple{VideoIO.libffmpeg.AVRational, VideoIO.libffmpeg.AVRational, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_nearer_q","text":"av_nearer_q(q::AVRational, q1::AVRational, q2::AVRational)\n\nFind which of the two rationals is closer to another rational.\n\nArguments\n\nq: Rational to be compared against\nq1: Rational to be tested\nq2: Rational to be tested\n\nReturns\n\nOne of the following values: - 1 if q1 is nearer to q than q2 - -1 if q2 is nearer to q than q1 - 0 if they have the same distance\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_new_packet-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_new_packet","text":"av_new_packet(pkt, size::Integer)\n\nAllocate the payload of a packet and initialize its fields with default values.\n\nArguments\n\npkt: packet\nsize: wanted payload size\n\nReturns\n\n0 if OK, AVERROR_xxx otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_child_class_iterate-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_child_class_iterate","text":"av_opt_child_class_iterate(parent, iter)\n\nIterate over potential AVOptions-enabled children of parent.\n\nArguments\n\niter: a pointer where iteration state is stored.\n\nReturns\n\nAVClass corresponding to next potential child or NULL\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_child_next-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_child_next","text":"av_opt_child_next(obj, prev)\n\nIterate over AVOptions-enabled children of obj.\n\nArguments\n\nprev: result of a previous call to this function or NULL\n\nReturns\n\nnext AVOptions-enabled child or NULL\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_copy-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_copy","text":"av_opt_copy(dest, src)\n\nCopy options from src object into dest object.\n\nThe underlying AVClass of both src and dest must coincide. The guarantee below does not apply if this is not fulfilled.\n\nOptions that require memory allocation (e.g. string or binary) are malloc'ed in dest object. Original memory allocated for such options is freed unless both src and dest options points to the same memory.\n\nEven on error it is guaranteed that allocated options from src and dest no longer alias each other afterwards; in particular calling av_opt_free() on both src and dest is safe afterwards if dest has been memdup'ed from src.\n\nArguments\n\ndest: Object to copy from\nsrc: Object to copy into\n\nReturns\n\n0 on success, negative on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_eval_flags-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_eval_flags","text":"av_opt_eval_flags(obj, o, val, flags_out)\n\nopt_eval_funcs Evaluating option strings\n\n@{ This group of functions can be used to evaluate option strings and get numbers out of them. They do the same thing as av_opt_set(), except the result is written into the caller-supplied pointer.\n\nArguments\n\nobj: a struct whose first element is a pointer to AVClass.\no: an option for which the string is to be evaluated.\nval: string to be evaluated.\n*_out: value of the string will be written here.\n\nReturns\n\n0 on success, a negative number on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_find-Tuple{Any, Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_find","text":"av_opt_find(obj, name, unit, opt_flags::Integer, search_flags::Integer)\n\nLook for an option in an object. Consider only options which have all the specified flags set.\n\nnote: Note\nOptions found with AV_OPT_SEARCH_CHILDREN flag may not be settable directly with av_opt_set(). Use special calls which take an options AVDictionary (e.g. avformat_open_input()) to set options found with this flag.\n\nArguments\n\nobj:[in] A pointer to a struct whose first element is a pointer to an AVClass. Alternatively a double pointer to an AVClass, if AV_OPT_SEARCH_FAKE_OBJ search flag is set.\nname:[in] The name of the option to look for.\nunit:[in] When searching for named constants, name of the unit it belongs to.\nopt_flags: Find only options with all the specified flags set (AV_OPT_FLAG).\nsearch_flags: A combination of AV_OPT_SEARCH_*.\n\nReturns\n\nA pointer to the option found, or NULL if no option was found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_find2-Tuple{Any, Any, Any, Integer, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_find2","text":"av_opt_find2(obj, name, unit, opt_flags::Integer, search_flags::Integer, target_obj)\n\nLook for an option in an object. Consider only options which have all the specified flags set.\n\nArguments\n\nobj:[in] A pointer to a struct whose first element is a pointer to an AVClass. Alternatively a double pointer to an AVClass, if AV_OPT_SEARCH_FAKE_OBJ search flag is set.\nname:[in] The name of the option to look for.\nunit:[in] When searching for named constants, name of the unit it belongs to.\nopt_flags: Find only options with all the specified flags set (AV_OPT_FLAG).\nsearch_flags: A combination of AV_OPT_SEARCH_*.\ntarget_obj:[out] if non-NULL, an object to which the option belongs will be written here. It may be different from obj if AV_OPT_SEARCH_CHILDREN is present in search_flags. This parameter is ignored if search_flags contain AV_OPT_SEARCH_FAKE_OBJ.\n\nReturns\n\nA pointer to the option found, or NULL if no option was found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_flag_is_set-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_flag_is_set","text":"av_opt_flag_is_set(obj, field_name, flag_name)\n\nCheck whether a particular flag is set in a flags field.\n\nArguments\n\nfield_name: the name of the flag field option\nflag_name: the name of the flag to check\n\nReturns\n\nnon-zero if the flag is set, zero if the flag isn't set, isn't of the right type, or the flags field doesn't exist.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_free","text":"av_opt_free(obj)\n\nFree all allocated objects in obj.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_freep_ranges-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_freep_ranges","text":"av_opt_freep_ranges(ranges)\n\nFree an AVOptionRanges struct and set it to NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_get-Tuple{Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_get","text":"av_opt_get(obj, name, search_flags::Integer, out_val)\n\nopt_get_funcs Option getting functions\n\n@{ Those functions get a value of the option with the given name from an object.\n\nnote: Note\nthe returned string will be av_malloc()ed and must be av_free()ed by the caller\n\nnote: Note\nif AV_OPT_ALLOW_NULL is set in search_flags in av_opt_get, and the option is of type AV_OPT_TYPE_STRING, AV_OPT_TYPE_BINARY or AV_OPT_TYPE_DICT and is set to NULL, *out_val will be set to NULL instead of an allocated empty string.\n\nArguments\n\nobj:[in] a struct whose first element is a pointer to an AVClass.\nname:[in] name of the option to get.\nsearch_flags:[in] flags passed to av_opt_find2. I.e. if AV_OPT_SEARCH_CHILDREN is passed here, then the option may be found in a child of obj.\nout_val:[out] value of the option will be written here\n\nReturns\n\n=0 on success, a negative error code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_get_array-Tuple{Any, Any, Integer, Integer, Integer, UInt32, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_get_array","text":"av_opt_get_array(obj, name, search_flags::Integer, start_elem::Integer, nb_elems::Integer, out_type::AVOptionType, out_val)\n\nFor an array-type option, retrieve the values of one or more array elements.\n\nThe array elements produced by this function will will be as if av_opt_getX() was called for each element, where X is specified by out_type. E.g. AV_OPT_TYPE_STRING corresponds to av_opt_get().\n\nTypically this should be the same as the scalarized type of the AVOption being retrieved, but certain conversions are also possible - the same as those done by the corresponding av_opt_get*() function. E.g. any option type can be retrieved as a string, numeric types can be retrieved as int64, double, or rational, etc.\n\nFor dynamically allocated types (strings, binary, dicts, etc.), the result is owned and freed by the caller.\n\nArguments\n\nstart_elem: index of the first array element to retrieve\nnb_elems: number of array elements to retrieve; start_elem+nb_elems must not be larger than array size as returned by av_opt_get_array_size()\nout_type: Option type corresponding to the desired output.\nout_val: Array with nb_elems members into which the output will be written. The array type must match the underlying C type as documented for out_type, and be zeroed on entry to this function.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_get_array_size-Tuple{Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_get_array_size","text":"av_opt_get_array_size(obj, name, search_flags::Integer, out_val)\n\nFor an array-type option, get the number of elements in the array.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_get_chlayout-Tuple{Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_get_chlayout","text":"av_opt_get_chlayout(obj, name, search_flags::Integer, layout)\n\nArguments\n\nlayout:[out] The returned layout is a copy of the actual value and must be freed with av_channel_layout_uninit() by the caller\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_get_dict_val-Tuple{Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_get_dict_val","text":"av_opt_get_dict_val(obj, name, search_flags::Integer, out_val)\n\nArguments\n\nout_val:[out] The returned dictionary is a copy of the actual value and must be freed with av_dict_free() by the caller\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_get_key_value-Tuple{Any, Any, Any, Integer, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_get_key_value","text":"av_opt_get_key_value(ropts, key_val_sep, pairs_sep, flags::Integer, rkey, rval)\n\nExtract a key-value pair from the beginning of a string.\n\nArguments\n\nropts: pointer to the options string, will be updated to point to the rest of the string (one of the pairs_sep or the final NUL)\nkey_val_sep: a 0-terminated list of characters used to separate key from value, for example '='\npairs_sep: a 0-terminated list of characters used to separate two pairs from each other, for example ':' or ','\nflags: flags; see the AV_OPT_FLAG_* values below\nrkey: parsed key; must be freed using av_free()\nrval: parsed value; must be freed using av_free()\n\nReturns\n\n=0 for success, or a negative value corresponding to an AVERROR code in case of error; in particular: AVERROR(EINVAL) if no key is present\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_is_set_to_default-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_is_set_to_default","text":"av_opt_is_set_to_default(obj, o)\n\nCheck if given option is set to its default value.\n\nOptions o must belong to the obj. This function must not be called to check child's options state.\n\nArguments\n\nobj: AVClass object to check option on\no: option to be checked\n\nReturns\n\n0 when option is set to its default, 0 when option is not set its default, <0 on error\n\nSee also\n\nav_opt_is_set_to_default_by_name().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_is_set_to_default_by_name-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_is_set_to_default_by_name","text":"av_opt_is_set_to_default_by_name(obj, name, search_flags::Integer)\n\nCheck if given option is set to its default value.\n\nArguments\n\nobj: AVClass object to check option on\nname: option name\nsearch_flags: combination of AV_OPT_SEARCH_*\n\nReturns\n\n0 when option is set to its default, 0 when option is not set its default, <0 on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_next-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_next","text":"av_opt_next(obj, prev)\n\nIterate over all AVOptions belonging to obj.\n\nArguments\n\nobj: an AVOptions-enabled struct or a double pointer to an AVClass describing it.\nprev: result of the previous call to av_opt_next() on this object or NULL\n\nReturns\n\nnext AVOption or NULL\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_ptr-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_ptr","text":"av_opt_ptr(avclass, obj, name)\n\nGets a pointer to the requested field in a struct. This function allows accessing a struct even when its fields are moved or renamed since the application making the access has been compiled,\n\ncompat: Deprecated\ndirect access to AVOption-exported fields is not supported\n\nReturns\n\na pointer to the field, it can be cast to the correct type and read or written to.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_query_ranges-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_query_ranges","text":"av_opt_query_ranges(arg1, obj, key, flags::Integer)\n\nGet a list of allowed ranges for the given option.\n\nThe returned list may depend on other fields in obj like for example profile.\n\nThe result must be freed with av_opt_freep_ranges.\n\nArguments\n\nflags: is a bitmask of flags, undefined flags should not be set and should be ignored AV_OPT_SEARCH_FAKE_OBJ indicates that the obj is a double pointer to a AVClass instead of a full instance AV_OPT_MULTI_COMPONENT_RANGE indicates that function may return more than one component,\n\nReturns\n\nnumber of components returned on success, a negative error code otherwise\n\nSee also\n\nAVOptionRanges\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_query_ranges_default-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_query_ranges_default","text":"av_opt_query_ranges_default(arg1, obj, key, flags::Integer)\n\nGet a default list of allowed ranges for the given option.\n\nThis list is constructed without using the AVClass.query_ranges() callback and can be used as fallback from within the callback.\n\nThe result must be freed with av_opt_free_ranges.\n\nArguments\n\nflags: is a bitmask of flags, undefined flags should not be set and should be ignored AV_OPT_SEARCH_FAKE_OBJ indicates that the obj is a double pointer to a AVClass instead of a full instance AV_OPT_MULTI_COMPONENT_RANGE indicates that function may return more than one component,\n\nReturns\n\nnumber of components returned on success, a negative error code otherwise\n\nSee also\n\nAVOptionRanges\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_serialize-Tuple{Any, Integer, Integer, Any, Int8, Int8}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_serialize","text":"av_opt_serialize(obj, opt_flags::Integer, flags::Integer, buffer, key_val_sep::Cchar, pairs_sep::Cchar)\n\nSerialize object's options.\n\nCreate a string containing object's serialized options. Such string may be passed back to av_opt_set_from_string() in order to restore option values. A key/value or pairs separator occurring in the serialized value or name string are escaped through the av_escape() function.\n\nwarning: Warning\nSeparators cannot be neither '\\' nor '\\0'. They also cannot be the same.\n\nArguments\n\nobj:[in] AVClass object to serialize\nopt_flags:[in] serialize options with all the specified flags set (AV_OPT_FLAG)\nflags:[in] combination of AV_OPT_SERIALIZE_* flags\nbuffer:[out] Pointer to buffer that will be allocated with string containing serialized options. Buffer must be freed by the caller when is no longer needed.\nkey_val_sep:[in] character used to separate key from value\npairs_sep:[in] character used to separate two pairs from each other\n\nReturns\n\n= 0 on success, negative on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_set-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_set","text":"av_opt_set(obj, name, val, search_flags::Integer)\n\nopt_set_funcs Option setting functions\n\n@{ Those functions set the field of obj with the given name to value.\n\nArguments\n\nobj:[in] A struct whose first element is a pointer to an AVClass.\nname:[in] the name of the field to set\nval:[in] The value to set. In case of av_opt_set() if the field is not of a string type, then the given string is parsed. SI postfixes and some named scalars are supported. If the field is of a numeric type, it has to be a numeric or named scalar. Behavior with more than one scalar and +- infix operators is undefined. If the field is of a flags type, it has to be a sequence of numeric scalars or named flags separated by '+' or '-'. Prefixing a flag with '+' causes it to be set without affecting the other flags; similarly, '-' unsets a flag. If the field is of a dictionary type, it has to be a ':' separated list of key=value parameters. Values containing ':' special characters must be escaped.\nsearch_flags: flags passed to av_opt_find2. I.e. if AV_OPT_SEARCH_CHILDREN is passed here, then the option may be set on a child of obj.\n\nReturns\n\n0 if the value has been set, or an AVERROR code in case of error: AVERROR_OPTION_NOT_FOUND if no matching option exists AVERROR(ERANGE) if the value is out of range AVERROR(EINVAL) if the value is not valid\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_set_array-Tuple{Any, Any, Integer, Integer, Integer, UInt32, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_set_array","text":"av_opt_set_array(obj, name, search_flags::Integer, start_elem::Integer, nb_elems::Integer, val_type::AVOptionType, val)\n\nAdd, replace, or remove elements for an array option. Which of these operations is performed depends on the values of val and search_flags.\n\nThe effect of this function will will be as if av_opt_setX() was called for each element, where X is specified by type. E.g. AV_OPT_TYPE_STRING corresponds to av_opt_set().\n\nTypically this should be the same as the scalarized type of the AVOption being set, but certain conversions are also possible - the same as those done by the corresponding av_opt_set*() function. E.g. any option type can be set from a string, numeric types can be set from int64, double, or rational, etc.\n\nWhen NULL, nb_elems array elements starting at start_elem are removed from the array. Any array elements remaining at the end are shifted by nb_elems towards the first element in order to keep the array contiguous.\n\nOtherwise (val is non-NULL), the type of val must match the underlying C type as documented for val_type.\n\nWhen AV_OPT_ARRAY_REPLACE is not set in search_flags, the array is enlarged by nb_elems, and the contents of val are inserted at start_elem. Previously existing array elements from start_elem onwards (if present) are shifted by nb_elems away from the first element in order to make space for the new elements.\n\nWhen AV_OPT_ARRAY_REPLACE is set in search_flags, the contents of val replace existing array elements from start_elem to start_elem+nb_elems (if present). New array size is max(start_elem + nb_elems, old array size).\n\nArguments\n\nstart_elem: Index of the first array element to modify; must not be larger than array size as returned by av_opt_get_array_size().\nnb_elems: number of array elements to modify; when val is NULL, start_elem+nb_elems must not be larger than array size as returned by av_opt_get_array_size()\nval_type: Option type corresponding to the type of val, ignored when val is NULL.\nval: Array with nb_elems elements or NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_set_chlayout-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_set_chlayout","text":"av_opt_set_chlayout(obj, name, layout, search_flags::Integer)\n\nnote: Note\nAny old chlayout present is discarded and replaced with a copy of the new one. The caller still owns layout and is responsible for uninitializing it.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_set_defaults-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_set_defaults","text":"av_opt_set_defaults(s)\n\nSet the values of all AVOption fields to their default values.\n\nArguments\n\ns: an AVOption-enabled struct (its first member must be a pointer to AVClass)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_set_defaults2-Tuple{Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_set_defaults2","text":"av_opt_set_defaults2(s, mask::Integer, flags::Integer)\n\nSet the values of all AVOption fields to their default values. Only these AVOption fields for which (opt->flags & mask) == flags will have their default applied to s.\n\nArguments\n\ns: an AVOption-enabled struct (its first member must be a pointer to AVClass)\nmask: combination of AV_OPT_FLAG_*\nflags: combination of AV_OPT_FLAG_*\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_set_dict-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_set_dict","text":"av_opt_set_dict(obj, options)\n\nSet all the options from a given dictionary on an object.\n\nArguments\n\nobj: a struct whose first element is a pointer to AVClass\noptions: options to process. This dictionary will be freed and replaced by a new one containing all options not found in obj. Of course this new dictionary needs to be freed by caller with av_dict_free().\n\nReturns\n\n0 on success, a negative AVERROR if some option was found in obj, but could not be set.\n\nSee also\n\nav_dict_copy()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_set_dict2-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_set_dict2","text":"av_opt_set_dict2(obj, options, search_flags::Integer)\n\nSet all the options from a given dictionary on an object.\n\nArguments\n\nobj: a struct whose first element is a pointer to AVClass\noptions: options to process. This dictionary will be freed and replaced by a new one containing all options not found in obj. Of course this new dictionary needs to be freed by caller with av_dict_free().\nsearch_flags: A combination of AV_OPT_SEARCH_*.\n\nReturns\n\n0 on success, a negative AVERROR if some option was found in obj, but could not be set.\n\nSee also\n\nav_dict_copy()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_set_dict_val-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_set_dict_val","text":"av_opt_set_dict_val(obj, name, val, search_flags::Integer)\n\nnote: Note\nAny old dictionary present is discarded and replaced with a copy of the new one. The caller still owns val is and responsible for freeing it.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_set_from_string-NTuple{5, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_set_from_string","text":"av_opt_set_from_string(ctx, opts, shorthand, key_val_sep, pairs_sep)\n\nParse the key-value pairs list in opts. For each key=value pair found, set the value of the corresponding option in ctx.\n\nOptions names must use only the following characters: a-z A-Z 0-9 - . / _ Separators must use characters distinct from option names and from each other.\n\nArguments\n\nctx: the AVClass object to set options on\nopts: the options string, key-value pairs separated by a delimiter\nshorthand: a NULL-terminated array of options names for shorthand notation: if the first field in opts has no key part, the key is taken from the first element of shorthand; then again for the second, etc., until either opts is finished, shorthand is finished or a named option is found; after that, all options must be named\nkey_val_sep: a 0-terminated list of characters used to separate key from value, for example '='\npairs_sep: a 0-terminated list of characters used to separate two pairs from each other, for example ':' or ','\n\nReturns\n\nthe number of successfully set key=value pairs, or a negative value corresponding to an AVERROR code in case of error: AVERROR(EINVAL) if opts cannot be parsed, the error code issued by av_set_string3() if a key/value pair cannot be set\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_opt_show2-Tuple{Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_opt_show2","text":"av_opt_show2(obj, av_log_obj, req_flags::Integer, rej_flags::Integer)\n\nShow the obj options.\n\nArguments\n\nreq_flags: requested flags for the options to show. Show only the options for which it is opt->flags & req_flags.\nrej_flags: rejected flags for the options to show. Show only the options for which it is !(opt->flags & req_flags).\nav_log_obj: log context to use for showing the options\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_output_audio_device_next-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_output_audio_device_next","text":"av_output_audio_device_next(d)\n\nAudio output devices iterator.\n\nIf d is NULL, returns the first registered output audio/video device, if d is non-NULL, returns the next registered output audio/video device after d or NULL if d is the last one.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_output_video_device_next-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_output_video_device_next","text":"av_output_video_device_next(d)\n\nVideo output devices iterator.\n\nIf d is NULL, returns the first registered output audio/video device, if d is non-NULL, returns the next registered output audio/video device after d or NULL if d is the last one.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_add_side_data-Tuple{Any, UInt32, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_add_side_data","text":"av_packet_add_side_data(pkt, type::AVPacketSideDataType, data, size::Csize_t)\n\nWrap an existing array as a packet side data.\n\nArguments\n\npkt: packet\ntype: side information type\ndata: the side data array. It must be allocated with the av_malloc() family of functions. The ownership of the data is transferred to pkt.\nsize: side information size\n\nReturns\n\na non-negative number on success, a negative AVERROR code on failure. On failure, the packet is unchanged and the data remains owned by the caller.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_alloc","text":"av_packet_alloc()\n\nAllocate an AVPacket and set its fields to default values. The resulting struct must be freed using av_packet_free().\n\nnote: Note\nthis only allocates the AVPacket itself, not the data buffers. Those must be allocated through other means such as av_new_packet.\n\nReturns\n\nAn AVPacket filled with default values or NULL on failure.\n\nSee also\n\nav_new_packet\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_clone-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_clone","text":"av_packet_clone(src)\n\nCreate a new packet that references the same data as src.\n\nThis is a shortcut for av_packet_alloc()+av_packet_ref().\n\nReturns\n\nnewly created AVPacket on success, NULL on error.\n\nSee also\n\nav_packet_alloc, av_packet_ref\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_copy_props-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_copy_props","text":"av_packet_copy_props(dst, src)\n\nCopy only \"properties\" fields from src to dst.\n\nProperties for the purpose of this function are all the fields beside those related to the packet data (buf, data, size)\n\nArguments\n\ndst: Destination packet\nsrc: Source packet\n\nReturns\n\n0 on success AVERROR on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_free","text":"av_packet_free(pkt)\n\nFree the packet, if the packet is reference counted, it will be unreferenced first.\n\nnote: Note\npassing NULL is a no-op.\n\nArguments\n\npkt: packet to be freed. The pointer will be set to NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_free_side_data-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_free_side_data","text":"av_packet_free_side_data(pkt)\n\nConvenience function to free all the side data stored. All the other fields stay untouched.\n\nArguments\n\npkt: packet\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_from_data-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_from_data","text":"av_packet_from_data(pkt, data, size::Integer)\n\nInitialize a reference-counted packet from av_malloc()ed data.\n\nArguments\n\npkt: packet to be initialized. This function will set the data, size, and buf fields, all others are left untouched.\ndata: Data allocated by av_malloc() to be used as packet data. If this function returns successfully, the data is owned by the underlying AVBuffer. The caller may not access the data through other means.\nsize: size of data in bytes, without the padding. I.e. the full buffer size is assumed to be size + AV_INPUT_BUFFER_PADDING_SIZE.\n\nReturns\n\n0 on success, a negative AVERROR on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_get_side_data-Tuple{Any, UInt32, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_get_side_data","text":"av_packet_get_side_data(pkt, type::AVPacketSideDataType, size)\n\nGet side information from packet.\n\nArguments\n\npkt: packet\ntype: desired side information type\nsize: If supplied, *size will be set to the size of the side data or to zero if the desired side data is not present.\n\nReturns\n\npointer to data if present or NULL otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_make_refcounted-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_make_refcounted","text":"av_packet_make_refcounted(pkt)\n\nEnsure the data described by a given packet is reference counted.\n\nnote: Note\nThis function does not ensure that the reference will be writable. Use av_packet_make_writable instead for that purpose.\n\nArguments\n\npkt: packet whose data should be made reference counted.\n\nReturns\n\n0 on success, a negative AVERROR on error. On failure, the packet is unchanged.\n\nSee also\n\nav_packet_ref, av_packet_make_writable\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_make_writable-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_make_writable","text":"av_packet_make_writable(pkt)\n\nCreate a writable reference for the data described by a given packet, avoiding data copy if possible.\n\nArguments\n\npkt: Packet whose data should be made writable.\n\nReturns\n\n0 on success, a negative AVERROR on failure. On failure, the packet is unchanged.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_move_ref-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_move_ref","text":"av_packet_move_ref(dst, src)\n\nMove every field in src to dst and reset src.\n\nArguments\n\nsrc: Source packet, will be reset\ndst: Destination packet\n\nSee also\n\nav_packet_unref\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_new_side_data-Tuple{Any, UInt32, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_new_side_data","text":"av_packet_new_side_data(pkt, type::AVPacketSideDataType, size::Csize_t)\n\nAllocate new information of a packet.\n\nArguments\n\npkt: packet\ntype: side information type\nsize: side information size\n\nReturns\n\npointer to fresh allocated data or NULL otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_pack_dictionary-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_pack_dictionary","text":"av_packet_pack_dictionary(dict, size)\n\nPack a dictionary for use in side_data.\n\nArguments\n\ndict: The dictionary to pack.\nsize: pointer to store the size of the returned data\n\nReturns\n\npointer to data if successful, NULL otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_ref-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_ref","text":"av_packet_ref(dst, src)\n\nSetup a new reference to the data described by a given packet\n\nIf src is reference-counted, setup dst as a new reference to the buffer in src. Otherwise allocate a new buffer in dst and copy the data from src into it.\n\nAll the other fields are copied from src.\n\nArguments\n\ndst: Destination packet. Will be completely overwritten.\nsrc: Source packet\n\nReturns\n\n0 on success, a negative AVERROR on error. On error, dst will be blank (as if returned by av_packet_alloc()).\n\nSee also\n\nav_packet_unref\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_rescale_ts-Tuple{Any, VideoIO.libffmpeg.AVRational, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_rescale_ts","text":"av_packet_rescale_ts(pkt, tb_src::AVRational, tb_dst::AVRational)\n\nConvert valid timing fields (timestamps / durations) in a packet from one timebase to another. Timestamps with unknown values (AV_NOPTS_VALUE) will be ignored.\n\nArguments\n\npkt: packet on which the conversion will be performed\ntb_src: source timebase, in which the timing fields in pkt are expressed\ntb_dst: destination timebase, to which the timing fields will be converted\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_shrink_side_data-Tuple{Any, UInt32, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_shrink_side_data","text":"av_packet_shrink_side_data(pkt, type::AVPacketSideDataType, size::Csize_t)\n\nShrink the already allocated side data buffer\n\nArguments\n\npkt: packet\ntype: side information type\nsize: new side information size\n\nReturns\n\n0 on success, < 0 on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_side_data_add-Tuple{Any, Any, UInt32, Any, UInt64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_side_data_add","text":"av_packet_side_data_add(sd, nb_sd, type::AVPacketSideDataType, data, size::Csize_t, flags::Integer)\n\nWrap existing data as packet side data.\n\nArguments\n\nsd: pointer to an array of side data to which the side data should be added. *sd may be NULL, in which case the array will be initialized\nnb_sd: pointer to an integer containing the number of entries in the array. The integer value will be increased by 1 on success.\ntype: side data type\ndata: a data array. It must be allocated with the av_malloc() family of functions. The ownership of the data is transferred to the side data array on success\nsize: size of the data array\nflags: currently unused. Must be zero\n\nReturns\n\npointer to freshly allocated side data on success, or NULL otherwise On failure, the side data array is unchanged and the data remains owned by the caller.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_side_data_free-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_side_data_free","text":"av_packet_side_data_free(sd, nb_sd)\n\nConvenience function to free all the side data stored in an array, and the array itself.\n\nArguments\n\nsd: pointer to array of side data to free. Will be set to NULL upon return.\nnb_sd: pointer to an integer containing the number of entries in the array. Will be set to 0 upon return.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_side_data_get-Tuple{Any, Integer, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_side_data_get","text":"av_packet_side_data_get(sd, nb_sd::Integer, type::AVPacketSideDataType)\n\nGet side information from a side data array.\n\nArguments\n\nsd: the array from which the side data should be fetched\nnb_sd: value containing the number of entries in the array.\ntype: desired side information type\n\nReturns\n\npointer to side data if present or NULL otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_side_data_new-Tuple{Any, Any, UInt32, UInt64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_side_data_new","text":"av_packet_side_data_new(psd, pnb_sd, type::AVPacketSideDataType, size::Csize_t, flags::Integer)\n\nAllocate a new packet side data.\n\nArguments\n\nsd: pointer to an array of side data to which the side data should be added. *sd may be NULL, in which case the array will be initialized.\nnb_sd: pointer to an integer containing the number of entries in the array. The integer value will be increased by 1 on success.\ntype: side data type\nsize: desired side data size\nflags: currently unused. Must be zero\n\nReturns\n\npointer to freshly allocated side data on success, or NULL otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_side_data_remove-Tuple{Any, Any, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_side_data_remove","text":"av_packet_side_data_remove(sd, nb_sd, type::AVPacketSideDataType)\n\nRemove side data of the given type from a side data array.\n\nArguments\n\nsd: the array from which the side data should be removed\nnb_sd: pointer to an integer containing the number of entries in the array. Will be reduced by the amount of entries removed upon return\ntype: side information type\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_unpack_dictionary-Tuple{Any, UInt64, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_unpack_dictionary","text":"av_packet_unpack_dictionary(data, size::Csize_t, dict)\n\nUnpack a dictionary from side_data.\n\nArguments\n\ndata: data from side_data\nsize: size of the data\ndict: the metadata storage dictionary\n\nReturns\n\n0 on success, < 0 on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_packet_unref-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_packet_unref","text":"av_packet_unref(pkt)\n\nWipe the packet.\n\nUnreference the buffer referenced by the packet and reset the remaining packet fields to their default values.\n\nArguments\n\npkt: The packet to be unreferenced.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_parse_color-Tuple{Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_parse_color","text":"av_parse_color(rgba_color, color_string, slen::Integer, log_ctx)\n\nPut the RGBA values that correspond to color_string in rgba_color.\n\nArguments\n\nrgba_color: 4-elements array of uint8_t values, where the respective red, green, blue and alpha component values are written.\ncolor_string: a string specifying a color. It can be the name of a color (case insensitive match) or a [0x|#]RRGGBB[AA] sequence, possibly followed by \"@\" and a string representing the alpha component. The alpha component may be a string composed by \"0x\" followed by an hexadecimal number or a decimal number between 0.0 and 1.0, which represents the opacity value (0x00/0.0 means completely transparent, 0xff/1.0 completely opaque). If the alpha component is not specified then 0xff is assumed. The string \"random\" will result in a random color.\nslen: length of the initial part of color_string containing the color. It can be set to -1 if color_string is a null terminated string containing nothing else than the color.\nlog_ctx: a pointer to an arbitrary struct of which the first field is a pointer to an AVClass struct (used for av_log()). Can be NULL.\n\nReturns\n\n= 0 in case of success, a negative value in case of failure (for example if color_string cannot be parsed).\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_parse_cpu_caps-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_parse_cpu_caps","text":"av_parse_cpu_caps(flags, s)\n\nParse CPU caps from a string and update the given AV_CPU_* flags based on that.\n\nReturns\n\nnegative on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_parse_ratio-Tuple{Any, Any, Integer, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_parse_ratio","text":"av_parse_ratio(q, str, max::Integer, log_offset::Integer, log_ctx)\n\nParse str and store the parsed ratio in q.\n\nNote that a ratio with infinite (1/0) or negative value is considered valid, so you should check on the returned value if you want to exclude those values.\n\nThe undefined value can be expressed using the \"0:0\" string.\n\nArguments\n\nq:[in,out] pointer to the AVRational which will contain the ratio\nstr:[in] the string to parse: it has to be a string in the format num:den, a float number or an expression\nmax:[in] the maximum allowed numerator and denominator\nlog_offset:[in] log level offset which is applied to the log level of log_ctx\nlog_ctx:[in] parent logging context\n\nReturns\n\n= 0 on success, a negative error code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_parse_time-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_parse_time","text":"av_parse_time(timeval, timestr, duration::Integer)\n\nParse timestr and return in *time a corresponding number of microseconds.\n\n [{YYYY-MM-DD|YYYYMMDD}[T|t| ]]{{HH:MM:SS[.m...]]]}|{HHMMSS[.m...]]]}}[Z]\n now\n\nIf the value is \"now\" it takes the current time. Time is local time unless Z is appended, in which case it is interpreted as UTC. If the year-month-day part is not specified it takes the current year-month-day. - If a duration the syntax is:\n\n [-][HH:]MM:SS[.m...]\n [-]S+[.m...]\n\nArguments\n\ntimeval: puts here the number of microseconds corresponding to the string in timestr. If the string represents a duration, it is the number of microseconds contained in the time interval. If the string is a date, is the number of microseconds since 1st of January, 1970 up to the time of the parsed date. If timestr cannot be successfully parsed, set *time to INT64_MIN.\ntimestr: a string representing a date or a duration. - If a date the syntax is:\nduration: flag which tells how to interpret timestr, if not zero timestr is interpreted as a duration, otherwise as a date\n\nReturns\n\n= 0 in case of success, a negative value corresponding to an AVERROR code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_parse_video_rate-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_parse_video_rate","text":"av_parse_video_rate(rate, str)\n\nParse str and store the detected values in *rate.\n\nArguments\n\nrate:[in,out] pointer to the AVRational which will contain the detected frame rate\nstr:[in] the string to parse: it has to be a string in the format rate_num / rate_den, a float number or a valid video rate abbreviation\n\nReturns\n\n= 0 on success, a negative error code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_parse_video_size-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_parse_video_size","text":"av_parse_video_size(width_ptr, height_ptr, str)\n\nParse str and put in width_ptr and height_ptr the detected values.\n\nArguments\n\nwidth_ptr:[in,out] pointer to the variable which will contain the detected width value\nheight_ptr:[in,out] pointer to the variable which will contain the detected height value\nstr:[in] the string to parse: it has to be a string in the format width x height or a valid video size abbreviation.\n\nReturns\n\n= 0 on success, a negative error code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_parser_iterate-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_parser_iterate","text":"av_parser_iterate(opaque)\n\nIterate over all registered codec parsers.\n\nArguments\n\nopaque: a pointer where libavcodec will store the iteration state. Must point to NULL to start the iteration.\n\nReturns\n\nthe next registered codec parser or NULL when the iteration is finished\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_parser_parse2-Tuple{Any, Any, Any, Any, Any, Integer, Int64, Int64, Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_parser_parse2","text":"av_parser_parse2(s, avctx, poutbuf, poutbuf_size, buf, buf_size::Integer, pts::Int64, dts::Int64, pos::Int64)\n\nParse a packet.\n\nExample:\n\n   while(in_len){\n       len = av_parser_parse2(myparser, AVCodecContext, &data, &size,\n                                        in_data, in_len,\n                                        pts, dts, pos);\n       in_data += len;\n       in_len  -= len;\n\n       if(size)\n          decode_frame(data, size);\n   }\n\nArguments\n\ns: parser context.\navctx: codec context.\npoutbuf: set to pointer to parsed buffer or NULL if not yet finished.\npoutbuf_size: set to size of parsed buffer or zero if not yet finished.\nbuf: input buffer.\nbuf_size: buffer size in bytes without the padding. I.e. the full buffer size is assumed to be buf_size + AV_INPUT_BUFFER_PADDING_SIZE. To signal EOF, this should be 0 (so that the last frame can be output).\npts: input presentation timestamp.\ndts: input decoding timestamp.\npos: input byte position in stream.\n\nReturns\n\nthe number of bytes of the input bitstream used.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_pix_fmt_count_planes-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_pix_fmt_count_planes","text":"av_pix_fmt_count_planes(pix_fmt::AVPixelFormat)\n\nReturns\n\nnumber of planes in pix_fmt, a negative AVERROR if pix_fmt is not a valid pixel format.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_pix_fmt_desc_get-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_pix_fmt_desc_get","text":"av_pix_fmt_desc_get(pix_fmt::AVPixelFormat)\n\nReturns\n\na pixel format descriptor for provided pixel format or NULL if this pixel format is unknown.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_pix_fmt_desc_get_id-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_pix_fmt_desc_get_id","text":"av_pix_fmt_desc_get_id(desc)\n\nReturns\n\nan AVPixelFormat id described by desc, or AV_PIX_FMT_NONE if desc is not a valid pointer to a pixel format descriptor.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_pix_fmt_desc_next-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_pix_fmt_desc_next","text":"av_pix_fmt_desc_next(prev)\n\nIterate over all pixel format descriptors known to libavutil.\n\nArguments\n\nprev: previous descriptor. NULL to get the first descriptor.\n\nReturns\n\nnext descriptor or NULL after the last descriptor\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_pix_fmt_get_chroma_sub_sample-Tuple{Int32, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_pix_fmt_get_chroma_sub_sample","text":"av_pix_fmt_get_chroma_sub_sample(pix_fmt::AVPixelFormat, h_shift, v_shift)\n\nUtility function to access log2_chroma_w log2_chroma_h from the pixel format AVPixFmtDescriptor.\n\nArguments\n\npix_fmt:[in] the pixel format\nh_shift:[out] store log2_chroma_w (horizontal/width shift)\nv_shift:[out] store log2_chroma_h (vertical/height shift)\n\nReturns\n\n0 on success, AVERROR(ENOSYS) on invalid or unknown pixel format\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_pix_fmt_swap_endianness-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_pix_fmt_swap_endianness","text":"av_pix_fmt_swap_endianness(pix_fmt::AVPixelFormat)\n\nUtility function to swap the endianness of a pixel format.\n\nArguments\n\npix_fmt:[in] the pixel format\n\nReturns\n\npixel format with swapped endianness if it exists, otherwise AV_PIX_FMT_NONE\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_pixelutils_get_sad_fn-Tuple{Integer, Integer, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_pixelutils_get_sad_fn","text":"av_pixelutils_get_sad_fn(w_bits::Integer, h_bits::Integer, aligned::Integer, log_ctx)\n\nGet a potentially optimized pointer to a Sum-of-absolute-differences function (see the av_pixelutils_sad_fn prototype).\n\nArguments\n\nw_bits: 1<<w_bits is the requested width of the block size\nh_bits: 1<<h_bits is the requested height of the block size\naligned: If set to 2, the returned sad function will assume src1 and src2 addresses are aligned on the block size. If set to 1, the returned sad function will assume src1 is aligned on the block size. If set to 0, the returned sad function assume no particular alignment.\nlog_ctx: context used for logging, can be NULL\n\nReturns\n\na pointer to the SAD function or NULL in case of error (because of invalid parameters)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_pkt_dump2-Tuple{Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_pkt_dump2","text":"av_pkt_dump2(f, pkt, dump_payload::Integer, st)\n\nSend a nice dump of a packet to the specified file stream.\n\nArguments\n\nf: The file stream pointer where the dump should be sent to.\npkt: packet to dump\ndump_payload: True if the payload must be displayed, too.\nst: AVStream that the packet belongs to\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_pkt_dump_log2-Tuple{Any, Integer, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_pkt_dump_log2","text":"av_pkt_dump_log2(avcl, level::Integer, pkt, dump_payload::Integer, st)\n\nSend a nice dump of a packet to the log.\n\nArguments\n\navcl: A pointer to an arbitrary struct of which the first field is a pointer to an AVClass struct.\nlevel: The importance level of the message, lower values signifying higher importance.\npkt: packet to dump\ndump_payload: True if the payload must be displayed, too.\nst: AVStream that the packet belongs to\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_popcount64_c-Tuple{UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_popcount64_c","text":"av_popcount64_c(x::UInt64)\n\nCount number of bits set to one in x\n\nArguments\n\nx: value to count bits of\n\nReturns\n\nthe number of bits set to one in x\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_popcount_c-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_popcount_c","text":"av_popcount_c(x::Integer)\n\nCount number of bits set to one in x\n\nArguments\n\nx: value to count bits of\n\nReturns\n\nthe number of bits set to one in x\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_probe_input_buffer-Tuple{Any, Any, Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_probe_input_buffer","text":"av_probe_input_buffer(pb, fmt, url, logctx, offset::Integer, max_probe_size::Integer)\n\nLike av_probe_input_buffer2() but returns 0 on success\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_probe_input_buffer2-Tuple{Any, Any, Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_probe_input_buffer2","text":"av_probe_input_buffer2(pb, fmt, url, logctx, offset::Integer, max_probe_size::Integer)\n\nProbe a bytestream to determine the input format. Each time a probe returns with a score that is too low, the probe buffer size is increased and another attempt is made. When the maximum probe size is reached, the input format with the highest score is returned.\n\nArguments\n\npb: the bytestream to probe\nfmt: the input format is put here\nurl: the url of the stream\nlogctx: the log context\noffset: the offset within the bytestream to probe from\nmax_probe_size: the maximum probe buffer size (zero for default)\n\nReturns\n\nthe score in case of success, a negative value corresponding to an the maximal score is AVPROBE_SCORE_MAX AVERROR code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_probe_input_format-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_probe_input_format","text":"av_probe_input_format(pd, is_opened::Integer)\n\nGuess the file format.\n\nArguments\n\npd: data to be probed\nis_opened: Whether the file is already opened; determines whether demuxers with or without AVFMT_NOFILE are probed.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_probe_input_format2-Tuple{Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_probe_input_format2","text":"av_probe_input_format2(pd, is_opened::Integer, score_max)\n\nGuess the file format.\n\nArguments\n\npd: data to be probed\nis_opened: Whether the file is already opened; determines whether demuxers with or without AVFMT_NOFILE are probed.\nscore_max: A probe score larger that this is required to accept a detection, the variable is set to the actual detection score afterwards. If the score is <= AVPROBE_SCORE_MAX / 4 it is recommended to retry with a larger probe buffer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_probe_input_format3-Tuple{Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_probe_input_format3","text":"av_probe_input_format3(pd, is_opened::Integer, score_ret)\n\nGuess the file format.\n\nArguments\n\nis_opened: Whether the file is already opened; determines whether demuxers with or without AVFMT_NOFILE are probed.\nscore_ret: The score of the best detection.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_q2d-Tuple{VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_q2d","text":"av_q2d(a::AVRational)\n\nConvert an AVRational to a double.\n\nArguments\n\na: AVRational to convert\n\nReturns\n\na in floating-point form\n\nSee also\n\nav_d2q()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_q2intfloat-Tuple{VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_q2intfloat","text":"av_q2intfloat(q::AVRational)\n\nConvert an AVRational to a IEEE 32-bit float expressed in fixed-point format.\n\nnote: Note\nThe returned value is platform-indepedant.\n\nArguments\n\nq: Rational to be converted\n\nReturns\n\nEquivalent floating-point value, expressed as an unsigned 32-bit integer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_qsv_alloc_context-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_qsv_alloc_context","text":"av_qsv_alloc_context()\n\nAllocate a new context.\n\nIt must be freed by the caller with av_free().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_random_bytes-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_random_bytes","text":"av_random_bytes(buf, len::Csize_t)\n\nGenerate cryptographically secure random data, i.e. suitable for use as encryption keys and similar.\n\n\\retval0 success, len bytes of random data was written into buf\n\n\\retval\"a negative AVERROR code\" random data could not be generated\n\nArguments\n\nbuf: buffer into which the random data will be written\nlen: size of buf in bytes\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_rc4_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_rc4_alloc","text":"av_rc4_alloc()\n\nAllocate an AVRC4 context.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_rc4_crypt-Tuple{Any, Any, Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_rc4_crypt","text":"av_rc4_crypt(d, dst, src, count::Integer, iv, decrypt::Integer)\n\nEncrypts / decrypts using the RC4 algorithm.\n\nArguments\n\nd: pointer to the AVRC4 context\ncount: number of bytes\ndst: destination array, can be equal to src\nsrc: source array, can be equal to dst, may be NULL\niv: not (yet) used for RC4, should be NULL\ndecrypt: 0 for encryption, 1 for decryption, not (yet) used\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_rc4_init-Tuple{Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_rc4_init","text":"av_rc4_init(d, key, key_bits::Integer, decrypt::Integer)\n\nInitializes an AVRC4 context.\n\nArguments\n\nd: pointer to the AVRC4 context\nkey: buffer containing the key\nkey_bits: must be a multiple of 8\ndecrypt: 0 for encryption, 1 for decryption, currently has no effect\n\nReturns\n\nzero on success, negative value otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_read_frame-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_read_frame","text":"av_read_frame(s, pkt)\n\nReturn the next frame of a stream. This function returns what is stored in the file, and does not validate that what is there are valid frames for the decoder. It will split what is stored in the file into frames and return one for each call. It will not omit invalid data between valid frames so as to give the decoder the maximum information possible for decoding.\n\nOn success, the returned packet is reference-counted (pkt->buf is set) and valid indefinitely. The packet must be freed with av_packet_unref() when it is no longer needed. For video, the packet contains exactly one frame. For audio, it contains an integer number of frames if each frame has a known fixed size (e.g. PCM or ADPCM data). If the audio frames have a variable size (e.g. MPEG audio), then it contains one frame.\n\npkt->pts, pkt->dts and pkt->duration are always set to correct values in AVStream.time_base units (and guessed if the format cannot provide them). pkt->pts can be AV_NOPTS_VALUE if the video format has B-frames, so it is better to rely on pkt->dts if you do not decompress the payload.\n\nnote: Note\npkt will be initialized, so it may be uninitialized, but it must not contain data that needs to be freed.\n\nReturns\n\n0 if OK, < 0 on error or end of file. On error, pkt will be blank (as if it came from av_packet_alloc()).\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_read_image_line2-Tuple{Any, Any, Any, Any, Vararg{Integer, 6}}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_read_image_line2","text":"av_read_image_line2(dst, data, linesize, desc, x::Integer, y::Integer, c::Integer, w::Integer, read_pal_component::Integer, dst_element_size::Integer)\n\nRead a line from an image, and write the values of the pixel format component c to dst.\n\nArguments\n\ndata: the array containing the pointers to the planes of the image\nlinesize: the array containing the linesizes of the image\ndesc: the pixel format descriptor for the image\nx: the horizontal coordinate of the first pixel to read\ny: the vertical coordinate of the first pixel to read\nw: the width of the line to read, that is the number of values to write to dst\nread_pal_component: if not zero and the format is a paletted format writes the values corresponding to the palette component c in data[1] to dst, rather than the palette indexes in data[0]. The behavior is undefined if the format is not paletted.\ndst_element_size: size of elements in dst array (2 or 4 byte)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_read_pause-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_read_pause","text":"av_read_pause(s)\n\nPause a network-based stream (e.g. RTSP stream).\n\nUse av_read_play() to resume it.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_read_play-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_read_play","text":"av_read_play(s)\n\nStart playing a network-based stream (e.g. RTSP stream) at the current position.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_realloc-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_realloc","text":"av_realloc(ptr, size::Csize_t)\n\nAllocate, reallocate, or free a block of memory.\n\nIf ptr is NULL and size > 0, allocate a new block. Otherwise, expand or shrink that block of memory according to size.\n\nwarning: Warning\nUnlike av_malloc(), the returned pointer is not guaranteed to be correctly aligned. The returned pointer must be freed after even if size is zero.\n\nArguments\n\nptr: Pointer to a memory block already allocated with av_realloc() or NULL\nsize: Size in bytes of the memory block to be allocated or reallocated\n\nReturns\n\nPointer to a newly-reallocated block or NULL if the block cannot be reallocated\n\nSee also\n\nav_fast_realloc(), av_reallocp()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_realloc_array-Tuple{Any, UInt64, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_realloc_array","text":"av_realloc_array(ptr, nmemb::Csize_t, size::Csize_t)\n\nAllocate, reallocate, or free an array.\n\nIf ptr is NULL and nmemb > 0, allocate a new block.\n\nwarning: Warning\nUnlike av_malloc(), the allocated memory is not guaranteed to be correctly aligned. The returned pointer must be freed after even if nmemb is zero.\n\nArguments\n\nptr: Pointer to a memory block already allocated with av_realloc() or NULL\nnmemb: Number of elements in the array\nsize: Size of the single element of the array\n\nReturns\n\nPointer to a newly-reallocated block or NULL if the block cannot be reallocated\n\nSee also\n\nav_reallocp_array()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_realloc_f-Tuple{Any, UInt64, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_realloc_f","text":"av_realloc_f(ptr, nelem::Csize_t, elsize::Csize_t)\n\nAllocate, reallocate, or free a block of memory.\n\nThis function does the same thing as av_realloc(), except: - It takes two size arguments and allocates nelem * elsize bytes, after checking the result of the multiplication for integer overflow. - It frees the input block in case of failure, thus avoiding the memory leak with the classic\n\n{.c}\n   buf = realloc(buf);\n   if (!buf)\n       return -1;\n\npattern.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_reallocp-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_reallocp","text":"av_reallocp(ptr, size::Csize_t)\n\nAllocate, reallocate, or free a block of memory through a pointer to a pointer.\n\nIf *ptr is NULL and size > 0, allocate a new block. If size is zero, free the memory block pointed to by *ptr. Otherwise, expand or shrink that block of memory according to size.\n\nwarning: Warning\nUnlike av_malloc(), the allocated memory is not guaranteed to be correctly aligned.\n\nArguments\n\nptr:[in,out] Pointer to a pointer to a memory block already allocated with av_realloc(), or a pointer to NULL. The pointer is updated on success, or freed on failure.\nsize:[in] Size in bytes for the memory block to be allocated or reallocated\n\nReturns\n\nZero on success, an AVERROR error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_reallocp_array-Tuple{Any, UInt64, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_reallocp_array","text":"av_reallocp_array(ptr, nmemb::Csize_t, size::Csize_t)\n\nAllocate, reallocate an array through a pointer to a pointer.\n\nIf *ptr is NULL and nmemb > 0, allocate a new block.\n\nwarning: Warning\nUnlike av_malloc(), the allocated memory is not guaranteed to be correctly aligned. *ptr must be freed after even if nmemb is zero.\n\nArguments\n\nptr:[in,out] Pointer to a pointer to a memory block already allocated with av_realloc(), or a pointer to NULL. The pointer is updated on success, or freed on failure.\nnmemb:[in] Number of elements\nsize:[in] Size of the single element\n\nReturns\n\nZero on success, an AVERROR error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_reduce-Tuple{Any, Any, Int64, Int64, Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_reduce","text":"av_reduce(dst_num, dst_den, num::Int64, den::Int64, max::Int64)\n\nReduce a fraction.\n\nThis is useful for framerate calculations.\n\nArguments\n\ndst_num:[out] Destination numerator\ndst_den:[out] Destination denominator\nnum:[in] Source numerator\nden:[in] Source denominator\nmax:[in] Maximum allowed values for dst_num & dst_den\n\nReturns\n\n1 if the operation is exact, 0 otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_alloc_ext-Tuple{UInt64, Integer, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_alloc_ext","text":"av_refstruct_alloc_ext(size::Csize_t, flags::Integer, opaque, free_cb)\n\nA wrapper around av_refstruct_alloc_ext_c() for the common case of a non-const qualified opaque.\n\nSee also\n\nav_refstruct_alloc_ext_c()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_alloc_ext_c-Tuple{UInt64, Integer, VideoIO.libffmpeg.AVRefStructOpaque, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_alloc_ext_c","text":"av_refstruct_alloc_ext_c(size::Csize_t, flags::Integer, opaque::AVRefStructOpaque, free_cb)\n\nAllocate a refcounted object of usable size size managed via the RefStruct API.\n\nBy default (in the absence of flags to the contrary), the returned object is initially zeroed.\n\nArguments\n\nsize: Desired usable size of the returned object.\nflags: A bitwise combination of AV_REFSTRUCT_FLAG_* flags.\nopaque: A pointer that will be passed to the free_cb callback.\nfree_cb: A callback for freeing this object's content when its reference count reaches zero; it must not free the object itself.\n\nReturns\n\nA pointer to an object of the desired size or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_allocz-Tuple{UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_allocz","text":"av_refstruct_allocz(size::Csize_t)\n\nEquivalent to av_refstruct_alloc_ext(size, 0, NULL, NULL)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_exclusive-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_exclusive","text":"av_refstruct_exclusive(obj)\n\nCheck whether the reference count of an object managed via this API is 1.\n\nArguments\n\nobj: A pointer to an object managed via this API.\n\nReturns\n\n1 if the reference count of obj is 1; 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_pool_alloc-Tuple{UInt64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_pool_alloc","text":"av_refstruct_pool_alloc(size::Csize_t, flags::Integer)\n\nEquivalent to av_refstruct_pool_alloc(size, flags, NULL, NULL, NULL, NULL, NULL)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_pool_alloc_ext-Tuple{UInt64, Integer, Vararg{Any, 5}}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_pool_alloc_ext","text":"av_refstruct_pool_alloc_ext(size::Csize_t, flags::Integer, opaque, init_cb, reset_cb, free_entry_cb, free_cb)\n\nA wrapper around av_refstruct_pool_alloc_ext_c() for the common case of a non-const qualified opaque.\n\nSee also\n\nav_refstruct_pool_alloc_ext_c()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_pool_alloc_ext_c-Tuple{UInt64, Integer, VideoIO.libffmpeg.AVRefStructOpaque, Vararg{Any, 4}}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_pool_alloc_ext_c","text":"av_refstruct_pool_alloc_ext_c(size::Csize_t, flags::Integer, opaque::AVRefStructOpaque, init_cb, reset_cb, free_entry_cb, free_cb)\n\nAllocate an AVRefStructPool, potentially using complex callbacks.\n\nArguments\n\nsize: size of the entries of the pool\nflags: a bitwise combination of AV_REFSTRUCT_POOL_FLAG_* flags\nopaque: A pointer that will be passed to the callbacks below.\ninit: A callback that will be called directly after a new entry has been allocated. obj has already been zeroed unless the AV_REFSTRUCT_POOL_FLAG_NO_ZEROING flag is in use.\nreset: A callback that will be called after an entry has been returned to the pool and before it is reused.\nfree_entry: A callback that will be called when an entry is freed after the pool has been marked as to be uninitialized.\nfree: A callback that will be called when the pool itself is freed (after the last entry has been returned and freed).\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_pool_get-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_pool_get","text":"av_refstruct_pool_get(pool)\n\nGet an object from the pool, reusing an old one from the pool when available.\n\nEvery call to this function must happen before av_refstruct_pool_uninit(). Otherwise undefined behaviour may occur.\n\nArguments\n\npool: the pool from which to get the object\n\nReturns\n\na reference to the object on success, NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_pool_uninit-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_pool_uninit","text":"av_refstruct_pool_uninit(poolp)\n\nMark the pool as being available for freeing. It will actually be freed only once all the allocated buffers associated with the pool are released. Thus it is safe to call this function while some of the allocated buffers are still in use.\n\nIt is illegal to try to get a new entry after this function has been called.\n\nArguments\n\npoolp: pointer to a pointer to either NULL or a pool to be freed. *poolp will be set to NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_ref-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_ref","text":"av_refstruct_ref(obj)\n\nCreate a new reference to an object managed via this API, i.e. increment the reference count of the underlying object and return obj.\n\nReturns\n\na pointer equal to obj.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_ref_c-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_ref_c","text":"av_refstruct_ref_c(obj)\n\nAnalog of av_refstruct_ref(), but for constant objects.\n\nSee also\n\nav_refstruct_ref()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_replace-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_replace","text":"av_refstruct_replace(dstp, src)\n\nEnsure *dstp refers to the same object as src.\n\nIf *dstp is already equal to src, do nothing. Otherwise unreference *dstp and replace it with a new reference to src in case src != NULL (this involves incrementing the reference count of src's underlying object) or with NULL otherwise.\n\nArguments\n\ndstp: Pointer to a pointer that is either NULL or points to an object managed via this API.\nsrc: A pointer to an object managed via this API or NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_refstruct_unref-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_refstruct_unref","text":"av_refstruct_unref(objp)\n\nDecrement the reference count of the underlying object and automatically free the object if there are no more references to it.\n\n*objp == NULL is legal and a no-op.\n\nArguments\n\nobjp: Pointer to a pointer that is either NULL or points to an object managed via this API. *objp is set to NULL on return.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_rescale-Tuple{Int64, Int64, Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_rescale","text":"av_rescale(a::Int64, b::Int64, c::Int64)\n\nRescale a 64-bit integer with rounding to nearest.\n\nThe operation is mathematically equivalent to a * b / c, but writing that directly can overflow.\n\nThis function is equivalent to av_rescale_rnd() with #AV_ROUND_NEAR_INF.\n\nSee also\n\nav_rescale_rnd(), av_rescale_q(), av_rescale_q_rnd()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_rescale_delta-Tuple{VideoIO.libffmpeg.AVRational, Int64, VideoIO.libffmpeg.AVRational, Integer, Any, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_rescale_delta","text":"av_rescale_delta(in_tb::AVRational, in_ts::Int64, fs_tb::AVRational, duration::Integer, last, out_tb::AVRational)\n\nRescale a timestamp while preserving known durations.\n\nThis function is designed to be called per audio packet to scale the input timestamp to a different time base. Compared to a simple av_rescale_q() call, this function is robust against possible inconsistent frame durations.\n\nThe last parameter is a state variable that must be preserved for all subsequent calls for the same stream. For the first call, *last should be initialized to #AV_NOPTS_VALUE.\n\nnote: Note\nIn the context of this function, \"duration\" is in term of samples, not seconds.\n\nArguments\n\nin_tb:[in] Input time base\nin_ts:[in] Input timestamp\nfs_tb:[in] Duration time base; typically this is finer-grained (greater) than in_tb and out_tb\nduration:[in] Duration till the next call to this function (i.e. duration of the current packet/frame)\nlast:[in,out] Pointer to a timestamp expressed in terms of fs_tb, acting as a state variable\nout_tb:[in] Output timebase\n\nReturns\n\nTimestamp expressed in terms of out_tb\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_rescale_q-Tuple{Int64, VideoIO.libffmpeg.AVRational, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_rescale_q","text":"av_rescale_q(a::Int64, bq::AVRational, cq::AVRational)\n\nRescale a 64-bit integer by 2 rational numbers.\n\nThe operation is mathematically equivalent to a * bq / cq.\n\nThis function is equivalent to av_rescale_q_rnd() with #AV_ROUND_NEAR_INF.\n\nSee also\n\nav_rescale(), av_rescale_rnd(), av_rescale_q_rnd()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_rescale_q_rnd-Tuple{Int64, VideoIO.libffmpeg.AVRational, VideoIO.libffmpeg.AVRational, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_rescale_q_rnd","text":"av_rescale_q_rnd(a::Int64, bq::AVRational, cq::AVRational, rnd::AVRounding)\n\nRescale a 64-bit integer by 2 rational numbers with specified rounding.\n\nThe operation is mathematically equivalent to a * bq / cq.\n\nSee also\n\nav_rescale(), av_rescale_rnd(), av_rescale_q()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_rescale_rnd-Tuple{Int64, Int64, Int64, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_rescale_rnd","text":"av_rescale_rnd(a::Int64, b::Int64, c::Int64, rnd::AVRounding)\n\nRescale a 64-bit integer with specified rounding.\n\nThe operation is mathematically equivalent to a * b / c, but writing that directly can overflow, and does not support different rounding methods. If the result is not representable then INT64_MIN is returned.\n\nSee also\n\nav_rescale(), av_rescale_q(), av_rescale_q_rnd()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_ripemd_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_ripemd_alloc","text":"av_ripemd_alloc()\n\nAllocate an AVRIPEMD context.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_ripemd_final-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_ripemd_final","text":"av_ripemd_final(context, digest)\n\nFinish hashing and output digest value.\n\nArguments\n\ncontext: hash function context\ndigest: buffer where output digest value is stored\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_ripemd_init-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_ripemd_init","text":"av_ripemd_init(context, bits::Integer)\n\nInitialize RIPEMD hashing.\n\nArguments\n\ncontext: pointer to the function context (of size av_ripemd_size)\nbits: number of bits in digest (128, 160, 256 or 320 bits)\n\nReturns\n\nzero if initialization succeeded, -1 otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_ripemd_update-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_ripemd_update","text":"av_ripemd_update(context, data, len::Csize_t)\n\nUpdate hash value.\n\nArguments\n\ncontext: hash function context\ndata: input data to update hash with\nlen: input data length\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sample_fmt_is_planar-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sample_fmt_is_planar","text":"av_sample_fmt_is_planar(sample_fmt::AVSampleFormat)\n\nCheck if the sample format is planar.\n\nArguments\n\nsample_fmt: the sample format to inspect\n\nReturns\n\n1 if the sample format is planar, 0 if it is interleaved\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_samples_alloc-Tuple{Any, Any, Integer, Integer, Int32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_samples_alloc","text":"av_samples_alloc(audio_data, linesize, nb_channels::Integer, nb_samples::Integer, sample_fmt::AVSampleFormat, align::Integer)\n\nAllocate a samples buffer for nb_samples samples, and fill data pointers and linesize accordingly. The allocated samples buffer can be freed by using av_freep(&audio_data[0]) Allocated data will be initialized to silence.\n\n\\todo return the size of the allocated buffer in case of success at the next bump\n\nArguments\n\naudio_data:[out] array to be filled with the pointer for each channel\nlinesize:[out] aligned size for audio buffer(s), may be NULL\nnb_channels: number of audio channels\nnb_samples: number of samples per channel\nsample_fmt: the sample format\nalign: buffer size alignment (0 = default, 1 = no alignment)\n\nReturns\n\n=0 on success or a negative error code on failure\n\nSee also\n\nenum AVSampleFormat The documentation for AVSampleFormat describes the data layout., av_samples_fill_arrays(), av_samples_alloc_array_and_samples()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_samples_alloc_array_and_samples-Tuple{Any, Any, Integer, Integer, Int32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_samples_alloc_array_and_samples","text":"av_samples_alloc_array_and_samples(audio_data, linesize, nb_channels::Integer, nb_samples::Integer, sample_fmt::AVSampleFormat, align::Integer)\n\nAllocate a data pointers array, samples buffer for nb_samples samples, and fill data pointers and linesize accordingly.\n\nThis is the same as av_samples_alloc(), but also allocates the data pointers array.\n\nSee also\n\nav_samples_alloc()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_samples_copy-Tuple{Any, Any, Integer, Integer, Integer, Integer, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_samples_copy","text":"av_samples_copy(dst, src, dst_offset::Integer, src_offset::Integer, nb_samples::Integer, nb_channels::Integer, sample_fmt::AVSampleFormat)\n\nCopy samples from src to dst.\n\nArguments\n\ndst: destination array of pointers to data planes\nsrc: source array of pointers to data planes\ndst_offset: offset in samples at which the data will be written to dst\nsrc_offset: offset in samples at which the data will be read from src\nnb_samples: number of samples to be copied\nnb_channels: number of audio channels\nsample_fmt: audio sample format\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_samples_fill_arrays-Tuple{Any, Any, Any, Integer, Integer, Int32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_samples_fill_arrays","text":"av_samples_fill_arrays(audio_data, linesize, buf, nb_channels::Integer, nb_samples::Integer, sample_fmt::AVSampleFormat, align::Integer)\n\nFill plane data pointers and linesize for samples with sample format sample_fmt.\n\nThe audio_data array is filled with the pointers to the samples data planes: for planar, set the start point of each channel's data within the buffer, for packed, set the start point of the entire buffer only.\n\nThe value pointed to by linesize is set to the aligned size of each channel's data buffer for planar layout, or to the aligned size of the buffer for all channels for packed layout.\n\nThe buffer in buf must be big enough to contain all the samples (use av_samples_get_buffer_size() to compute its minimum size), otherwise the audio_data pointers will point to invalid data.\n\nArguments\n\naudio_data:[out] array to be filled with the pointer for each channel\nlinesize:[out] calculated linesize, may be NULL\nbuf: the pointer to a buffer containing the samples\nnb_channels: the number of channels\nnb_samples: the number of samples in a single channel\nsample_fmt: the sample format\nalign: buffer size alignment (0 = default, 1 = no alignment)\n\nReturns\n\nminimum size in bytes required for the buffer on success, or a negative error code on failure\n\nSee also\n\nenum AVSampleFormat The documentation for AVSampleFormat describes the data layout.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_samples_get_buffer_size-Tuple{Any, Integer, Integer, Int32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_samples_get_buffer_size","text":"av_samples_get_buffer_size(linesize, nb_channels::Integer, nb_samples::Integer, sample_fmt::AVSampleFormat, align::Integer)\n\nGet the required buffer size for the given audio parameters.\n\nArguments\n\nlinesize:[out] calculated linesize, may be NULL\nnb_channels: the number of channels\nnb_samples: the number of samples in a single channel\nsample_fmt: the sample format\nalign: buffer size alignment (0 = default, 1 = no alignment)\n\nReturns\n\nrequired buffer size, or negative error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_samples_set_silence-Tuple{Any, Integer, Integer, Integer, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_samples_set_silence","text":"av_samples_set_silence(audio_data, offset::Integer, nb_samples::Integer, nb_channels::Integer, sample_fmt::AVSampleFormat)\n\nFill an audio buffer with silence.\n\nArguments\n\naudio_data: array of pointers to data planes\noffset: offset in samples at which to start filling\nnb_samples: number of samples to fill\nnb_channels: number of audio channels\nsample_fmt: audio sample format\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sat_add32_c-Tuple{Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sat_add32_c","text":"av_sat_add32_c(a::Integer, b::Integer)\n\nAdd two signed 32-bit values with saturation.\n\nArguments\n\na: one value\nb: another value\n\nReturns\n\nsum with signed saturation\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sat_add64_c-Tuple{Int64, Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sat_add64_c","text":"av_sat_add64_c(a::Int64, b::Int64)\n\nAdd two signed 64-bit values with saturation.\n\nArguments\n\na: one value\nb: another value\n\nReturns\n\nsum with signed saturation\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sat_dadd32_c-Tuple{Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sat_dadd32_c","text":"av_sat_dadd32_c(a::Integer, b::Integer)\n\nAdd a doubled value to another value with saturation at both stages.\n\nArguments\n\na: first value\nb: value doubled and added to a\n\nReturns\n\nsum sat(a + sat(2*b)) with signed saturation\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sat_dsub32_c-Tuple{Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sat_dsub32_c","text":"av_sat_dsub32_c(a::Integer, b::Integer)\n\nSubtract a doubled value from another value with saturation at both stages.\n\nArguments\n\na: first value\nb: value doubled and subtracted from a\n\nReturns\n\ndifference sat(a - sat(2*b)) with signed saturation\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sat_sub32_c-Tuple{Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sat_sub32_c","text":"av_sat_sub32_c(a::Integer, b::Integer)\n\nSubtract two signed 32-bit values with saturation.\n\nArguments\n\na: one value\nb: another value\n\nReturns\n\ndifference with signed saturation\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sat_sub64_c-Tuple{Int64, Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sat_sub64_c","text":"av_sat_sub64_c(a::Int64, b::Int64)\n\nSubtract two signed 64-bit values with saturation.\n\nArguments\n\na: one value\nb: another value\n\nReturns\n\ndifference with signed saturation\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sdp_create-Tuple{Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sdp_create","text":"av_sdp_create(ac, n_files::Integer, buf, size::Integer)\n\nGenerate an SDP for an RTP session.\n\nNote, this overwrites the id values of AVStreams in the muxer contexts for getting unique dynamic payload types.\n\nArguments\n\nac: array of AVFormatContexts describing the RTP streams. If the array is composed by only one context, such context can contain multiple AVStreams (one AVStream per RTP stream). Otherwise, all the contexts in the array (an AVCodecContext per RTP stream) must contain only one AVStream.\nn_files: number of AVCodecContexts contained in ac\nbuf: buffer where the SDP will be stored (must be allocated by the caller)\nsize: the size of the buffer\n\nReturns\n\n0 if OK, AVERROR_xxx on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_seek_frame-Tuple{Any, Integer, Int64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_seek_frame","text":"av_seek_frame(s, stream_index::Integer, timestamp::Int64, flags::Integer)\n\nSeek to the keyframe at timestamp. 'timestamp' in 'stream_index'.\n\nArguments\n\ns: media file handle\nstream_index: If stream_index is (-1), a default stream is selected, and timestamp is automatically converted from AV_TIME_BASE units to the stream specific time_base.\ntimestamp: Timestamp in AVStream.time_base units or, if no stream is specified, in AV_TIME_BASE units.\nflags: flags which select direction and seeking mode\n\nReturns\n\n= 0 on success\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_set_options_string-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_set_options_string","text":"av_set_options_string(ctx, opts, key_val_sep, pairs_sep)\n\nParse the key/value pairs list in opts. For each key/value pair found, stores the value in the field in ctx that is named like the key. ctx must be an AVClass context, storing is done using AVOptions.\n\nArguments\n\nopts: options string to parse, may be NULL\nkey_val_sep: a 0-terminated list of characters used to separate key from value\npairs_sep: a 0-terminated list of characters used to separate two pairs from each other\n\nReturns\n\nthe number of successfully set key/value pairs, or a negative value corresponding to an AVERROR code in case of error: AVERROR(EINVAL) if opts cannot be parsed, the error code issued by av_opt_set() if a key/value pair cannot be set\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sha512_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sha512_alloc","text":"av_sha512_alloc()\n\nAllocate an AVSHA512 context.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sha512_final-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sha512_final","text":"av_sha512_final(context, digest)\n\nFinish hashing and output digest value.\n\nArguments\n\ncontext: hash function context\ndigest: buffer where output digest value is stored\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sha512_init-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sha512_init","text":"av_sha512_init(context, bits::Integer)\n\nInitialize SHA-2 512 hashing.\n\nArguments\n\ncontext: pointer to the function context (of size av_sha512_size)\nbits: number of bits in digest (224, 256, 384 or 512 bits)\n\nReturns\n\nzero if initialization succeeded, -1 otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sha512_update-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sha512_update","text":"av_sha512_update(context, data, len::Csize_t)\n\nUpdate hash value.\n\nArguments\n\ncontext: hash function context\ndata: input data to update hash with\nlen: input data length\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sha_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sha_alloc","text":"av_sha_alloc()\n\nAllocate an AVSHA context.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sha_final-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sha_final","text":"av_sha_final(context, digest)\n\nFinish hashing and output digest value.\n\nArguments\n\ncontext: hash function context\ndigest: buffer where output digest value is stored\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sha_init-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sha_init","text":"av_sha_init(context, bits::Integer)\n\nInitialize SHA-1 or SHA-2 hashing.\n\nArguments\n\ncontext: pointer to the function context (of size av_sha_size)\nbits: number of bits in digest (SHA-1 - 160 bits, SHA-2 224 or 256 bits)\n\nReturns\n\nzero if initialization succeeded, -1 otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sha_update-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sha_update","text":"av_sha_update(ctx, data, len::Csize_t)\n\nUpdate hash value.\n\nArguments\n\nctx: hash function context\ndata: input data to update hash with\nlen: input data length\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_shrink_packet-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_shrink_packet","text":"av_shrink_packet(pkt, size::Integer)\n\nReduce packet size, correctly zeroing padding\n\nArguments\n\npkt: packet\nsize: new size\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_size_mult-Tuple{UInt64, UInt64, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_size_mult","text":"av_size_mult(a::Csize_t, b::Csize_t, r)\n\nMultiply two size_t values checking for overflow.\n\nArguments\n\na:[in] Operand of multiplication\nb:[in] Operand of multiplication\nr:[out] Pointer to the result of the operation\n\nReturns\n\n0 on success, AVERROR(EINVAL) on overflow\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_small_strptime-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_small_strptime","text":"av_small_strptime(p, fmt, dt)\n\nSimplified version of strptime\n\nParse the input string p according to the format string fmt and store its results in the structure dt. This implementation supports only a subset of the formats supported by the standard strptime().\n\nThe supported input field descriptors are listed below. - %H: the hour as a decimal number, using a 24-hour clock, in the range '00' through '23' - %J: hours as a decimal number, in the range '0' through INT_MAX - %M: the minute as a decimal number, using a 24-hour clock, in the range '00' through '59' - %S: the second as a decimal number, using a 24-hour clock, in the range '00' through '59' - %Y: the year as a decimal number, using the Gregorian calendar - %m: the month as a decimal number, in the range '1' through '12' - %d: the day of the month as a decimal number, in the range '1' through '31' - %T: alias for %H:%M:%S - %%: a literal %\n\nReturns\n\na pointer to the first character not processed in this function call. In case the input string contains more characters than required by the format string the return value points right after the last consumed input character. In case the whole input string is consumed the return value points to the null byte at the end of the string. On failure NULL is returned.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_smpte_291m_anc_8bit_decode-Tuple{Any, UInt32, UInt16, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_smpte_291m_anc_8bit_decode","text":"av_smpte_291m_anc_8bit_decode(out, sample_coding::AVSmpte436mPayloadSampleCoding, sample_count::UInt16, payload, log_ctx)\n\nDecode a AVSmpte436mCodedAnc payload into AVSmpte291mAnc8bit\n\nArguments\n\nsample_coding:[in] the payload sample coding\nsample_count:[in] the number of samples stored in the payload\npayload:[in] the bytes storing the payload, the needed size can be obtained from avpriv_smpte_436m_coded_anc_payload_size\nlog_ctx:[in] context pointer for av_log\nout:[out] The decoded ANC packet.\n\nReturns\n\nreturns 0 on success, otherwise < 0.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_smpte_291m_anc_8bit_encode-Tuple{Any, UInt16, UInt32, UInt32, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_smpte_291m_anc_8bit_encode","text":"av_smpte_291m_anc_8bit_encode(out, line_number::UInt16, wrapping_type::AVSmpte436mWrappingType, sample_coding::AVSmpte436mPayloadSampleCoding, payload, log_ctx)\n\nEncode a AVSmpte291mAnc8bit into a AVSmpte436mCodedAnc\n\nArguments\n\nline_number:[in] the line number the ANC packet is on\nwrapping_type:[in] the wrapping type\nsample_coding:[in] the payload sample coding\npayload:[in] the ANC packet to encode.\nlog_ctx:[in] context pointer for av_log\nout:[out] The encoded ANC packet.\n\nReturns\n\nreturns 0 on success, otherwise < 0.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_smpte_291m_anc_8bit_extract_cta_708-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_smpte_291m_anc_8bit_extract_cta_708","text":"av_smpte_291m_anc_8bit_extract_cta_708(anc, cc_data, log_ctx)\n\nTry to decode an ANC packet into EIA-608/CTA-708 data (AV_CODEC_ID_EIA_608). This\n\nArguments\n\nanc:[in] The ANC packet.\nlog_ctx:[in] Context pointer for av_log\ncc_data:[out] the buffer to store the extracted EIA-608/CTA-708 data, you can pass NULL to not store the data. the required size is 3 * cc_count bytes. SMPTE_291M_ANC_PAYLOAD_CAPACITY is always enough size.\n\nReturns\n\nreturns cc_count (>= 0) on success, AVERROR(EAGAIN) if it wasn't a CTA-708 ANC packet, < 0 on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_smpte_291m_anc_8bit_fill_checksum-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_smpte_291m_anc_8bit_fill_checksum","text":"av_smpte_291m_anc_8bit_fill_checksum(anc)\n\nFill in the correct checksum for a AVSmpte291mAnc8bit\n\nArguments\n\nanc:[in,out] The ANC packet.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_smpte_291m_anc_8bit_get_sample_count-Tuple{Any, UInt32, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_smpte_291m_anc_8bit_get_sample_count","text":"av_smpte_291m_anc_8bit_get_sample_count(anc, sample_coding::AVSmpte436mPayloadSampleCoding, log_ctx)\n\nCompute the sample count needed to encode a AVSmpte291mAnc8bit into a AVSmpte436mCodedAnc payload\n\nArguments\n\nanc:[in] The ANC packet.\nsample_coding:[in] The sample coding.\nlog_ctx:[in] context pointer for av_log\n\nReturns\n\nreturns the sample count on success, otherwise < 0.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_smpte_436m_anc_append-Tuple{Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_smpte_436m_anc_append","text":"av_smpte_436m_anc_append(pkt, anc_packet_count::Integer, anc_packets)\n\nAppend more ANC packets to a single AV_CODEC_ID_SMPTE_436M_ANC AVPacket's data.\n\nArguments\n\nanc_packet_count:[in] number of ANC packets to encode\nanc_packets:[in] the ANC packets to encode\npkt: the AVPacket to append to. it must either be size 0 or contain valid SMPTE_436M_ANC data.\n\nReturns\n\n0 on success, AVERROR codes otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_smpte_436m_anc_encode-Tuple{Any, Integer, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_smpte_436m_anc_encode","text":"av_smpte_436m_anc_encode(out, size::Integer, anc_packet_count::Integer, anc_packets)\n\nEncode ANC packets into a single AV_CODEC_ID_SMPTE_436M_ANC AVPacket's data.\n\nArguments\n\nanc_packet_count:[in] number of ANC packets to encode\nanc_packets:[in] the ANC packets to encode\nsize:[in] the size of out. ignored if out is NULL.\nout:[out] Output bytes. Doesn't write anything if out is NULL.\n\nReturns\n\nthe number of bytes written on success, AVERROR codes otherwise. If out is NULL, returns the number of bytes it would have written.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_smpte_436m_anc_iter_init-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_smpte_436m_anc_iter_init","text":"av_smpte_436m_anc_iter_init(iter, buf, buf_size::Integer)\n\nSet up iteration over the ANC packets in a single AV_CODEC_ID_SMPTE_436M_ANC AVPacket's data.\n\nArguments\n\nbuf:[in] Pointer to the data from a AV_CODEC_ID_SMPTE_436M_ANC AVPacket.\nbuf_size:[in] Size of the data from a AV_CODEC_ID_SMPTE_436M_ANC AVPacket.\niter:[out] Pointer to the iterator.\n\nReturns\n\n0 on success, AVERROR codes otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_smpte_436m_anc_iter_next-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_smpte_436m_anc_iter_next","text":"av_smpte_436m_anc_iter_next(iter, anc)\n\nGet the next ANC packet from the iterator, advancing the iterator.\n\nArguments\n\niter:[in,out] Pointer to the iterator.\nanc:[out] The returned ANC packet.\n\nReturns\n\n0 on success, AVERROR_EOF when the iterator has reached the end, AVERROR codes otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_smpte_436m_coded_anc_payload_size-Tuple{UInt32, UInt16}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_smpte_436m_coded_anc_payload_size","text":"av_smpte_436m_coded_anc_payload_size(sample_coding::AVSmpte436mPayloadSampleCoding, sample_count::UInt16)\n\nGet the minimum number of bytes needed to store a AVSmpte436mCodedAnc payload.\n\nArguments\n\nsample_coding: the payload sample coding\nsample_count: the number of samples stored in the payload\n\nReturns\n\nreturns the minimum number of bytes needed, on error returns < 0. always <= SMPTE_436M_CODED_ANC_PAYLOAD_CAPACITY\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_smpte_436m_coded_anc_validate-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_smpte_436m_coded_anc_validate","text":"av_smpte_436m_coded_anc_validate(anc)\n\nValidate a AVSmpte436mCodedAnc structure. Doesn't check if the payload is valid.\n\nArguments\n\nanc:[in] ANC packet to validate\n\nReturns\n\n0 on success, AVERROR codes otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_spherical_alloc-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_spherical_alloc","text":"av_spherical_alloc(size)\n\nAllocate a AVSphericalVideo structure and initialize its fields to default values.\n\nReturns\n\nthe newly allocated struct or NULL on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_spherical_from_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_spherical_from_name","text":"av_spherical_from_name(name)\n\nGet the AVSphericalProjection form a human-readable name.\n\nArguments\n\nname: The input string.\n\nReturns\n\nThe AVSphericalProjection value, or -1 if not found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_spherical_projection_name-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_spherical_projection_name","text":"av_spherical_projection_name(projection::AVSphericalProjection)\n\nProvide a human-readable name of a given AVSphericalProjection.\n\nArguments\n\nprojection: The input AVSphericalProjection.\n\nReturns\n\nThe name of the AVSphericalProjection, or \"unknown\".\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_spherical_tile_bounds-Tuple{Any, UInt64, UInt64, Vararg{Any, 4}}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_spherical_tile_bounds","text":"av_spherical_tile_bounds(map, width::Csize_t, height::Csize_t, left, top, right, bottom)\n\nConvert the bounding fields from an AVSphericalVideo from 0.32 fixed point to pixels.\n\nArguments\n\nmap: The AVSphericalVideo map to read bound values from.\nwidth: Width of the current frame or stream.\nheight: Height of the current frame or stream.\nleft: Pixels from the left edge.\ntop: Pixels from the top edge.\nright: Pixels from the right edge.\nbottom: Pixels from the bottom edge.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stereo3d_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stereo3d_alloc","text":"av_stereo3d_alloc()\n\nAllocate an AVStereo3D structure and set its fields to default values. The resulting struct can be freed using av_freep().\n\nReturns\n\nAn AVStereo3D filled with default values or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stereo3d_alloc_size-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stereo3d_alloc_size","text":"av_stereo3d_alloc_size(size)\n\nAllocate an AVStereo3D structure and set its fields to default values. The resulting struct can be freed using av_freep().\n\nReturns\n\nAn AVStereo3D filled with default values or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stereo3d_create_side_data-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stereo3d_create_side_data","text":"av_stereo3d_create_side_data(frame)\n\nAllocate a complete AVFrameSideData and add it to the frame.\n\nArguments\n\nframe: The frame which side data is added to.\n\nReturns\n\nThe AVStereo3D structure to be filled by caller.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stereo3d_from_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stereo3d_from_name","text":"av_stereo3d_from_name(name)\n\nGet the AVStereo3DType form a human-readable name.\n\nArguments\n\nname: The input string.\n\nReturns\n\nThe AVStereo3DType value, or -1 if not found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stereo3d_primary_eye_from_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stereo3d_primary_eye_from_name","text":"av_stereo3d_primary_eye_from_name(name)\n\nGet the AVStereo3DPrimaryEye form a human-readable name.\n\nArguments\n\nname: The input string.\n\nReturns\n\nThe AVStereo3DPrimaryEye value, or -1 if not found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stereo3d_primary_eye_name-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stereo3d_primary_eye_name","text":"av_stereo3d_primary_eye_name(eye::Integer)\n\nProvide a human-readable name of a given stereo3d primary eye.\n\nArguments\n\ntype: The input stereo3d primary eye value.\n\nReturns\n\nThe name of the stereo3d primary eye value, or \"unknown\".\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stereo3d_type_name-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stereo3d_type_name","text":"av_stereo3d_type_name(type::Integer)\n\nProvide a human-readable name of a given stereo3d type.\n\nArguments\n\ntype: The input stereo3d type value.\n\nReturns\n\nThe name of the stereo3d value, or \"unknown\".\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stereo3d_view_from_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stereo3d_view_from_name","text":"av_stereo3d_view_from_name(name)\n\nGet the AVStereo3DView form a human-readable name.\n\nArguments\n\nname: The input string.\n\nReturns\n\nThe AVStereo3DView value, or -1 if not found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stereo3d_view_name-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stereo3d_view_name","text":"av_stereo3d_view_name(view::Integer)\n\nProvide a human-readable name of a given stereo3d view.\n\nArguments\n\ntype: The input stereo3d view value.\n\nReturns\n\nThe name of the stereo3d view value, or \"unknown\".\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strcasecmp-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strcasecmp","text":"av_strcasecmp(a, b)\n\nLocale-independent case-insensitive compare.\n\nnote: Note\nThis means only ASCII-range characters are case-insensitive\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strdup-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strdup","text":"av_strdup(s)\n\nDuplicate a string.\n\nArguments\n\ns: String to be duplicated\n\nReturns\n\nPointer to a newly-allocated string containing a copy of s or NULL if the string cannot be allocated\n\nSee also\n\nav_strndup()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stream_get_class-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stream_get_class","text":"av_stream_get_class()\n\nGet the AVClass for AVStream. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options.\n\nSee also\n\nav_opt_find().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stream_get_codec_timebase-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stream_get_codec_timebase","text":"av_stream_get_codec_timebase(st)\n\ncompat: Deprecated\ndo not call this function\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stream_group_get_class-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stream_group_get_class","text":"av_stream_group_get_class()\n\nGet the AVClass for AVStreamGroup. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options.\n\nSee also\n\nav_opt_find().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strerror-Tuple{Integer, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strerror","text":"av_strerror(errnum::Integer, errbuf, errbuf_size::Csize_t)\n\nPut a description of the AVERROR code errnum in errbuf. In case of failure the global variable errno is set to indicate the error. Even in case of failure av_strerror() will print a generic error message indicating the errnum provided to errbuf.\n\nArguments\n\nerrnum: error code to describe\nerrbuf: buffer to which description is written\nerrbuf_size: the size in bytes of errbuf\n\nReturns\n\n0 on success, a negative value if a description for errnum cannot be found\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strireplace-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strireplace","text":"av_strireplace(str, from, to)\n\nLocale-independent strings replace.\n\nnote: Note\nThis means only ASCII-range characters are replaced.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stristart-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stristart","text":"av_stristart(str, pfx, ptr)\n\nReturn non-zero if pfx is a prefix of str independent of case. If it is, *ptr is set to the address of the first character in str after the prefix.\n\nArguments\n\nstr: input string\npfx: prefix to test\nptr: updated if the prefix is matched inside str\n\nReturns\n\nnon-zero if the prefix matches, zero otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_stristr-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_stristr","text":"av_stristr(haystack, needle)\n\nLocate the first case-independent occurrence in the string haystack of the string needle. A zero-length string needle is considered to match at the start of haystack.\n\nThis function is a case-insensitive version of the standard strstr().\n\nArguments\n\nhaystack: string to search in\nneedle: string to search for\n\nReturns\n\npointer to the located match within haystack or a null pointer if no match\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strlcat-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strlcat","text":"av_strlcat(dst, src, size::Csize_t)\n\nAppend the string src to the string dst, but to a total length of no more than size - 1 bytes, and null-terminate dst.\n\nThis function is similar to BSD strlcat(), but differs when size <= strlen(dst).\n\nwarning: Warning\nsince the return value use the length of src and dst, these absolutely _must_ be a properly 0-terminated strings, otherwise this will read beyond the end of the buffer and possibly crash.\n\nArguments\n\ndst: destination buffer\nsrc: source string\nsize: size of destination buffer\n\nReturns\n\nthe total length of src and dst\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strlcpy-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strlcpy","text":"av_strlcpy(dst, src, size::Csize_t)\n\nCopy the string src to dst, but no more than size - 1 bytes, and null-terminate dst.\n\nThis function is the same as BSD strlcpy().\n\nwarning: Warning\nsince the return value is the length of src, src absolutely _must_ be a properly 0-terminated string, otherwise this will read beyond the end of the buffer and possibly crash.\n\nArguments\n\ndst: destination buffer\nsrc: source string\nsize: size of destination buffer\n\nReturns\n\nthe length of src\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strncasecmp-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strncasecmp","text":"av_strncasecmp(a, b, n::Csize_t)\n\nLocale-independent case-insensitive compare.\n\nnote: Note\nThis means only ASCII-range characters are case-insensitive\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strndup-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strndup","text":"av_strndup(s, len::Csize_t)\n\nDuplicate a substring of a string.\n\nArguments\n\ns: String to be duplicated\nlen: Maximum length of the resulting string (not counting the terminating byte)\n\nReturns\n\nPointer to a newly-allocated string containing a substring of s or NULL if the string cannot be allocated\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strnlen-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strnlen","text":"av_strnlen(s, len::Csize_t)\n\nGet the count of continuous non zero chars starting from the beginning.\n\nArguments\n\ns: the string whose length to count\nlen: maximum number of characters to check in the string, that is the maximum value which is returned by the function\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strnstr-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strnstr","text":"av_strnstr(haystack, needle, hay_length::Csize_t)\n\nLocate the first occurrence of the string needle in the string haystack where not more than hay_length characters are searched. A zero-length string needle is considered to match at the start of haystack.\n\nThis function is a length-limited version of the standard strstr().\n\nArguments\n\nhaystack: string to search in\nneedle: string to search for\nhay_length: length of string to search in\n\nReturns\n\npointer to the located match within haystack or a null pointer if no match\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strstart-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strstart","text":"av_strstart(str, pfx, ptr)\n\nReturn non-zero if pfx is a prefix of str. If it is, *ptr is set to the address of the first character in str after the prefix.\n\nArguments\n\nstr: input string\npfx: prefix to test\nptr: updated if the prefix is matched inside str\n\nReturns\n\nnon-zero if the prefix matches, zero otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strtod-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strtod","text":"av_strtod(numstr, tail)\n\nParse the string in numstr and return its value as a double. If the string is empty, contains only whitespaces, or does not contain an initial substring that has the expected syntax for a floating-point number, no conversion is performed. In this case, returns a value of zero and the value returned in tail is the value of numstr.\n\nArguments\n\nnumstr: a string representing a number, may contain one of the International System number postfixes, for example 'K', 'M', 'G'. If 'i' is appended after the postfix, powers of 2 are used instead of powers of 10. The 'B' postfix multiplies the value by 8, and can be appended after another postfix or used alone. This allows using for example 'KB', 'MiB', 'G' and 'B' as postfix.\ntail: if non-NULL puts here the pointer to the char next after the last parsed character\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_strtok-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_strtok","text":"av_strtok(s, delim, saveptr)\n\nSplit the string into several tokens which can be accessed by successive calls to av_strtok().\n\nA token is defined as a sequence of characters not belonging to the set specified in delim.\n\nOn the first call to av_strtok(), s should point to the string to parse, and the value of saveptr is ignored. In subsequent calls, s should be NULL, and saveptr should be unchanged since the previous call.\n\nThis function is similar to strtok_r() defined in POSIX.1.\n\nArguments\n\ns: the string to parse, may be NULL\ndelim: 0-terminated list of token delimiters, must be non-NULL\nsaveptr: user-provided pointer which points to stored information necessary for av_strtok() to continue scanning the same string. saveptr is updated to point to the next character after the first delimiter found, or to NULL if the string was terminated\n\nReturns\n\nthe found token, or NULL when no token is found\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_sub_q-Tuple{VideoIO.libffmpeg.AVRational, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_sub_q","text":"av_sub_q(b::AVRational, c::AVRational)\n\nSubtract one rational from another.\n\nArguments\n\nb: First rational\nc: Second rational\n\nReturns\n\nb-c\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tdrdi_alloc-Tuple{Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tdrdi_alloc","text":"av_tdrdi_alloc(nb_displays::Integer, size)\n\nAllocate a AV3DReferenceDisplaysInfo structure and initialize its fields to default values.\n\nReturns\n\nthe newly allocated struct or NULL on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tea_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tea_alloc","text":"av_tea_alloc()\n\nAllocate an AVTEA context To free the struct: av_free(ptr)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tea_crypt-Tuple{Any, Any, Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tea_crypt","text":"av_tea_crypt(ctx, dst, src, count::Integer, iv, decrypt::Integer)\n\nEncrypt or decrypt a buffer using a previously initialized context.\n\nArguments\n\nctx: an AVTEA context\ndst: destination array, can be equal to src\nsrc: source array, can be equal to dst\ncount: number of 8 byte blocks\niv: initialization vector for CBC mode, if NULL then ECB will be used\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tea_init-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tea_init","text":"av_tea_init(ctx, key, rounds::Integer)\n\nInitialize an AVTEA context.\n\nArguments\n\nctx: an AVTEA context\nkey: a key of 16 bytes used for encryption/decryption\nrounds: the number of rounds in TEA (64 is the \"standard\")\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_thread_message_flush-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_thread_message_flush","text":"av_thread_message_flush(mq)\n\nFlush the message queue\n\nThis function is mostly equivalent to reading and free-ing every message except that it will be done in a single operation (no lock/unlock between reads).\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_thread_message_queue_alloc-Tuple{Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_thread_message_queue_alloc","text":"av_thread_message_queue_alloc(mq, nelem::Integer, elsize::Integer)\n\nAllocate a new message queue.\n\nArguments\n\nmq: pointer to the message queue\nnelem: maximum number of elements in the queue\nelsize: size of each element in the queue\n\nReturns\n\n=0 for success; <0 for error, in particular AVERROR(ENOSYS) if lavu was built without thread support\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_thread_message_queue_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_thread_message_queue_free","text":"av_thread_message_queue_free(mq)\n\nFree a message queue.\n\nThe message queue must no longer be in use by another thread.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_thread_message_queue_nb_elems-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_thread_message_queue_nb_elems","text":"av_thread_message_queue_nb_elems(mq)\n\nReturn the current number of messages in the queue.\n\nReturns\n\nthe current number of messages or AVERROR(ENOSYS) if lavu was built without thread support\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_thread_message_queue_recv-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_thread_message_queue_recv","text":"av_thread_message_queue_recv(mq, msg, flags::Integer)\n\nReceive a message from the queue.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_thread_message_queue_send-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_thread_message_queue_send","text":"av_thread_message_queue_send(mq, msg, flags::Integer)\n\nSend a message on the queue.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_thread_message_queue_set_err_recv-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_thread_message_queue_set_err_recv","text":"av_thread_message_queue_set_err_recv(mq, err::Integer)\n\nSet the receiving error code.\n\nIf the error code is set to non-zero, av_thread_message_queue_recv() will return it immediately when there are no longer available messages. Conventional values, such as AVERROR_EOF or AVERROR(EAGAIN), can be used to cause the receiving thread to stop or suspend its operation.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_thread_message_queue_set_err_send-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_thread_message_queue_set_err_send","text":"av_thread_message_queue_set_err_send(mq, err::Integer)\n\nSet the sending error code.\n\nIf the error code is set to non-zero, av_thread_message_queue_send() will return it immediately. Conventional values, such as AVERROR_EOF or AVERROR(EAGAIN), can be used to cause the sending thread to stop or suspend its operation.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_thread_message_queue_set_free_func-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_thread_message_queue_set_free_func","text":"av_thread_message_queue_set_free_func(mq, free_func)\n\nSet the optional free message callback function which will be called if an operation is removing messages from the queue.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timecode_adjust_ntsc_framenum2-Tuple{Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timecode_adjust_ntsc_framenum2","text":"av_timecode_adjust_ntsc_framenum2(framenum::Integer, fps::Integer)\n\nAdjust frame number for NTSC drop frame time code.\n\nwarning: Warning\nadjustment is only valid for multiples of NTSC 29.97\n\nArguments\n\nframenum: frame number to adjust\nfps: frame per second, multiples of 30\n\nReturns\n\nadjusted frame number\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timecode_check_frame_rate-Tuple{VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timecode_check_frame_rate","text":"av_timecode_check_frame_rate(rate::AVRational)\n\nCheck if the timecode feature is available for the given frame rate\n\nReturns\n\n0 if supported, <0 otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timecode_get_smpte-Tuple{VideoIO.libffmpeg.AVRational, Vararg{Integer, 5}}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timecode_get_smpte","text":"av_timecode_get_smpte(rate::AVRational, drop::Integer, hh::Integer, mm::Integer, ss::Integer, ff::Integer)\n\nConvert sei info to SMPTE 12M binary representation.\n\nArguments\n\nrate: frame rate in rational form\ndrop: drop flag\nhh: hour\nmm: minute\nss: second\nff: frame number\n\nReturns\n\nthe SMPTE binary representation\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timecode_get_smpte_from_framenum-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timecode_get_smpte_from_framenum","text":"av_timecode_get_smpte_from_framenum(tc, framenum::Integer)\n\nConvert frame number to SMPTE 12M binary representation.\n\nSee SMPTE ST 314M-2005 Sec 4.4.2.2.1 \"Time code pack (TC)\" the format description as follows: bits 0-5: hours, in BCD(6bits) bits 6: BGF1 bits 7: BGF2 (NTSC) or FIELD (PAL) bits 8-14: minutes, in BCD(7bits) bits 15: BGF0 (NTSC) or BGF2 (PAL) bits 16-22: seconds, in BCD(7bits) bits 23: FIELD (NTSC) or BGF0 (PAL) bits 24-29: frames, in BCD(6bits) bits 30: drop frame flag (0: non drop, 1: drop) bits 31: color frame flag (0: unsync mode, 1: sync mode)\n\nnote: Note\nBCD numbers (6 or 7 bits): 4 or 5 lower bits for units, 2 higher bits for tens.\n\nnote: Note\nFrame number adjustment is automatically done in case of drop timecode, you do NOT have to call av_timecode_adjust_ntsc_framenum2().\n\nnote: Note\nThe frame number is relative to tc->start.\n\nnote: Note\nColor frame (CF) and binary group flags (BGF) bits are set to zero.\n\nArguments\n\ntc: timecode data correctly initialized\nframenum: frame number\n\nReturns\n\nthe SMPTE binary representation\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timecode_init-Tuple{Any, VideoIO.libffmpeg.AVRational, Integer, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timecode_init","text":"av_timecode_init(tc, rate::AVRational, flags::Integer, frame_start::Integer, log_ctx)\n\nInit a timecode struct with the passed parameters.\n\nArguments\n\ntc: pointer to an allocated AVTimecode\nrate: frame rate in rational form\nflags: miscellaneous flags such as drop frame, +24 hours, ... (see AVTimecodeFlag)\nframe_start: the first frame number\nlog_ctx: a pointer to an arbitrary struct of which the first field is a pointer to an AVClass struct (used for av_log)\n\nReturns\n\n0 on success, AVERROR otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timecode_init_from_components-Tuple{Any, VideoIO.libffmpeg.AVRational, Integer, Integer, Integer, Integer, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timecode_init_from_components","text":"av_timecode_init_from_components(tc, rate::AVRational, flags::Integer, hh::Integer, mm::Integer, ss::Integer, ff::Integer, log_ctx)\n\nInit a timecode struct from the passed timecode components.\n\nArguments\n\ntc: pointer to an allocated AVTimecode\nrate: frame rate in rational form\nflags: miscellaneous flags such as drop frame, +24 hours, ... (see AVTimecodeFlag)\nhh: hours\nmm: minutes\nss: seconds\nff: frames\nlog_ctx: a pointer to an arbitrary struct of which the first field is a pointer to an AVClass struct (used for av_log)\n\nReturns\n\n0 on success, AVERROR otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timecode_init_from_string-Tuple{Any, VideoIO.libffmpeg.AVRational, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timecode_init_from_string","text":"av_timecode_init_from_string(tc, rate::AVRational, str, log_ctx)\n\nParse timecode representation (hh:mm:ss[:;.]ff).\n\nArguments\n\ntc: pointer to an allocated AVTimecode\nrate: frame rate in rational form\nstr: timecode string which will determine the frame start\nlog_ctx: a pointer to an arbitrary struct of which the first field is a pointer to an AVClass struct (used for av_log).\n\nReturns\n\n0 on success, AVERROR otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timecode_make_mpeg_tc_string-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timecode_make_mpeg_tc_string","text":"av_timecode_make_mpeg_tc_string(buf, tc25bit::Integer)\n\nGet the timecode string from the 25-bit timecode format (MPEG GOP format).\n\nArguments\n\nbuf: destination buffer, must be at least AV_TIMECODE_STR_SIZE long\ntc25bit: the 25-bits timecode\n\nReturns\n\nthe buf parameter\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timecode_make_smpte_tc_string-Tuple{Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timecode_make_smpte_tc_string","text":"av_timecode_make_smpte_tc_string(buf, tcsmpte::Integer, prevent_df::Integer)\n\nGet the timecode string from the SMPTE timecode format.\n\nArguments\n\nbuf: destination buffer, must be at least AV_TIMECODE_STR_SIZE long\ntcsmpte: the 32-bit SMPTE timecode\nprevent_df: prevent the use of a drop flag when it is known the DF bit is arbitrary\n\nReturns\n\nthe buf parameter\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timecode_make_smpte_tc_string2-Tuple{Any, VideoIO.libffmpeg.AVRational, Integer, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timecode_make_smpte_tc_string2","text":"av_timecode_make_smpte_tc_string2(buf, rate::AVRational, tcsmpte::Integer, prevent_df::Integer, skip_field::Integer)\n\nGet the timecode string from the SMPTE timecode format.\n\nIn contrast to av_timecode_make_smpte_tc_string this function supports 50/60 fps timecodes by using the field bit.\n\nArguments\n\nbuf: destination buffer, must be at least AV_TIMECODE_STR_SIZE long\nrate: frame rate of the timecode\ntcsmpte: the 32-bit SMPTE timecode\nprevent_df: prevent the use of a drop flag when it is known the DF bit is arbitrary\nskip_field: prevent the use of a field flag when it is known the field bit is arbitrary (e.g. because it is used as PC flag)\n\nReturns\n\nthe buf parameter\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timecode_make_string-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timecode_make_string","text":"av_timecode_make_string(tc, buf, framenum::Integer)\n\nLoad timecode string in buf.\n\nnote: Note\nTimecode representation can be a negative timecode and have more than 24 hours, but will only be honored if the flags are correctly set.\n\nnote: Note\nThe frame number is relative to tc->start.\n\nArguments\n\ntc: timecode data correctly initialized\nbuf: destination buffer, must be at least AV_TIMECODE_STR_SIZE long\nframenum: frame number\n\nReturns\n\nthe buf parameter\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_timegm-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_timegm","text":"av_timegm(tm_)\n\nConvert the decomposed UTC time in tm to a time_t value.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tolower-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tolower","text":"av_tolower(c::Integer)\n\nLocale-independent conversion of ASCII characters to lowercase.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_toupper-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_toupper","text":"av_toupper(c::Integer)\n\nLocale-independent conversion of ASCII characters to uppercase.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tree_enumerate-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tree_enumerate","text":"av_tree_enumerate(t, opaque, cmp, enu)\n\nApply enu(opaque, &elem) to all the elements in the tree in a given range.\n\nnote: Note\nThe cmp function should use the same ordering used to construct the tree.\n\nArguments\n\ncmp: a comparison function that returns < 0 for an element below the range, > 0 for an element above the range and == 0 for an element inside the range\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tree_find-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tree_find","text":"av_tree_find(root, key, cmp, next)\n\nFind an element.\n\nArguments\n\nroot: a pointer to the root node of the tree\nnext: If next is not NULL, then next[0] will contain the previous element and next[1] the next element. If either does not exist, then the corresponding entry in next is unchanged.\ncmp: compare function used to compare elements in the tree, API identical to that of Standard C's qsort It is guaranteed that the first and only the first argument to cmp() will be the key parameter to av_tree_find(), thus it could if the user wants, be a different type (like an opaque context).\n\nReturns\n\nAn element with cmp(key, elem) == 0 or NULL if no such element exists in the tree.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tree_insert-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tree_insert","text":"av_tree_insert(rootp, key, cmp, next)\n\nInsert or remove an element.\n\nIf *next is NULL, then the supplied element will be removed if it exists. If *next is non-NULL, then the supplied element will be inserted, unless it already exists in the tree.\n\n             void *tree_insert(struct AVTreeNode **rootp, void *key,\n                               int (*cmp)(void *key, const void *b),\n                               AVTreeNode **next)\n             {\n                 if (!*next)\n                     *next = av_mallocz(av_tree_node_size);\n                 return av_tree_insert(rootp, key, cmp, next);\n             }\n             void *tree_remove(struct AVTreeNode **rootp, void *key,\n                               int (*cmp)(void *key, const void *b, AVTreeNode **next))\n             {\n                 av_freep(next);\n                 return av_tree_insert(rootp, key, cmp, next);\n             }\n\nArguments\n\nrootp: A pointer to a pointer to the root node of the tree; note that the root node can change during insertions, this is required to keep the tree balanced.\nkey: pointer to the element key to insert in the tree\nnext: Used to allocate and free AVTreeNodes. For insertion the user must set it to an allocated and zeroed object of at least av_tree_node_size bytes size. av_tree_insert() will set it to NULL if it has been consumed. For deleting elements *next is set to NULL by the user and av_tree_insert() will set it to the AVTreeNode which was used for the removed element. This allows the use of flat arrays, which have lower overhead compared to many malloced elements. You might want to define a function like:\ncmp: compare function used to compare elements in the tree, API identical to that of Standard C's qsort\n\nReturns\n\nIf no insertion happened, the found element; if an insertion or removal happened, then either key or NULL will be returned. Which one it is depends on the tree state and the implementation. You should make no assumptions that it's one or the other in the code.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tree_node_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tree_node_alloc","text":"av_tree_node_alloc()\n\nAllocate an AVTreeNode.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_ts_make_string-Tuple{Any, Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_ts_make_string","text":"av_ts_make_string(buf, ts::Int64)\n\nFill the provided buffer with a string containing a timestamp representation.\n\nArguments\n\nbuf: a buffer with size in bytes of at least AV_TS_MAX_STRING_SIZE\nts: the timestamp to represent\n\nReturns\n\nthe buffer in input\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_ts_make_time_string-Tuple{Any, Int64, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_ts_make_time_string","text":"av_ts_make_time_string(buf, ts::Int64, tb)\n\nFill the provided buffer with a string containing a timestamp representation.\n\nSee also\n\nav_ts_make_time_string2\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_ts_make_time_string2-Tuple{Any, Int64, VideoIO.libffmpeg.AVRational}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_ts_make_time_string2","text":"av_ts_make_time_string2(buf, ts::Int64, tb::AVRational)\n\nFill the provided buffer with a string containing a timestamp time representation.\n\nArguments\n\nbuf: a buffer with size in bytes of at least AV_TS_MAX_STRING_SIZE\nts: the timestamp to represent\ntb: the timebase of the timestamp\n\nReturns\n\nthe buffer in input\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_twofish_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_twofish_alloc","text":"av_twofish_alloc()\n\nAllocate an AVTWOFISH context To free the struct: av_free(ptr)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_twofish_crypt-Tuple{Any, Any, Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_twofish_crypt","text":"av_twofish_crypt(ctx, dst, src, count::Integer, iv, decrypt::Integer)\n\nEncrypt or decrypt a buffer using a previously initialized context\n\nArguments\n\nctx: an AVTWOFISH context\ndst: destination array, can be equal to src\nsrc: source array, can be equal to dst\ncount: number of 16 byte blocks\niv: initialization vector for CBC mode, NULL for ECB mode\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_twofish_init-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_twofish_init","text":"av_twofish_init(ctx, key, key_bits::Integer)\n\nInitialize an AVTWOFISH context.\n\nArguments\n\nctx: an AVTWOFISH context\nkey: a key of size ranging from 1 to 32 bytes used for encryption/decryption\nkey_bits: number of keybits: 128, 192, 256 If less than the required, padded with zeroes to nearest valid value; return value is 0 if key_bits is 128/192/256, -1 if less than 0, 1 otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tx_init-Tuple{Any, Any, UInt32, Integer, Integer, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tx_init","text":"av_tx_init(ctx, tx, type::AVTXType, inv::Integer, len::Integer, scale, flags::UInt64)\n\nInitialize a transform context with the given configuration (i)MDCTs with an odd length are currently not supported.\n\nArguments\n\nctx: the context to allocate, will be NULL on error\ntx: pointer to the transform function pointer to set\ntype: type the type of transform\ninv: whether to do an inverse or a forward transform\nlen: the size of the transform in samples\nscale: pointer to the value to scale the output if supported by type\nflags: a bitmask of AVTXFlags or 0\n\nReturns\n\n0 on success, negative error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tx_uninit-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tx_uninit","text":"av_tx_uninit(ctx)\n\nFrees a context and sets *ctx to NULL, does nothing when *ctx == NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_url_split-Tuple{Any, Integer, Any, Integer, Any, Integer, Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_url_split","text":"av_url_split(proto, proto_size::Integer, authorization, authorization_size::Integer, hostname, hostname_size::Integer, port_ptr, path, path_size::Integer, url)\n\nSplit a URL string into components.\n\nThe pointers to buffers for storing individual components may be null, in order to ignore that component. Buffers for components not found are set to empty strings. If the port is not found, it is set to a negative value.\n\nArguments\n\nproto: the buffer for the protocol\nproto_size: the size of the proto buffer\nauthorization: the buffer for the authorization\nauthorization_size: the size of the authorization buffer\nhostname: the buffer for the host name\nhostname_size: the size of the hostname buffer\nport_ptr: a pointer to store the port number in\npath: the buffer for the path\npath_size: the size of the path buffer\nurl: the URL to split\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_usleep-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_usleep","text":"av_usleep(usec::Integer)\n\nSleep for a period of time. Although the duration is expressed in microseconds, the actual delay may be rounded to the precision of the system timer.\n\nArguments\n\nusec: Number of microseconds to sleep.\n\nReturns\n\nzero on success or (negative) error code.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_utf8_decode-Tuple{Any, Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_utf8_decode","text":"av_utf8_decode(codep, bufp, buf_end, flags::Integer)\n\nRead and decode a single UTF-8 code point (character) from the buffer in *buf, and update *buf to point to the next byte to decode.\n\nIn case of an invalid byte sequence, the pointer will be updated to the next byte after the invalid sequence and the function will return an error code.\n\nDepending on the specified flags, the function will also fail in case the decoded code point does not belong to a valid range.\n\nnote: Note\nFor speed-relevant code a carefully implemented use of GET_UTF8() may be preferred.\n\nArguments\n\ncodep: pointer used to return the parsed code in case of success. The value in *codep is set even in case the range check fails.\nbufp: pointer to the address the first byte of the sequence to decode, updated by the function to point to the byte next after the decoded sequence\nbuf_end: pointer to the end of the buffer, points to the next byte past the last in the buffer. This is used to avoid buffer overreads (in case of an unfinished UTF-8 sequence towards the end of the buffer).\nflags: a collection of AV_UTF8_FLAG_* flags\n\nReturns\n\n= 0 in case a sequence was successfully read, a negative value in case of invalid sequence\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_uuid_copy-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_uuid_copy","text":"av_uuid_copy(dest, src)\n\nCopies the bytes of src into dest.\n\nArguments\n\ndest:[out] AVUUID\nsrc:[in] AVUUID\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_uuid_equal-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_uuid_equal","text":"av_uuid_equal(uu1, uu2)\n\nCompares two UUIDs for equality.\n\nArguments\n\nuu1:[in] AVUUID\nuu2:[in] AVUUID\n\nReturns\n\nNonzero if uu1 and uu2 are identical, 0 otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_uuid_nil-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_uuid_nil","text":"av_uuid_nil(uu)\n\nSets a UUID to the nil UUID, i.e. a UUID with have all its 128 bits set to zero.\n\nArguments\n\nuu:[in,out] UUID to be set to the nil UUID\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_uuid_parse-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_uuid_parse","text":"av_uuid_parse(in, uu)\n\nParses a string representation of a UUID formatted according to IETF RFC 4122 into an AVUUID. The parsing is case-insensitive. The string must be 37 characters long, including the terminating NUL character.\n\nExample string representation: \"2fceebd0-7017-433d-bafb-d073a7116696\"\n\nArguments\n\nin:[in] String representation of a UUID, e.g. 2fceebd0-7017-433d-bafb-d073a7116696\nuu:[out] AVUUID\n\nReturns\n\nA non-zero value in case of an error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_uuid_parse_range-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_uuid_parse_range","text":"av_uuid_parse_range(in_start, in_end, uu)\n\nParses a string representation of a UUID formatted according to IETF RFC 4122 into an AVUUID. The parsing is case-insensitive.\n\nArguments\n\nin_start:[in] Pointer to the first character of the string representation\nin_end:[in] Pointer to the character after the last character of the string representation. That memory location is never accessed. It is an error if in\\_end - in\\_start != 36.\nuu:[out] AVUUID\n\nReturns\n\nA non-zero value in case of an error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_uuid_unparse-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_uuid_unparse","text":"av_uuid_unparse(uu, out)\n\nSerializes a AVUUID into a string representation according to IETF RFC 4122. The string is lowercase and always 37 characters long, including the terminating NUL character.\n\nArguments\n\nuu:[in] AVUUID\nout:[out] Pointer to an array of no less than 37 characters.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_uuid_urn_parse-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_uuid_urn_parse","text":"av_uuid_urn_parse(in, uu)\n\nParses a URN representation of a UUID, as specified at IETF RFC 4122, into an AVUUID. The parsing is case-insensitive. The string must be 46 characters long, including the terminating NUL character.\n\nExample string representation: \"urn:uuid:2fceebd0-7017-433d-bafb-d073a7116696\"\n\nArguments\n\nin:[in] URN UUID\nuu:[out] AVUUID\n\nReturns\n\nA non-zero value in case of an error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_vdpau_bind_context-Tuple{Any, UInt32, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_vdpau_bind_context","text":"av_vdpau_bind_context(avctx, device::VdpDevice, get_proc_address, flags::Integer)\n\nAssociate a VDPAU device with a codec context for hardware acceleration. This function is meant to be called from the get_format() codec callback, or earlier. It can also be called after avcodec_flush_buffers() to change the underlying VDPAU device mid-stream (e.g. to recover from non-transparent display preemption).\n\nnote: Note\nget_format() must return AV_PIX_FMT_VDPAU if this function completes successfully.\n\nArguments\n\navctx: decoding context whose get_format() callback is invoked\ndevice: VDPAU device handle to use for hardware acceleration\nget_proc_address: VDPAU device driver\nflags: zero of more OR'd AV_HWACCEL_FLAG_* flags\n\nReturns\n\n0 on success, an AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_vdpau_get_surface_parameters-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_vdpau_get_surface_parameters","text":"av_vdpau_get_surface_parameters(avctx, type, width, height)\n\nGets the parameters to create an adequate VDPAU video surface for the codec context using VDPAU hardware decoding acceleration.\n\nnote: Note\nBehavior is undefined if the context was not successfully bound to a VDPAU device using av_vdpau_bind_context().\n\nArguments\n\navctx: the codec context being used for decoding the stream\ntype: storage space for the VDPAU video surface chroma type (or NULL to ignore)\nwidth: storage space for the VDPAU video surface pixel width (or NULL to ignore)\nheight: storage space for the VDPAU video surface pixel height (or NULL to ignore)\n\nReturns\n\n0 on success, a negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_version_info-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_version_info","text":"av_version_info()\n\nReturn an informative version string. This usually is the actual release version number or a git commit description. This string has no fixed format and can change any time. It should never be parsed by code.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_video_enc_params_alloc-Tuple{Int32, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_video_enc_params_alloc","text":"av_video_enc_params_alloc(type::AVVideoEncParamsType, nb_blocks::Integer, out_size)\n\nAllocates memory for AVVideoEncParams of the given type, plus an array of {\n\n nb_blocks} AVVideoBlockParams and initializes the variables. Can be\n freed with a normal av_free() call.\n\n @param out_size if non-NULL, the size in bytes of the resulting data array is\n written here.\n \n\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_video_enc_params_block-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_video_enc_params_block","text":"av_video_enc_params_block(par, idx::Integer)\n\nGet the block at the specified {\n\n idx}. Must be between 0 and nb_blocks - 1.\n \n\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_video_enc_params_create_side_data-Tuple{Any, Int32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_video_enc_params_create_side_data","text":"av_video_enc_params_create_side_data(frame, type::AVVideoEncParamsType, nb_blocks::Integer)\n\nAllocates memory for AVEncodeInfoFrame plus an array of {\n\n nb_blocks} AVEncodeInfoBlock in the given AVFrame {@code frame}\n as AVFrameSideData of type AV_FRAME_DATA_VIDEO_ENC_PARAMS\n and initializes the variables.\n \n\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_video_hint_alloc-Tuple{UInt64, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_video_hint_alloc","text":"av_video_hint_alloc(nb_rects::Csize_t, out_size)\n\nAllocate memory for the AVVideoHint struct along with an nb_rects-sized arrays of AVVideoRect.\n\nThe side data contains a list of rectangles for the portions of the frame which changed from the last encoded one (and the remainder are assumed to be changed), or, alternately (depending on the type parameter) the unchanged ones (and the remaining ones are those which changed). Macroblocks will thus be hinted either to be P_SKIP-ped or go through the regular encoding procedure.\n\nIt's responsibility of the caller to fill the AVRects accordingly, and to set the proper AVVideoHintType field.\n\nArguments\n\nout_size: if non-NULL, the size in bytes of the resulting data array is written here\n\nReturns\n\nnewly allocated AVVideoHint struct (must be freed by the caller using av_free()) on success, NULL on memory allocation failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_video_hint_create_side_data-Tuple{Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_video_hint_create_side_data","text":"av_video_hint_create_side_data(frame, nb_rects::Csize_t)\n\nSame as av_video_hint_alloc(), except newly-allocated AVVideoHint is attached as side data of type AV_FRAME_DATA_VIDEO_HINT_INFO to frame.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_vk_frame_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_vk_frame_alloc","text":"av_vk_frame_alloc()\n\nAllocates a single AVVkFrame and initializes everything as 0.\n\nnote: Note\nMust be freed via av_free()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_vorbis_parse_frame-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_vorbis_parse_frame","text":"av_vorbis_parse_frame(s, buf, buf_size::Integer)\n\nGet the duration for a Vorbis packet.\n\nArguments\n\ns: Vorbis parser context\nbuf: buffer containing a Vorbis frame\nbuf_size: size of the buffer\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_vorbis_parse_frame_flags-Tuple{Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_vorbis_parse_frame_flags","text":"av_vorbis_parse_frame_flags(s, buf, buf_size::Integer, flags)\n\nGet the duration for a Vorbis packet.\n\nIf flags is NULL, special frames are considered invalid.\n\nArguments\n\ns: Vorbis parser context\nbuf: buffer containing a Vorbis frame\nbuf_size: size of the buffer\nflags: flags for special frames\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_vorbis_parse_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_vorbis_parse_free","text":"av_vorbis_parse_free(s)\n\nFree the parser and everything associated with it.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_vorbis_parse_init-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_vorbis_parse_init","text":"av_vorbis_parse_init(extradata, extradata_size::Integer)\n\nAllocate and initialize the Vorbis parser using headers in the extradata.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_write_frame-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_write_frame","text":"av_write_frame(s, pkt)\n\nWrite a packet to an output media file.\n\nThis function passes the packet directly to the muxer, without any buffering or reordering. The caller is responsible for correctly interleaving the packets if the format requires it. Callers that want libavformat to handle the interleaving should call av_interleaved_write_frame() instead of this function.\n\nArguments\n\ns: media file handle\npkt: The packet containing the data to be written. Note that unlike av_interleaved_write_frame(), this function does not take ownership of the packet passed to it (though some muxers may make an internal reference to the input packet). <br> This parameter can be NULL (at any time, not just at the end), in order to immediately flush data buffered within the muxer, for muxers that buffer up data internally before writing it to the output. <br> Packet's AVPacket.streamindex \"stream\\index\" field must be set to the index of the corresponding stream in AVFormatContext.streams \"s->streams\". <br> The timestamps (AVPacket.pts \"pts\", AVPacket.dts \"dts\") must be set to correct values in the stream's timebase (unless the output format is flagged with the AVFMT_NOTIMESTAMPS flag, then they can be set to AV_NOPTS_VALUE). The dts for subsequent packets passed to this function must be strictly increasing when compared in their respective timebases (unless the output format is flagged with the AVFMT_TS_NONSTRICT, then they merely have to be nondecreasing). AVPacket.duration \"duration\") should also be set if known.\n\nReturns\n\n< 0 on error, = 0 if OK, 1 if flushed and there is no more data to flush\n\nSee also\n\nav_interleaved_write_frame()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_write_image_line2-Tuple{Any, Any, Any, Any, Vararg{Integer, 5}}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_write_image_line2","text":"av_write_image_line2(src, data, linesize, desc, x::Integer, y::Integer, c::Integer, w::Integer, src_element_size::Integer)\n\nWrite the values from src to the pixel format component c of an image line.\n\nArguments\n\nsrc: array containing the values to write\ndata: the array containing the pointers to the planes of the image to write into. It is supposed to be zeroed.\nlinesize: the array containing the linesizes of the image\ndesc: the pixel format descriptor for the image\nx: the horizontal coordinate of the first pixel to write\ny: the vertical coordinate of the first pixel to write\nw: the width of the line to write, that is the number of values to write to the image line\nsrc_element_size: size of elements in src array (2 or 4 byte)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_write_trailer-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_write_trailer","text":"av_write_trailer(s)\n\nWrite the stream trailer to an output media file and free the file private data.\n\nMay only be called after a successful call to avformat_write_header.\n\nArguments\n\ns: media file handle\n\nReturns\n\n0 if OK, AVERROR_xxx on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_write_uncoded_frame-Tuple{Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_write_uncoded_frame","text":"av_write_uncoded_frame(s, stream_index::Integer, frame)\n\nWrite an uncoded frame to an output media file.\n\nThe frame must be correctly interleaved according to the container specification; if not, av_interleaved_write_uncoded_frame() must be used.\n\nSee av_interleaved_write_uncoded_frame() for details.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_write_uncoded_frame_query-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_write_uncoded_frame_query","text":"av_write_uncoded_frame_query(s, stream_index::Integer)\n\nTest whether a muxer supports uncoded frame.\n\nReturns\n\n=0 if an uncoded frame can be written to that muxer and stream, <0 if not\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_x_if_null-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_x_if_null","text":"av_x_if_null(p, x)\n\nReturn x default pointer in case p is NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_xiphlacing-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_xiphlacing","text":"av_xiphlacing(s, v::Integer)\n\nEncode extradata length to a buffer. Used by xiph codecs.\n\nArguments\n\ns: buffer to write to; must be at least (v/255+1) bytes long\nv: size of extradata in bytes\n\nReturns\n\nnumber of bytes written to the buffer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_xtea_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_xtea_alloc","text":"av_xtea_alloc()\n\nAllocate an AVXTEA context.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_xtea_crypt-Tuple{Any, Any, Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_xtea_crypt","text":"av_xtea_crypt(ctx, dst, src, count::Integer, iv, decrypt::Integer)\n\nEncrypt or decrypt a buffer using a previously initialized context, in big endian format.\n\nArguments\n\nctx: an AVXTEA context\ndst: destination array, can be equal to src\nsrc: source array, can be equal to dst\ncount: number of 8 byte blocks\niv: initialization vector for CBC mode, if NULL then ECB will be used\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_xtea_init-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_xtea_init","text":"av_xtea_init(ctx, key)\n\nInitialize an AVXTEA context.\n\nArguments\n\nctx: an AVXTEA context\nkey: a key of 16 bytes used for encryption/decryption, interpreted as big endian 32 bit numbers\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_xtea_le_crypt-Tuple{Any, Any, Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_xtea_le_crypt","text":"av_xtea_le_crypt(ctx, dst, src, count::Integer, iv, decrypt::Integer)\n\nEncrypt or decrypt a buffer using a previously initialized context, in little endian format.\n\nArguments\n\nctx: an AVXTEA context\ndst: destination array, can be equal to src\nsrc: source array, can be equal to dst\ncount: number of 8 byte blocks\niv: initialization vector for CBC mode, if NULL then ECB will be used\ndecrypt: 0 for encryption, 1 for decryption\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_xtea_le_init-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_xtea_le_init","text":"av_xtea_le_init(ctx, key)\n\nInitialize an AVXTEA context.\n\nArguments\n\nctx: an AVXTEA context\nkey: a key of 16 bytes used for encryption/decryption, interpreted as little endian 32 bit numbers\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_zero_extend_c-Tuple{Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_zero_extend_c","text":"av_zero_extend_c(a::Integer, p::Integer)\n\nClear high bits from an unsigned integer starting with specific bit position\n\nArguments\n\na: value to clip\np: bit position to clip at. Must be between 0 and 31.\n\nReturns\n\nclipped value\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_align_dimensions-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_align_dimensions","text":"avcodec_align_dimensions(s, width, height)\n\nModify width and height values so that they will result in a memory buffer that is acceptable for the codec if you do not use any horizontal padding.\n\nMay only be used if a codec with AV_CODEC_CAP_DR1 has been opened.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_align_dimensions2-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_align_dimensions2","text":"avcodec_align_dimensions2(s, width, height, linesize_align)\n\nModify width and height values so that they will result in a memory buffer that is acceptable for the codec if you also ensure that all line sizes are a multiple of the respective linesize_align[i].\n\nMay only be used if a codec with AV_CODEC_CAP_DR1 has been opened.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_alloc_context3-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_alloc_context3","text":"avcodec_alloc_context3(codec)\n\nAllocate an AVCodecContext and set its fields to default values. The resulting struct should be freed with avcodec_free_context().\n\nArguments\n\ncodec: if non-NULL, allocate private data and initialize defaults for the given codec. It is illegal to then call avcodec_open2() with a different codec. If NULL, then the codec-specific defaults won't be initialized, which may result in suboptimal default settings (this is important mainly for encoders, e.g. libx264).\n\nReturns\n\nAn AVCodecContext filled with default values or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_configuration-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_configuration","text":"avcodec_configuration()\n\nReturn the libavcodec build-time configuration.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_dct_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_dct_alloc","text":"avcodec_dct_alloc()\n\nAllocates a AVDCT context. This needs to be initialized with avcodec_dct_init() after optionally configuring it with AVOptions.\n\nTo free it use av_free()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_decode_subtitle2-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_decode_subtitle2","text":"avcodec_decode_subtitle2(avctx, sub, got_sub_ptr, avpkt)\n\nDecode a subtitle message. Return a negative value on error, otherwise return the number of bytes used. If no subtitle could be decompressed, got_sub_ptr is zero. Otherwise, the subtitle is stored in *sub. Note that AV_CODEC_CAP_DR1 is not available for subtitle codecs. This is for simplicity, because the performance difference is expected to be negligible and reusing a get_buffer written for video codecs would probably perform badly due to a potentially very different allocation pattern.\n\nSome decoders (those marked with AV_CODEC_CAP_DELAY) have a delay between input and output. This means that for some packets they will not immediately produce decoded output and need to be flushed at the end of decoding to get all the decoded data. Flushing is done by calling this function with packets with avpkt->data set to NULL and avpkt->size set to 0 until it stops returning subtitles. It is safe to flush even those decoders that are not marked with AV_CODEC_CAP_DELAY, then no subtitles will be returned.\n\nnote: Note\nThe AVCodecContext MUST have been opened with avcodec_open2() before packets may be fed to the decoder.\n\nArguments\n\navctx: the codec context\nsub:[out] The preallocated AVSubtitle in which the decoded subtitle will be stored, must be freed with avsubtitle_free if *got_sub_ptr is set.\ngot_sub_ptr:[in,out] Zero if no subtitle could be decompressed, otherwise, it is nonzero.\navpkt:[in] The input AVPacket containing the input buffer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_default_get_buffer2-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_default_get_buffer2","text":"avcodec_default_get_buffer2(s, frame, flags::Integer)\n\nThe default callback for AVCodecContext.get_buffer2(). It is made public so it can be called by custom get_buffer2() implementations for decoders without AV_CODEC_CAP_DR1 set.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_default_get_encode_buffer-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_default_get_encode_buffer","text":"avcodec_default_get_encode_buffer(s, pkt, flags::Integer)\n\nThe default callback for AVCodecContext.get_encode_buffer(). It is made public so it can be called by custom get_encode_buffer() implementations for encoders without AV_CODEC_CAP_DR1 set.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_descriptor_get-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_descriptor_get","text":"avcodec_descriptor_get(id::AVCodecID)\n\nReturns\n\ndescriptor for given codec ID or NULL if no descriptor exists.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_descriptor_get_by_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_descriptor_get_by_name","text":"avcodec_descriptor_get_by_name(name)\n\nReturns\n\ncodec descriptor with the given name or NULL if no such descriptor exists.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_descriptor_next-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_descriptor_next","text":"avcodec_descriptor_next(prev)\n\nIterate over all codec descriptors known to libavcodec.\n\nArguments\n\nprev: previous descriptor. NULL to get the first descriptor.\n\nReturns\n\nnext descriptor or NULL after the last descriptor\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_encode_subtitle-Tuple{Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_encode_subtitle","text":"avcodec_encode_subtitle(avctx, buf, buf_size::Integer, sub)\n\nlavc_encoding\n\n@{\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_fill_audio_frame-Tuple{Any, Integer, Int32, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_fill_audio_frame","text":"avcodec_fill_audio_frame(frame, nb_channels::Integer, sample_fmt::AVSampleFormat, buf, buf_size::Integer, align::Integer)\n\nFill AVFrame audio data and linesize pointers.\n\nThe buffer buf must be a preallocated buffer with a size big enough to contain the specified samples amount. The filled AVFrame data pointers will point to this buffer.\n\nAVFrame extended_data channel pointers are allocated if necessary for planar audio.\n\n\\todo return the size in bytes required to store the samples in case of success, at the next libavutil bump\n\nArguments\n\nframe: the AVFrame frame->nb_samples must be set prior to calling the function. This function fills in frame->data, frame->extended_data, frame->linesize[0].\nnb_channels: channel count\nsample_fmt: sample format\nbuf: buffer to use for frame data\nbuf_size: size of buffer\nalign: plane size sample alignment (0 = default)\n\nReturns\n\n=0 on success, negative error code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_find_best_pix_fmt_of_list-Tuple{Any, Int32, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_find_best_pix_fmt_of_list","text":"avcodec_find_best_pix_fmt_of_list(pix_fmt_list, src_pix_fmt::AVPixelFormat, has_alpha::Integer, loss_ptr)\n\nFind the best pixel format to convert to given a certain source pixel format. When converting from one pixel format to another, information loss may occur. For example, when converting from RGB24 to GRAY, the color information will be lost. Similarly, other losses occur when converting from some formats to other formats. avcodec_find_best_pix_fmt_of_2() searches which of the given pixel formats should be used to suffer the least amount of loss. The pixel formats from which it chooses one, are determined by the pix_fmt_list parameter.\n\nArguments\n\npix_fmt_list:[in] AV_PIX_FMT_NONE terminated array of pixel formats to choose from\nsrc_pix_fmt:[in] source pixel format\nhas_alpha:[in] Whether the source pixel format alpha channel is used.\nloss_ptr:[out] Combination of flags informing you what kind of losses will occur.\n\nReturns\n\nThe best pixel format to convert to or -1 if none was found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_find_decoder-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_find_decoder","text":"avcodec_find_decoder(id::AVCodecID)\n\nFind a registered decoder with a matching codec ID.\n\nArguments\n\nid: AVCodecID of the requested decoder\n\nReturns\n\nA decoder if one was found, NULL otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_find_decoder_by_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_find_decoder_by_name","text":"avcodec_find_decoder_by_name(name)\n\nFind a registered decoder with the specified name.\n\nArguments\n\nname: name of the requested decoder\n\nReturns\n\nA decoder if one was found, NULL otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_find_encoder-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_find_encoder","text":"avcodec_find_encoder(id::AVCodecID)\n\nFind a registered encoder with a matching codec ID.\n\nArguments\n\nid: AVCodecID of the requested encoder\n\nReturns\n\nAn encoder if one was found, NULL otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_find_encoder_by_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_find_encoder_by_name","text":"avcodec_find_encoder_by_name(name)\n\nFind a registered encoder with the specified name.\n\nArguments\n\nname: name of the requested encoder\n\nReturns\n\nAn encoder if one was found, NULL otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_flush_buffers-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_flush_buffers","text":"avcodec_flush_buffers(avctx)\n\nReset the internal codec state / flush internal buffers. Should be called e.g. when seeking or when switching to a different stream.\n\nnote: Note\nfor decoders, this function just releases any references the decoder might keep internally, but the caller's references remain valid.\n\nnote: Note\nfor encoders, this function will only do something if the encoder declares support for AV_CODEC_CAP_ENCODER_FLUSH. When called, the encoder will drain any remaining packets, and can then be reused for a different stream (as opposed to sending a null frame which will leave the encoder in a permanent EOF state after draining). This can be desirable if the cost of tearing down and replacing the encoder instance is high.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_free_context-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_free_context","text":"avcodec_free_context(avctx)\n\nFree the codec context and everything associated with it and write NULL to the provided pointer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_get_class-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_get_class","text":"avcodec_get_class()\n\nGet the AVClass for AVCodecContext. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options.\n\nSee also\n\nav_opt_find().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_get_hw_config-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_get_hw_config","text":"avcodec_get_hw_config(codec, index::Integer)\n\nRetrieve supported hardware configurations for a codec.\n\nValues of index from zero to some maximum return the indexed configuration descriptor; all other values return NULL. If the codec does not support any hardware configurations then it will always return NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_get_hw_frames_parameters-Tuple{Any, Any, Int32, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_get_hw_frames_parameters","text":"avcodec_get_hw_frames_parameters(avctx, device_ref, hw_pix_fmt::AVPixelFormat, out_frames_ref)\n\nCreate and return a AVHWFramesContext with values adequate for hardware decoding. This is meant to get called from the get_format callback, and is a helper for preparing a AVHWFramesContext for AVCodecContext.hw_frames_ctx. This API is for decoding with certain hardware acceleration modes/APIs only.\n\nThe returned AVHWFramesContext is not initialized. The caller must do this with av_hwframe_ctx_init().\n\nCalling this function is not a requirement, but makes it simpler to avoid codec or hardware API specific details when manually allocating frames.\n\nAlternatively to this, an API user can set AVCodecContext.hw_device_ctx, which sets up AVCodecContext.hw_frames_ctx fully automatically, and makes it unnecessary to call this function or having to care about AVHWFramesContext initialization at all.\n\nThere are a number of requirements for calling this function:\n\nIt must be called from get_format with the same avctx parameter that was passed to get_format. Calling it outside of get_format is not allowed, and can trigger undefined behavior. - The function is not always supported (see description of return values). Even if this function returns successfully, hwaccel initialization could fail later. (The degree to which implementations check whether the stream is actually supported varies. Some do this check only after the user's get_format callback returns.) - The hw_pix_fmt must be one of the choices suggested by get_format. If the user decides to use a AVHWFramesContext prepared with this API function, the user must return the same hw_pix_fmt from get_format. - The device_ref passed to this function must support the given hw_pix_fmt. - After calling this API function, it is the user's responsibility to initialize the AVHWFramesContext (returned by the out_frames_ref parameter), and to set AVCodecContext.hw_frames_ctx to it. If done, this must be done before returning from get_format (this is implied by the normal AVCodecContext.hw_frames_ctx API rules). - The AVHWFramesContext parameters may change every time time get_format is called. Also, AVCodecContext.hw_frames_ctx is reset before get_format. So you are inherently required to go through this process again on every get_format call. - It is perfectly possible to call this function without actually using the resulting AVHWFramesContext. One use-case might be trying to reuse a previously initialized AVHWFramesContext, and calling this API function only to test whether the required frame parameters have changed. - Fields that use dynamically allocated values of any kind must not be set by the user unless setting them is explicitly allowed by the documentation. If the user sets AVHWFramesContext.free and AVHWFramesContext.user_opaque, the new free callback must call the potentially set previous free callback. This API call may set any dynamically allocated fields, including the free callback.\n\nThe function will set at least the following fields on AVHWFramesContext (potentially more, depending on hwaccel API):\n\nAll fields set by av_hwframe_ctx_alloc(). - Set the format field to hw_pix_fmt. - Set the sw_format field to the most suited and most versatile format. (An implication is that this will prefer generic formats over opaque formats with arbitrary restrictions, if possible.) - Set the width/height fields to the coded frame size, rounded up to the API-specific minimum alignment. - Only _if_ the hwaccel requires a pre-allocated pool: set the initial_pool_size field to the number of maximum reference surfaces possible with the codec, plus 1 surface for the user to work (meaning the user can safely reference at most 1 decoded surface at a time), plus additional buffering introduced by frame threading. If the hwaccel does not require pre-allocation, the field is left to 0, and the decoder will allocate new surfaces on demand during decoding. - Possibly AVHWFramesContext.hwctx fields, depending on the underlying hardware API.\n\nEssentially, out_frames_ref returns the same as av_hwframe_ctx_alloc(), but with basic frame parameters set.\n\nThe function is stateless, and does not change the AVCodecContext or the device_ref AVHWDeviceContext.\n\nArguments\n\navctx: The context which is currently calling get_format, and which implicitly contains all state needed for filling the returned AVHWFramesContext properly.\ndevice_ref: A reference to the AVHWDeviceContext describing the device which will be used by the hardware decoder.\nhw_pix_fmt: The hwaccel format you are going to return from get_format.\nout_frames_ref: On success, set to a reference to an _uninitialized_ AVHWFramesContext, created from the given device_ref. Fields will be set to values required for decoding. Not changed if an error is returned.\n\nReturns\n\nzero on success, a negative value on error. The following error codes have special semantics: AVERROR(ENOENT): the decoder does not support this functionality. Setup is always manual, or it is a decoder which does not support setting AVCodecContext.hw_frames_ctx at all, or it is a software format. AVERROR(EINVAL): it is known that hardware decoding is not supported for this configuration, or the device_ref is not supported for the hwaccel referenced by hw_pix_fmt.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_get_name-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_get_name","text":"avcodec_get_name(id::AVCodecID)\n\nGet the name of a codec.\n\nReturns\n\na static string identifying the codec; never NULL\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_get_subtitle_rect_class-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_get_subtitle_rect_class","text":"avcodec_get_subtitle_rect_class()\n\nGet the AVClass for AVSubtitleRect. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options.\n\nSee also\n\nav_opt_find().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_get_supported_config-Tuple{Any, Any, UInt32, Integer, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_get_supported_config","text":"avcodec_get_supported_config(avctx, codec, config::AVCodecConfig, flags::Integer, out_configs, out_num_configs)\n\nRetrieve a list of all supported values for a given configuration type.\n\nArguments\n\navctx: An optional context to use. Values such as strict_std_compliance may affect the result. If NULL, default values are used.\ncodec: The codec to query, or NULL to use avctx->codec.\nconfig: The configuration to query.\nflags: Currently unused; should be set to zero.\nout_configs: On success, set to a list of configurations, terminated by a config-specific terminator, or NULL if all possible values are supported.\nout_num_configs: On success, set to the number of elements inout_configs, excluding the terminator. Optional.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_get_type-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_get_type","text":"avcodec_get_type(codec_id::AVCodecID)\n\nGet the type of the given codec.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_is_open-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_is_open","text":"avcodec_is_open(s)\n\nReturns\n\na positive value if s is open (i.e. avcodec_open2() was called on it), 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_license-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_license","text":"avcodec_license()\n\nReturn the libavcodec license.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_open2-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_open2","text":"avcodec_open2(avctx, codec, options)\n\nInitialize the AVCodecContext to use the given AVCodec. Prior to using this function the context has to be allocated with avcodec_alloc_context3().\n\nThe functions avcodec_find_decoder_by_name(), avcodec_find_encoder_by_name(), avcodec_find_decoder() and avcodec_find_encoder() provide an easy way for retrieving a codec.\n\nDepending on the codec, you might need to set options in the codec context also for decoding (e.g. width, height, or the pixel or audio sample format in the case the information is not available in the bitstream, as when decoding raw audio or video).\n\nOptions in the codec context can be set either by setting them in the options AVDictionary, or by setting the values in the context itself, directly or by using the av_opt_set() API before calling this function.\n\nExample:\n\n av_dict_set(&opts, \"b\", \"2.5M\", 0);\n codec = avcodec_find_decoder(AV_CODEC_ID_H264);\n if (!codec)\n     exit(1);\n\n context = avcodec_alloc_context3(codec);\n\n if (avcodec_open2(context, codec, opts) < 0)\n     exit(1);\n\nIn the case AVCodecParameters are available (e.g. when demuxing a stream using libavformat, and accessing the AVStream contained in the demuxer), the codec parameters can be copied to the codec context using avcodec_parameters_to_context(), as in the following example:\n\n AVStream *stream = ...;\n context = avcodec_alloc_context3(codec);\n if (avcodec_parameters_to_context(context, stream->codecpar) < 0)\n     exit(1);\n if (avcodec_open2(context, codec, NULL) < 0)\n     exit(1);\n\nnote: Note\nAlways call this function before using decoding routines (such as avcodecreceiveframe()).\n\nArguments\n\navctx: The context to initialize.\ncodec: The codec to open this context for. If a non-NULL codec has been previously passed to avcodec_alloc_context3() or for this context, then this parameter MUST be either NULL or equal to the previously passed codec.\noptions: A dictionary filled with AVCodecContext and codec-private options, which are set on top of the options already set in avctx, can be NULL. On return this object will be filled with options that were not found in the avctx codec context.\n\nReturns\n\nzero on success, a negative value on error\n\nSee also\n\navcodec_alloc_context3(), avcodec_find_decoder(), avcodec_find_encoder(), av_dict_set(), av_opt_set(), av_opt_find(), avcodec_parameters_to_context()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_parameters_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_parameters_alloc","text":"avcodec_parameters_alloc()\n\nAllocate a new AVCodecParameters and set its fields to default values (unknown/invalid/0). The returned struct must be freed with avcodec_parameters_free().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_parameters_copy-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_parameters_copy","text":"avcodec_parameters_copy(dst, src)\n\nCopy the contents of src to dst. Any allocated fields in dst are freed and replaced with newly allocated duplicates of the corresponding fields in src.\n\nReturns\n\n= 0 on success, a negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_parameters_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_parameters_free","text":"avcodec_parameters_free(par)\n\nFree an AVCodecParameters instance and everything associated with it and write NULL to the supplied pointer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_parameters_from_context-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_parameters_from_context","text":"avcodec_parameters_from_context(par, codec)\n\nFill the parameters struct based on the values from the supplied codec context. Any allocated fields in par are freed and replaced with duplicates of the corresponding fields in codec.\n\nReturns\n\n= 0 on success, a negative AVERROR code on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_parameters_to_context-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_parameters_to_context","text":"avcodec_parameters_to_context(codec, par)\n\nFill the codec context based on the values from the supplied codec parameters. Any allocated fields in codec that have a corresponding field in par are freed and replaced with duplicates of the corresponding field in par. Fields in codec that do not have a counterpart in par are not touched.\n\nReturns\n\n= 0 on success, a negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_pix_fmt_to_codec_tag-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_pix_fmt_to_codec_tag","text":"avcodec_pix_fmt_to_codec_tag(pix_fmt::AVPixelFormat)\n\nReturn a value representing the fourCC code associated to the pixel format pix_fmt, or 0 if no associated fourCC code can be found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_profile_name-Tuple{UInt32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_profile_name","text":"avcodec_profile_name(codec_id::AVCodecID, profile::Integer)\n\nReturn a name for the specified profile, if available.\n\nnote: Note\nunlike av_get_profile_name(), which searches a list of profiles supported by a specific decoder or encoder implementation, this function searches the list of profiles from the AVCodecDescriptor\n\nArguments\n\ncodec_id: the ID of the codec to which the requested profile belongs\nprofile: the profile value for which a name is requested\n\nReturns\n\nA name for the profile if found, NULL otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_receive_frame-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_receive_frame","text":"avcodec_receive_frame(avctx, frame)\n\nReturn decoded output data from a decoder or encoder (when the AVCODECFLAGRECONFRAME flag is used).\n\n\\retval0 success, a frame was returned\n\n\\retvalAVERROR(EAGAIN) output is not available in this state - user must try to send new input\n\n\\retvalAVERROR_EOF the codec has been fully flushed, and there will be no more output frames\n\n\\retvalAVERROR(EINVAL) codec not opened, or it is an encoder without the AVCODECFLAGRECONFRAME flag enabled\n\n\\retval\"other negative error code\" legitimate decoding errors\n\nArguments\n\navctx: codec context\nframe: This will be set to a reference-counted video or audio frame (depending on the decoder type) allocated by the codec. Note that the function will always call av_frame_unref(frame) before doing anything else.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_receive_packet-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_receive_packet","text":"avcodec_receive_packet(avctx, avpkt)\n\nRead encoded data from the encoder.\n\n\\retval0 success\n\n\\retvalAVERROR(EAGAIN) output is not available in the current state - user must try to send input\n\n\\retvalAVERROR_EOF the encoder has been fully flushed, and there will be no more output packets\n\n\\retvalAVERROR(EINVAL) codec not opened, or it is a decoder\n\n\\retval\"another negative error code\" legitimate encoding errors\n\nArguments\n\navctx: codec context\navpkt: This will be set to a reference-counted packet allocated by the encoder. Note that the function will always call av_packet_unref(avpkt) before doing anything else.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_send_frame-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_send_frame","text":"avcodec_send_frame(avctx, frame)\n\nSupply a raw video or audio frame to the encoder. Use avcodec_receive_packet() to retrieve buffered output packets.\n\nFor audio: If AV_CODEC_CAP_VARIABLE_FRAME_SIZE is set, then each frame can have any number of samples. If it is not set, frame->nb_samples must be equal to avctx->frame_size for all frames except the last. The final frame may be smaller than avctx->frame_size.\n\n\\retval0 success\n\n\\retvalAVERROR(EAGAIN) input is not accepted in the current state - user must read output with avcodec_receive_packet() (once all output is read, the packet should be resent, and the call will not fail with EAGAIN).\n\n\\retvalAVERROR_EOF the encoder has been flushed, and no new frames can be sent to it\n\n\\retvalAVERROR(EINVAL) codec not opened, it is a decoder, or requires flush\n\n\\retvalAVERROR(ENOMEM) failed to add packet to internal queue, or similar\n\n\\retval\"another negative error code\" legitimate encoding errors\n\nArguments\n\navctx: codec context\nframe:[in] AVFrame containing the raw audio or video frame to be encoded. Ownership of the frame remains with the caller, and the encoder will not write to the frame. The encoder may create a reference to the frame data (or copy it if the frame is not reference-counted). It can be NULL, in which case it is considered a flush packet. This signals the end of the stream. If the encoder still has packets buffered, it will return them after this call. Once flushing mode has been entered, additional flush packets are ignored, and sending frames will return AVERROR_EOF.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_send_packet-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_send_packet","text":"avcodec_send_packet(avctx, avpkt)\n\nSupply raw packet data as input to a decoder.\n\nInternally, this call will copy relevant AVCodecContext fields, which can influence decoding per-packet, and apply them when the packet is actually decoded. (For example AVCodecContext.skip_frame, which might direct the decoder to drop the frame contained by the packet sent with this function.)\n\nwarning: Warning\nThe input buffer, avpkt->data must be AV_INPUT_BUFFER_PADDING_SIZE larger than the actual read bytes because some optimized bitstream readers read 32 or 64 bits at once and could read over the end.\n\nnote: Note\nThe AVCodecContext MUST have been opened with avcodec_open2() before packets may be fed to the decoder.\n\n\\retval0 success\n\n\\retvalAVERROR(EAGAIN) input is not accepted in the current state - user must read output with avcodec_receive_frame() (once all output is read, the packet should be resent, and the call will not fail with EAGAIN).\n\n\\retvalAVERROR_EOF the decoder has been flushed, and no new packets can be sent to it (also returned if more than 1 flush packet is sent)\n\n\\retvalAVERROR(EINVAL) codec not opened, it is an encoder, or requires flush\n\n\\retvalAVERROR(ENOMEM) failed to add packet to internal queue, or similar\n\n\\retval\"another negative error code\" legitimate decoding errors\n\nArguments\n\navctx: codec context\navpkt:[in] The input AVPacket. Usually, this will be a single video frame, or several complete audio frames. Ownership of the packet remains with the caller, and the decoder will not write to the packet. The decoder may create a reference to the packet data (or copy it if the packet is not reference-counted). Unlike with older APIs, the packet is always fully consumed, and if it contains multiple frames (e.g. some audio codecs), will require you to call avcodec_receive_frame() multiple times afterwards before you can send a new packet. It can be NULL (or an AVPacket with data set to NULL and size set to 0); in this case, it is considered a flush packet, which signals the end of the stream. Sending the first flush packet will return success. Subsequent ones are unnecessary and will return AVERROR_EOF. If the decoder still has frames buffered, it will return them after sending a flush packet.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_string-Tuple{Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_string","text":"avcodec_string(buf, buf_size::Integer, enc, encode::Integer)\n\n@}\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avcodec_version-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avcodec_version","text":"avcodec_version()\n\nReturn the LIBAVCODEC_VERSION_INT constant.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avdevice_app_to_dev_control_message-Tuple{Any, UInt32, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avdevice_app_to_dev_control_message","text":"avdevice_app_to_dev_control_message(s, type::AVAppToDevMessageType, data, data_size::Csize_t)\n\nSend control message from application to device.\n\nArguments\n\ns: device context.\ntype: message type.\ndata: message data. Exact type depends on message type.\ndata_size: size of message data.\n\nReturns\n\n= 0 on success, negative on error. AVERROR(ENOSYS) when device doesn't implement handler of the message.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avdevice_configuration-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avdevice_configuration","text":"avdevice_configuration()\n\nReturn the libavdevice build-time configuration.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avdevice_dev_to_app_control_message-Tuple{Any, UInt32, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avdevice_dev_to_app_control_message","text":"avdevice_dev_to_app_control_message(s, type::AVDevToAppMessageType, data, data_size::Csize_t)\n\nSend control message from device to application.\n\nArguments\n\ns: device context.\ntype: message type.\ndata: message data. Can be NULL.\ndata_size: size of message data.\n\nReturns\n\n= 0 on success, negative on error. AVERROR(ENOSYS) when application doesn't implement handler of the message.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avdevice_free_list_devices-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avdevice_free_list_devices","text":"avdevice_free_list_devices(device_list)\n\nConvenient function to free result of avdevice_list_devices().\n\nArguments\n\ndevice_list: device list to be freed.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avdevice_license-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avdevice_license","text":"avdevice_license()\n\nReturn the libavdevice license.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avdevice_list_devices-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avdevice_list_devices","text":"avdevice_list_devices(s, device_list)\n\nList devices.\n\nReturns available device names and their parameters.\n\nnote: Note\n: Some devices may accept system-dependent device names that cannot be autodetected. The list returned by this function cannot be assumed to be always completed.\n\nArguments\n\ns: device context.\ndevice_list:[out] list of autodetected devices.\n\nReturns\n\ncount of autodetected devices, negative on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avdevice_list_input_sources-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avdevice_list_input_sources","text":"avdevice_list_input_sources(device, device_name, device_options, device_list)\n\nList devices.\n\nReturns available device names and their parameters. These are convenient wrappers for avdevice_list_devices(). Device context is allocated and deallocated internally.\n\nnote: Note\ndevice argument takes precedence over device_name when both are set.\n\nArguments\n\ndevice: device format. May be NULL if device name is set.\ndevice_name: device name. May be NULL if device format is set.\ndevice_options: An AVDictionary filled with device-private options. May be NULL. The same options must be passed later to avformat_write_header() for output devices or avformat_open_input() for input devices, or at any other place that affects device-private options.\ndevice_list:[out] list of autodetected devices\n\nReturns\n\ncount of autodetected devices, negative on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avdevice_register_all-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avdevice_register_all","text":"avdevice_register_all()\n\nInitialize libavdevice and register all the input and output devices.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avdevice_version-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avdevice_version","text":"avdevice_version()\n\nReturn the LIBAVDEVICE_VERSION_INT constant.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_configuration-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_configuration","text":"avfilter_configuration()\n\nReturn the libavfilter build-time configuration.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_filter_pad_count-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_filter_pad_count","text":"avfilter_filter_pad_count(filter, is_output::Integer)\n\nGet the number of elements in an AVFilter's inputs or outputs array.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_free","text":"avfilter_free(filter)\n\nFree a filter context. This will also remove the filter from its filtergraph's list of filters.\n\nArguments\n\nfilter: the filter to free\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_get_by_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_get_by_name","text":"avfilter_get_by_name(name)\n\nGet a filter definition matching the given name.\n\nArguments\n\nname: the filter name to find\n\nReturns\n\nthe filter definition, if any matching one is registered. NULL if none found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_get_class-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_get_class","text":"avfilter_get_class()\n\nReturns\n\nAVClass for AVFilterContext.\n\nSee also\n\nav_opt_find().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_alloc","text":"avfilter_graph_alloc()\n\nAllocate a filter graph.\n\nReturns\n\nthe allocated filter graph on success or NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_alloc_filter-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_alloc_filter","text":"avfilter_graph_alloc_filter(graph, filter, name)\n\nCreate a new filter instance in a filter graph.\n\nArguments\n\ngraph: graph in which the new filter will be used\nfilter: the filter to create an instance of\nname: Name to give to the new instance (will be copied to AVFilterContext.name). This may be used by the caller to identify different filters, libavfilter itself assigns no semantics to this parameter. May be NULL.\n\nReturns\n\nthe context of the newly created filter instance (note that it is also retrievable directly through AVFilterGraph.filters or with avfilter_graph_get_filter()) on success or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_config-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_config","text":"avfilter_graph_config(graphctx, log_ctx)\n\nCheck validity and configure all the links and formats in the graph.\n\nArguments\n\ngraphctx: the filter graph\nlog_ctx: context used for logging\n\nReturns\n\n= 0 in case of success, a negative AVERROR code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_create_filter-NTuple{6, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_create_filter","text":"avfilter_graph_create_filter(filt_ctx, filt, name, args, opaque, graph_ctx)\n\nA convenience wrapper that allocates and initializes a filter in a single step. The filter instance is created from the filter filt and inited with the parameter args. opaque is currently ignored.\n\nIn case of success put in *filt_ctx the pointer to the created filter instance, otherwise set *filt_ctx to NULL.\n\nwarning: Warning\nSince the filter is initialized after this function successfully returns, you MUST NOT set any further options on it. If you need to do that, call ::avfilter_graph_alloc_filter(), followed by setting the options, followed by ::avfilter_init_dict() instead of this function.\n\nArguments\n\nname: the instance name to give to the created filter instance\ngraph_ctx: the filter graph\n\nReturns\n\na negative AVERROR error code in case of failure, a non negative value otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_dump-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_dump","text":"avfilter_graph_dump(graph, options)\n\nDump a graph into a human-readable string representation.\n\nArguments\n\ngraph: the graph to dump\noptions: formatting options; currently ignored\n\nReturns\n\na string, or NULL in case of memory allocation failure; the string must be freed using av_free\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_free","text":"avfilter_graph_free(graph)\n\nFree a graph, destroy its links, and set *graph to NULL. If *graph is NULL, do nothing.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_get_filter-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_get_filter","text":"avfilter_graph_get_filter(graph, name)\n\nGet a filter instance identified by instance name from graph.\n\nArguments\n\ngraph: filter graph to search through.\nname: filter instance name (should be unique in the graph).\n\nReturns\n\nthe pointer to the found filter instance or NULL if it cannot be found.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_parse-NTuple{5, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_parse","text":"avfilter_graph_parse(graph, filters, inputs, outputs, log_ctx)\n\nAdd a graph described by a string to a graph.\n\nnote: Note\nThe caller must provide the lists of inputs and outputs, which therefore must be known before calling the function.\n\nnote: Note\nThe inputs parameter describes inputs of the already existing part of the graph; i.e. from the point of view of the newly created part, they are outputs. Similarly the outputs parameter describes outputs of the already existing filters, which are provided as inputs to the parsed filters.\n\nArguments\n\ngraph: the filter graph where to link the parsed graph context\nfilters: string to be parsed\ninputs: linked list to the inputs of the graph\noutputs: linked list to the outputs of the graph\n\nReturns\n\nzero on success, a negative AVERROR code on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_parse2-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_parse2","text":"avfilter_graph_parse2(graph, filters, inputs, outputs)\n\nAdd a graph described by a string to a graph.\n\nnote: Note\nThis function returns the inputs and outputs that are left unlinked after parsing the graph and the caller then deals with them.\n\nnote: Note\nThis function makes no reference whatsoever to already existing parts of the graph and the inputs parameter will on return contain inputs of the newly parsed part of the graph. Analogously the outputs parameter will contain outputs of the newly created filters.\n\nArguments\n\ngraph:[in] the filter graph where to link the parsed graph context\nfilters:[in] string to be parsed\ninputs:[out] a linked list of all free (unlinked) inputs of the parsed graph will be returned here. It is to be freed by the caller using avfilter_inout_free().\noutputs:[out] a linked list of all free (unlinked) outputs of the parsed graph will be returned here. It is to be freed by the caller using avfilter_inout_free().\n\nReturns\n\nzero on success, a negative AVERROR code on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_parse_ptr-NTuple{5, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_parse_ptr","text":"avfilter_graph_parse_ptr(graph, filters, inputs, outputs, log_ctx)\n\nAdd a graph described by a string to a graph.\n\nIn the graph filters description, if the input label of the first filter is not specified, \"in\" is assumed; if the output label of the last filter is not specified, \"out\" is assumed.\n\nArguments\n\ngraph: the filter graph where to link the parsed graph context\nfilters: string to be parsed\ninputs: pointer to a linked list to the inputs of the graph, may be NULL. If non-NULL, *inputs is updated to contain the list of open inputs after the parsing, should be freed with avfilter_inout_free().\noutputs: pointer to a linked list to the outputs of the graph, may be NULL. If non-NULL, *outputs is updated to contain the list of open outputs after the parsing, should be freed with avfilter_inout_free().\n\nReturns\n\nnon negative on success, a negative AVERROR code on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_queue_command-Tuple{Any, Any, Any, Any, Integer, Float64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_queue_command","text":"avfilter_graph_queue_command(graph, target, cmd, arg, flags::Integer, ts::Cdouble)\n\nQueue a command for one or more filter instances.\n\nnote: Note\nAs this executes commands after this function returns, no return code from the filter is provided, also AVFILTER_CMD_FLAG_ONE is not supported.\n\nArguments\n\ngraph: the filter graph\ntarget: the filter(s) to which the command should be sent \"all\" sends to all filters otherwise it can be a filter or filter instance name which will send the command to all matching filters.\ncmd: the command to sent, for handling simplicity all commands must be alphanumeric only\narg: the argument for the command\nts: time at which the command should be sent to the filter\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_request_oldest-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_request_oldest","text":"avfilter_graph_request_oldest(graph)\n\nRequest a frame on the oldest sink link.\n\nIf the request returns AVERROR_EOF, try the next.\n\nNote that this function is not meant to be the sole scheduling mechanism of a filtergraph, only a convenience function to help drain a filtergraph in a balanced way under normal circumstances.\n\nAlso note that AVERROR_EOF does not mean that frames did not arrive on some of the sinks during the process. When there are multiple sink links, in case the requested link returns an EOF, this may cause a filter to flush pending frames which are sent to another sink link, although unrequested.\n\nReturns\n\nthe return value of ff_request_frame(), or AVERROR_EOF if all links returned AVERROR_EOF\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_segment_apply-Tuple{Any, Integer, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_segment_apply","text":"avfilter_graph_segment_apply(seg, flags::Integer, inputs, outputs)\n\nApply all filter/link descriptions from a graph segment to the associated filtergraph.\n\nThis functions is currently equivalent to calling the following in sequence: - avfilter_graph_segment_create_filters(); - avfilter_graph_segment_apply_opts(); - avfilter_graph_segment_init(); - avfilter_graph_segment_link(); failing if any of them fails. This list may be extended in the future.\n\nSince the above functions are idempotent, the caller may call some of them manually, then do some custom processing on the filtergraph, then call this function to do the rest.\n\n\\retval\"non-negative number\" success\n\n\\retval\"negative error code\" failure\n\nnote: Note\nCalling this function multiple times is safe, as it is idempotent.\n\nArguments\n\nseg: the filtergraph segment to process\nflags: reserved for future use, caller must set to 0 for now\ninputs:[out] passed to avfilter_graph_segment_link()\noutputs:[out] passed to avfilter_graph_segment_link()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_segment_apply_opts-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_segment_apply_opts","text":"avfilter_graph_segment_apply_opts(seg, flags::Integer)\n\nApply parsed options to filter instances in a graph segment.\n\nWalk through all filter instances in the graph segment that have option dictionaries associated with them and apply those options with av_opt_set_dict2(..., AV_OPT_SEARCH_CHILDREN). AVFilterParams.opts is replaced by the dictionary output by av_opt_set_dict2(), which should be empty (NULL) if all options were successfully applied.\n\nIf any options could not be found, this function will continue processing all other filters and finally return AVERROR_OPTION_NOT_FOUND (unless another error happens). The calling program may then deal with unapplied options as it wishes.\n\nAny creation-pending filters (see avfilter_graph_segment_create_filters()) present in the segment will cause this function to fail. AVFilterParams with no associated filter context are simply skipped.\n\n\\retval\"non-negative number\" Success, all options were successfully applied.\n\n\\retvalAVERROROPTIONNOT_FOUND some options were not found in a filter\n\n\\retval\"another negative error code\" other failures\n\nnote: Note\nCalling this function multiple times is safe, as it is idempotent.\n\nArguments\n\nseg: the filtergraph segment to process\nflags: reserved for future use, caller must set to 0 for now\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_segment_create_filters-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_segment_create_filters","text":"avfilter_graph_segment_create_filters(seg, flags::Integer)\n\nCreate filters specified in a graph segment.\n\nWalk through the creation-pending AVFilterParams in the segment and create new filter instances for them. Creation-pending params are those where AVFilterParams.filter_name is non-NULL (and hence AVFilterParams.filter is NULL). All other AVFilterParams instances are ignored.\n\nFor any filter created by this function, the corresponding AVFilterParams.filter is set to the newly-created filter context, AVFilterParams.filter_name and AVFilterParams.instance_name are freed and set to NULL.\n\n\\retval\"non-negative number\" Success, all creation-pending filters were successfully created\n\n\\retvalAVERRORFILTERNOT_FOUND some filter's name did not correspond to a known filter\n\n\\retval\"another negative error code\" other failures\n\nnote: Note\nCalling this function multiple times is safe, as it is idempotent.\n\nArguments\n\nseg: the filtergraph segment to process\nflags: reserved for future use, caller must set to 0 for now\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_segment_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_segment_free","text":"avfilter_graph_segment_free(seg)\n\nFree the provided AVFilterGraphSegment and everything associated with it.\n\nnote: Note\nThe filter contexts (AVFilterParams.filter) are owned by AVFilterGraph rather than AVFilterGraphSegment, so they are not freed.\n\nArguments\n\nseg: double pointer to the AVFilterGraphSegment to be freed. NULL will be written to this pointer on exit from this function.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_segment_init-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_segment_init","text":"avfilter_graph_segment_init(seg, flags::Integer)\n\nInitialize all filter instances in a graph segment.\n\nWalk through all filter instances in the graph segment and call avfilter_init_dict(..., NULL) on those that have not been initialized yet.\n\nAny creation-pending filters (see avfilter_graph_segment_create_filters()) present in the segment will cause this function to fail. AVFilterParams with no associated filter context or whose filter context is already initialized, are simply skipped.\n\n\\retval\"non-negative number\" Success, all filter instances were successfully initialized\n\n\\retval\"negative error code\" failure\n\nnote: Note\nCalling this function multiple times is safe, as it is idempotent.\n\nArguments\n\nseg: the filtergraph segment to process\nflags: reserved for future use, caller must set to 0 for now\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_segment_link-Tuple{Any, Integer, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_segment_link","text":"avfilter_graph_segment_link(seg, flags::Integer, inputs, outputs)\n\nLink filters in a graph segment.\n\nWalk through all filter instances in the graph segment and try to link all unlinked input and output pads. Any creation-pending filters (see avfilter_graph_segment_create_filters()) present in the segment will cause this function to fail. Disabled filters and already linked pads are skipped.\n\nEvery filter output pad that has a corresponding AVFilterPadParams with a non-NULL label is - linked to the input with the matching label, if one exists; - exported in the outputs linked list otherwise, with the label preserved. Unlabeled outputs are - linked to the first unlinked unlabeled input in the next non-disabled filter in the chain, if one exists - exported in the outputs linked list otherwise, with NULL label\n\nSimilarly, unlinked input pads are exported in the inputs linked list.\n\n\\retval\"non-negative number\" success\n\n\\retval\"negative error code\" failure\n\nnote: Note\nCalling this function multiple times is safe, as it is idempotent.\n\nArguments\n\nseg: the filtergraph segment to process\nflags: reserved for future use, caller must set to 0 for now\ninputs:[out] a linked list of all free (unlinked) inputs of the filters in this graph segment will be returned here. It is to be freed by the caller using avfilter_inout_free().\noutputs:[out] a linked list of all free (unlinked) outputs of the filters in this graph segment will be returned here. It is to be freed by the caller using avfilter_inout_free().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_segment_parse-Tuple{Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_segment_parse","text":"avfilter_graph_segment_parse(graph, graph_str, flags::Integer, seg)\n\nParse a textual filtergraph description into an intermediate form.\n\nThis intermediate representation is intended to be modified by the caller as described in the documentation of AVFilterGraphSegment and its children, and then applied to the graph either manually or with other avfilter_graph_segment_*() functions. See the documentation for avfilter_graph_segment_apply() for the canonical way to apply AVFilterGraphSegment.\n\n\\retval\"non-negative number\" success\n\n\\retval\"negative error code\" failure\n\nArguments\n\ngraph: Filter graph the parsed segment is associated with. Will only be used for logging and similar auxiliary purposes. The graph will not be actually modified by this function - the parsing results are instead stored in seg for further processing.\ngraph_str: a string describing the filtergraph segment\nflags: reserved for future use, caller must set to 0 for now\nseg: A pointer to the newly-created AVFilterGraphSegment is written here on success. The graph segment is owned by the caller and must be freed with avfilter_graph_segment_free() before graph itself is freed.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_send_command-Tuple{Any, Any, Any, Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_send_command","text":"avfilter_graph_send_command(graph, target, cmd, arg, res, res_len::Integer, flags::Integer)\n\nSend a command to one or more filter instances.\n\nArguments\n\ngraph: the filter graph\ntarget: the filter(s) to which the command should be sent \"all\" sends to all filters otherwise it can be a filter or filter instance name which will send the command to all matching filters.\ncmd: the command to send, for handling simplicity all commands must be alphanumeric only\narg: the argument for the command\nres: a buffer with size res_size where the filter(s) can return a response.\n\nReturns\n\n=0 on success otherwise an error code. AVERROR(ENOSYS) on unsupported commands\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_graph_set_auto_convert-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_graph_set_auto_convert","text":"avfilter_graph_set_auto_convert(graph, flags::Integer)\n\nEnable or disable automatic format conversion inside the graph.\n\nNote that format conversion can still happen inside explicitly inserted scale and aresample filters.\n\nArguments\n\nflags: any of the AVFILTER_AUTO_CONVERT_* constants\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_init_dict-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_init_dict","text":"avfilter_init_dict(ctx, options)\n\nInitialize a filter with the supplied dictionary of options.\n\nnote: Note\nThis function and avfilter_init_str() do essentially the same thing, the difference is in manner in which the options are passed. It is up to the calling code to choose whichever is more preferable. The two functions also behave differently when some of the provided options are not declared as supported by the filter. In such a case, avfilter_init_str() will fail, but this function will leave those extra options in the options AVDictionary and continue as usual.\n\nArguments\n\nctx: uninitialized filter context to initialize\noptions: An AVDictionary filled with options for this filter. On return this parameter will be destroyed and replaced with a dict containing options that were not found. This dictionary must be freed by the caller. May be NULL, then this function is equivalent to avfilter_init_str() with the second parameter set to NULL.\n\nReturns\n\n0 on success, a negative AVERROR on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_init_str-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_init_str","text":"avfilter_init_str(ctx, args)\n\nInitialize a filter with the supplied parameters.\n\nArguments\n\nctx: uninitialized filter context to initialize\nargs: Options to initialize the filter with. This must be a ':'-separated list of options in the 'key=value' form. May be NULL if the options have been set directly using the AVOptions API or there are no options that need to be set.\n\nReturns\n\n0 on success, a negative AVERROR on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_inout_alloc-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_inout_alloc","text":"avfilter_inout_alloc()\n\nAllocate a single AVFilterInOut entry. Must be freed with avfilter_inout_free().\n\nReturns\n\nallocated AVFilterInOut on success, NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_inout_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_inout_free","text":"avfilter_inout_free(inout)\n\nFree the supplied list of AVFilterInOut and set *inout to NULL. If *inout is NULL, do nothing.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_insert_filter-Tuple{Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_insert_filter","text":"avfilter_insert_filter(link, filt, filt_srcpad_idx::Integer, filt_dstpad_idx::Integer)\n\nInsert a filter in the middle of an existing link.\n\nArguments\n\nlink: the link into which the filter should be inserted\nfilt: the filter to be inserted\nfilt_srcpad_idx: the input pad on the filter to connect\nfilt_dstpad_idx: the output pad on the filter to connect\n\nReturns\n\nzero on success\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_license-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_license","text":"avfilter_license()\n\nReturn the libavfilter license.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_link-Tuple{Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_link","text":"avfilter_link(src, srcpad::Integer, dst, dstpad::Integer)\n\nLink two filters together.\n\nArguments\n\nsrc: the source filter\nsrcpad: index of the output pad on the source filter\ndst: the destination filter\ndstpad: index of the input pad on the destination filter\n\nReturns\n\nzero on success\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_link_get_hw_frames_ctx-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_link_get_hw_frames_ctx","text":"avfilter_link_get_hw_frames_ctx(link)\n\nGet the hardware frames context of a filter link.\n\nArguments\n\nlink: an AVFilterLink\n\nReturns\n\na ref-counted copy of the link's hw_frames_ctx field if there is a hardware frames context associated with the link or NULL otherwise. The returned AVBufferRef needs to be released with av_buffer_unref() when it is no longer used.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_pad_get_name-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_pad_get_name","text":"avfilter_pad_get_name(pads, pad_idx::Integer)\n\nGet the name of an AVFilterPad.\n\nArguments\n\npads: an array of AVFilterPads\npad_idx: index of the pad in the array; it is the caller's responsibility to ensure the index is valid\n\nReturns\n\nname of the pad_idx'th pad in pads\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_pad_get_type-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_pad_get_type","text":"avfilter_pad_get_type(pads, pad_idx::Integer)\n\nGet the type of an AVFilterPad.\n\nArguments\n\npads: an array of AVFilterPads\npad_idx: index of the pad in the array; it is the caller's responsibility to ensure the index is valid\n\nReturns\n\ntype of the pad_idx'th pad in pads\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_process_command-Tuple{Any, Any, Any, Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_process_command","text":"avfilter_process_command(filter, cmd, arg, res, res_len::Integer, flags::Integer)\n\nMake the filter instance process a command. It is recommended to use avfilter_graph_send_command().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_version-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_version","text":"avfilter_version()\n\nReturn the LIBAVFILTER_VERSION_INT constant.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_alloc_context-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_alloc_context","text":"avformat_alloc_context()\n\nAllocate an AVFormatContext. avformat_free_context() can be used to free the context and everything allocated by the framework within it.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_alloc_output_context2-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_alloc_output_context2","text":"avformat_alloc_output_context2(ctx, oformat, format_name, filename)\n\nAllocate an AVFormatContext for an output format. avformat_free_context() can be used to free the context and everything allocated by the framework within it.\n\nArguments\n\nctx: pointee is set to the created format context, or to NULL in case of failure\noformat: format to use for allocating the context, if NULL format_name and filename are used instead\nformat_name: the name of output format to use for allocating the context, if NULL filename is used instead\nfilename: the name of the filename to use for allocating the context, may be NULL\n\nReturns\n\n= 0 in case of success, a negative AVERROR code in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_close_input-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_close_input","text":"avformat_close_input(s)\n\nClose an opened input AVFormatContext. Free it and all its contents and set *s to NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_configuration-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_configuration","text":"avformat_configuration()\n\nReturn the libavformat build-time configuration.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_find_stream_info-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_find_stream_info","text":"avformat_find_stream_info(ic, options)\n\nRead packets of a media file to get stream information. This is useful for file formats with no headers such as MPEG. This function also computes the real framerate in case of MPEG-2 repeat frame mode. The logical file position is not changed by this function; examined packets may be buffered for later processing.\n\nnote: Note\nthis function isn't guaranteed to open all the codecs, so options being non-empty at return is a perfectly normal behavior.\n\n\\todo Let the user decide somehow what information is needed so that we do not waste time getting stuff the user does not need.\n\nArguments\n\nic: media file handle\noptions: If non-NULL, an ic.nb_streams long array of pointers to dictionaries, where i-th member contains options for codec corresponding to i-th stream. On return each dictionary will be filled with options that were not found.\n\nReturns\n\n=0 if OK, AVERROR_xxx on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_flush-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_flush","text":"avformat_flush(s)\n\nDiscard all internally buffered data. This can be useful when dealing with discontinuities in the byte stream. Generally works only with formats that can resync. This includes headerless formats like MPEG-TS/TS but should also work with NUT, Ogg and in a limited way AVI for example.\n\nThe set of streams, the detected duration, stream parameters and codecs do not change when calling this function. If you want a complete reset, it's better to open a new AVFormatContext.\n\nThis does not flush the AVIOContext (s->pb). If necessary, call avio_flush(s->pb) before calling this function.\n\nArguments\n\ns: media file handle\n\nReturns\n\n=0 on success, error code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_free_context-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_free_context","text":"avformat_free_context(s)\n\nFree an AVFormatContext and all its streams.\n\nArguments\n\ns: context to free\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_get_class-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_get_class","text":"avformat_get_class()\n\nGet the AVClass for AVFormatContext. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options.\n\nSee also\n\nav_opt_find().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_get_mov_audio_tags-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_get_mov_audio_tags","text":"avformat_get_mov_audio_tags()\n\nReturns\n\nthe table mapping MOV FourCCs for audio to AVCodecID.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_get_mov_video_tags-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_get_mov_video_tags","text":"avformat_get_mov_video_tags()\n\nReturns\n\nthe table mapping MOV FourCCs for video to libavcodec AVCodecID.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_get_riff_audio_tags-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_get_riff_audio_tags","text":"avformat_get_riff_audio_tags()\n\nReturns\n\nthe table mapping RIFF FourCCs for audio to AVCodecID.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_get_riff_video_tags-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_get_riff_video_tags","text":"avformat_get_riff_video_tags()\n\nriff_fourcc RIFF FourCCs\n\n@{ Get the tables mapping RIFF FourCCs to libavcodec AVCodecIDs. The tables are meant to be passed to av_codec_get_id()/av_codec_get_tag() as in the following code:\n\n uint32_t tag = MKTAG('H', '2', '6', '4');\n const struct AVCodecTag *table[] = { avformat_get_riff_video_tags(), 0 };\n enum AVCodecID id = av_codec_get_id(table, tag);\n\nReturns\n\nthe table mapping RIFF FourCCs for video to libavcodec AVCodecID.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_index_get_entries_count-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_index_get_entries_count","text":"avformat_index_get_entries_count(st)\n\nGet the index entry count for the given AVStream.\n\nArguments\n\nst: stream\n\nReturns\n\nthe number of index entries in the stream\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_index_get_entry-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_index_get_entry","text":"avformat_index_get_entry(st, idx::Integer)\n\nGet the AVIndexEntry corresponding to the given index.\n\nnote: Note\nThe pointer returned by this function is only guaranteed to be valid until any function that takes the stream or the parent AVFormatContext as input argument is called.\n\nArguments\n\nst: Stream containing the requested AVIndexEntry.\nidx: The desired index.\n\nReturns\n\nA pointer to the requested AVIndexEntry if it exists, NULL otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_index_get_entry_from_timestamp-Tuple{Any, Int64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_index_get_entry_from_timestamp","text":"avformat_index_get_entry_from_timestamp(st, wanted_timestamp::Int64, flags::Integer)\n\nGet the AVIndexEntry corresponding to the given timestamp.\n\nnote: Note\nThe pointer returned by this function is only guaranteed to be valid until any function that takes the stream or the parent AVFormatContext as input argument is called.\n\nArguments\n\nst: Stream containing the requested AVIndexEntry.\nwanted_timestamp: Timestamp to retrieve the index entry for.\nflags: If AVSEEK_FLAG_BACKWARD then the returned entry will correspond to the timestamp which is <= the requested one, if backward is 0, then it will be >= if AVSEEK_FLAG_ANY seek to any frame, only keyframes otherwise.\n\nReturns\n\nA pointer to the requested AVIndexEntry if it exists, NULL otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_init_output-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_init_output","text":"avformat_init_output(s, options)\n\nAllocate the stream private data and initialize the codec, but do not write the header. May optionally be used before avformat_write_header() to initialize stream parameters before actually writing the header. If using this function, do not pass the same options to avformat_write_header().\n\n\\retvalAVSTREAMINITINWRITEHEADER On success, if the codec requires avformat_write_header to fully initialize.\n\n\\retvalAVSTREAMINITININITOUTPUT On success, if the codec has been fully initialized.\n\n\\retvalAVERROR Anegative AVERROR on failure.\n\nArguments\n\ns: Media file handle, must be allocated with avformat_alloc_context(). Its AVFormatContext.oformat \"oformat\" field must be set to the desired output format; Its AVFormatContext.pb \"pb\" field must be set to an already opened ::AVIOContext.\noptions: An ::AVDictionary filled with AVFormatContext and muxer-private options. On return this parameter will be destroyed and replaced with a dict containing options that were not found. May be NULL.\n\nSee also\n\nav_opt_find, av_dict_set, avio_open, av_oformat_next, avformat_write_header.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_license-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_license","text":"avformat_license()\n\nReturn the libavformat license.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_match_stream_specifier-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_match_stream_specifier","text":"avformat_match_stream_specifier(s, st, spec)\n\nCheck if the stream st contained in s is matched by the stream specifier spec.\n\nSee the \"stream specifiers\" chapter in the documentation for the syntax of spec.\n\nnote: Note\nA stream specifier can match several streams in the format.\n\nReturns\n\n0 if st is matched by spec; 0 if st is not matched by spec; AVERROR code if spec is invalid\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_network_deinit-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_network_deinit","text":"avformat_network_deinit()\n\nUndo the initialization done by avformat_network_init. Call it only once for each time you called avformat_network_init.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_network_init-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_network_init","text":"avformat_network_init()\n\nDo global initialization of network libraries. This is optional, and not recommended anymore.\n\nThis functions only exists to work around thread-safety issues with older GnuTLS or OpenSSL libraries. If libavformat is linked to newer versions of those libraries, or if you do not use them, calling this function is unnecessary. Otherwise, you need to call this function before any other threads using them are started.\n\nThis function will be deprecated once support for older GnuTLS and OpenSSL libraries is removed, and this function has no purpose anymore.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_new_stream-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_new_stream","text":"avformat_new_stream(s, c)\n\nAdd a new stream to a media file.\n\nWhen demuxing, it is called by the demuxer in read_header(). If the flag AVFMTCTX_NOHEADER is set in s.ctx_flags, then it may also be called in read_packet().\n\nWhen muxing, should be called by the user before avformat_write_header().\n\nUser is required to call avformat_free_context() to clean up the allocation by avformat_new_stream().\n\nArguments\n\ns: media file handle\nc: unused, does nothing\n\nReturns\n\nnewly created stream or NULL on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_open_input-NTuple{4, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_open_input","text":"avformat_open_input(ps, url, fmt, options)\n\nOpen an input stream and read the header. The codecs are not opened. The stream must be closed with avformat_close_input().\n\nnote: Note\nIf you want to use custom IO, preallocate the format context and set its pb field.\n\nArguments\n\nps: Pointer to user-supplied AVFormatContext (allocated by avformat_alloc_context). May be a pointer to NULL, in which case an AVFormatContext is allocated by this function and written into ps. Note that a user-supplied AVFormatContext will be freed on failure and its pointer set to NULL.\nurl: URL of the stream to open.\nfmt: If non-NULL, this parameter forces a specific input format. Otherwise the format is autodetected.\noptions: A dictionary filled with AVFormatContext and demuxer-private options. On return this parameter will be destroyed and replaced with a dict containing options that were not found. May be NULL.\n\nReturns\n\n0 on success; on failure: frees ps, sets its pointer to NULL, and returns a negative AVERROR.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_query_codec-Tuple{Any, UInt32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_query_codec","text":"avformat_query_codec(ofmt, codec_id::AVCodecID, std_compliance::Integer)\n\nTest if the given container can store a codec.\n\nArguments\n\nofmt: container to check for compatibility\ncodec_id: codec to potentially store in container\nstd_compliance: standards compliance level, one of FF_COMPLIANCE_*\n\nReturns\n\n1 if codec with ID codec_id can be stored in ofmt, 0 if it cannot. A negative number if this information is not available.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_seek_file-Tuple{Any, Integer, Int64, Int64, Int64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_seek_file","text":"avformat_seek_file(s, stream_index::Integer, min_ts::Int64, ts::Int64, max_ts::Int64, flags::Integer)\n\nSeek to timestamp ts. Seeking will be done so that the point from which all active streams can be presented successfully will be closest to ts and within min/max_ts. Active streams are all streams that have AVStream.discard < AVDISCARD_ALL.\n\nIf flags contain AVSEEK_FLAG_BYTE, then all timestamps are in bytes and are the file position (this may not be supported by all demuxers). If flags contain AVSEEK_FLAG_FRAME, then all timestamps are in frames in the stream with stream_index (this may not be supported by all demuxers). Otherwise all timestamps are in units of the stream selected by stream_index or if stream_index is -1, in AV_TIME_BASE units. If flags contain AVSEEK_FLAG_ANY, then non-keyframes are treated as keyframes (this may not be supported by all demuxers). If flags contain AVSEEK_FLAG_BACKWARD, it is ignored.\n\nnote: Note\nThis is part of the new seek API which is still under construction.\n\nArguments\n\ns: media file handle\nstream_index: index of the stream which is used as time base reference\nmin_ts: smallest acceptable timestamp\nts: target timestamp\nmax_ts: largest acceptable timestamp\nflags: flags\n\nReturns\n\n=0 on success, error code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_stream_group_add_stream-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_stream_group_add_stream","text":"avformat_stream_group_add_stream(stg, st)\n\nAdd an already allocated stream to a stream group.\n\nWhen demuxing, it may be called by the demuxer in read_header(). If the flag AVFMTCTX_NOHEADER is set in s.ctx_flags, then it may also be called in read_packet().\n\nWhen muxing, may be called by the user before avformat_write_header() after having allocated a new group with avformat_stream_group_create() and stream with avformat_new_stream().\n\nUser is required to call avformat_free_context() to clean up the allocation by avformat_stream_group_add_stream().\n\n\\retval0 success\n\n\\retvalAVERROR(EEXIST) the stream was already in the group\n\n\\retval\"another negative error code\" legitimate errors\n\nArguments\n\nstg: stream group belonging to a media file.\nst: stream in the media file to add to the group.\n\nSee also\n\navformat_new_stream, avformat_stream_group_create.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_stream_group_create-Tuple{Any, UInt32, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_stream_group_create","text":"avformat_stream_group_create(s, type::AVStreamGroupParamsType, options)\n\nAdd a new empty stream group to a media file.\n\nWhen demuxing, it may be called by the demuxer in read_header(). If the flag AVFMTCTX_NOHEADER is set in s.ctx_flags, then it may also be called in read_packet().\n\nWhen muxing, may be called by the user before avformat_write_header().\n\nUser is required to call avformat_free_context() to clean up the allocation by avformat_stream_group_create().\n\nNew streams can be added to the group with avformat_stream_group_add_stream().\n\nArguments\n\ns: media file handle\n\nReturns\n\nnewly created group or NULL on error.\n\nSee also\n\navformat_new_stream, avformat_stream_group_add_stream.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_stream_group_name-Tuple{UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_stream_group_name","text":"avformat_stream_group_name(type::AVStreamGroupParamsType)\n\nReturns\n\na string identifying the stream group type, or NULL if unknown\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_transfer_internal_stream_timing_info-Tuple{Any, Any, Any, Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_transfer_internal_stream_timing_info","text":"avformat_transfer_internal_stream_timing_info(ofmt, ost, ist, copy_tb::AVTimebaseSource)\n\ncompat: Deprecated\ndo not call this function\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_version-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_version","text":"avformat_version()\n\nReturn the LIBAVFORMAT_VERSION_INT constant.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avformat_write_header-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avformat_write_header","text":"avformat_write_header(s, options)\n\nAllocate the stream private data and write the stream header to an output media file.\n\n\\retvalAVSTREAMINITINWRITEHEADER On success, if the codec had not already been fully initialized in avformat_init_output().\n\n\\retvalAVSTREAMINITININITOUTPUT On success, if the codec had already been fully initialized in avformat_init_output().\n\n\\retvalAVERROR A negative AVERROR on failure.\n\nArguments\n\ns: Media file handle, must be allocated with avformat_alloc_context(). Its AVFormatContext.oformat \"oformat\" field must be set to the desired output format; Its AVFormatContext.pb \"pb\" field must be set to an already opened ::AVIOContext.\noptions: An ::AVDictionary filled with AVFormatContext and muxer-private options. On return this parameter will be destroyed and replaced with a dict containing options that were not found. May be NULL.\n\nSee also\n\nav_opt_find, av_dict_set, avio_open, av_oformat_next, avformat_init_output.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_accept-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_accept","text":"avio_accept(s, c)\n\nAccept and allocate a client context on a server context.\n\nArguments\n\ns: the server context\nc: the client context, must be unallocated\n\nReturns\n\n= 0 on success or a negative value corresponding to an AVERROR on failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_alloc_context-Tuple{Any, Integer, Integer, Vararg{Any, 4}}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_alloc_context","text":"avio_alloc_context(buffer, buffer_size::Integer, write_flag::Integer, opaque, read_packet, write_packet, seek)\n\nAllocate and initialize an AVIOContext for buffered I/O. It must be later freed with avio_context_free().\n\nArguments\n\nbuffer: Memory block for input/output operations via AVIOContext. The buffer must be allocated with av_malloc() and friends. It may be freed and replaced with a new buffer by libavformat. AVIOContext.buffer holds the buffer currently in use, which must be later freed with av_free().\nbuffer_size: The buffer size is very important for performance. For protocols with fixed blocksize it should be set to this blocksize. For others a typical size is a cache page, e.g. 4kb.\nwrite_flag: Set to 1 if the buffer should be writable, 0 otherwise.\nopaque: An opaque pointer to user-specific data.\nread_packet: A function for refilling the buffer, may be NULL. For stream protocols, must never return 0 but rather a proper AVERROR code.\nwrite_packet: A function for writing the buffer contents, may be NULL. The function may not change the input buffers content.\nseek: A function for seeking to specified byte position, may be NULL.\n\nReturns\n\nAllocated AVIOContext or NULL on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_check-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_check","text":"avio_check(url, flags::Integer)\n\nReturn AVIO_FLAG_* access flags corresponding to the access permissions of the resource in url, or a negative value corresponding to an AVERROR code in case of failure. The returned access flags are masked by the value in flags.\n\nnote: Note\nThis function is intrinsically unsafe, in the sense that the checked resource may change its existence or permission status from one call to another. Thus you should not trust the returned value, unless you are sure that no other processes are accessing the checked resource.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_close-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_close","text":"avio_close(s)\n\nClose the resource accessed by the AVIOContext s and free it. This function can only be used if s was opened by avio_open().\n\nThe internal buffer is automatically flushed before closing the resource.\n\nReturns\n\n0 on success, an AVERROR < 0 on error.\n\nSee also\n\navio_closep\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_close_dir-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_close_dir","text":"avio_close_dir(s)\n\nClose directory.\n\nnote: Note\nEntries created using avio_read_dir() are not deleted and must be freeded with avio_free_directory_entry().\n\nArguments\n\ns: directory read context.\n\nReturns\n\n=0 on success or negative on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_close_dyn_buf-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_close_dyn_buf","text":"avio_close_dyn_buf(s, pbuffer)\n\nReturn the written size and a pointer to the buffer. The buffer must be freed with av_free(). Padding of AV_INPUT_BUFFER_PADDING_SIZE is added to the buffer.\n\nArguments\n\ns: IO context\npbuffer: pointer to a byte buffer\n\nReturns\n\nthe length of the byte buffer\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_closep-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_closep","text":"avio_closep(s)\n\nClose the resource accessed by the AVIOContext *s, free it and set the pointer pointing to it to NULL. This function can only be used if s was opened by avio_open().\n\nThe internal buffer is automatically flushed before closing the resource.\n\nReturns\n\n0 on success, an AVERROR < 0 on error.\n\nSee also\n\navio_close\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_context_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_context_free","text":"avio_context_free(s)\n\nFree the supplied IO context and everything associated with it.\n\nArguments\n\ns: Double pointer to the IO context. This function will write NULL into s.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_enum_protocols-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_enum_protocols","text":"avio_enum_protocols(opaque, output::Integer)\n\nIterate through names of available protocols.\n\nArguments\n\nopaque: A private pointer representing current protocol. It must be a pointer to NULL on first iteration and will be updated by successive calls to avio_enum_protocols.\noutput: If set to 1, iterate over output protocols, otherwise over input protocols.\n\nReturns\n\nA static string containing the name of current protocol or NULL\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_feof-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_feof","text":"avio_feof(s)\n\nSimilar to feof() but also returns nonzero on read errors.\n\nReturns\n\nnon zero if and only if at end of file or a read error happened when reading.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_find_protocol_name-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_find_protocol_name","text":"avio_find_protocol_name(url)\n\nReturn the name of the protocol that will handle the passed URL.\n\nNULL is returned if no protocol could be found for the given URL.\n\nReturns\n\nName of the protocol or NULL.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_flush-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_flush","text":"avio_flush(s)\n\nForce flushing of buffered data.\n\nFor write streams, force the buffered data to be immediately written to the output, without to wait to fill the internal buffer.\n\nFor read streams, discard all currently buffered data, and advance the reported file position to that of the underlying stream. This does not read new data, and does not perform any seeks.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_free_directory_entry-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_free_directory_entry","text":"avio_free_directory_entry(entry)\n\nFree entry allocated by avio_read_dir().\n\nArguments\n\nentry: entry to be freed.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_get_dyn_buf-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_get_dyn_buf","text":"avio_get_dyn_buf(s, pbuffer)\n\nReturn the written size and a pointer to the buffer. The AVIOContext stream is left intact. The buffer must NOT be freed. No padding is added to the buffer.\n\nArguments\n\ns: IO context\npbuffer: pointer to a byte buffer\n\nReturns\n\nthe length of the byte buffer\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_get_str-Tuple{Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_get_str","text":"avio_get_str(pb, maxlen::Integer, buf, buflen::Integer)\n\nRead a string from pb into buf. The reading will terminate when either a NULL character was encountered, maxlen bytes have been read, or nothing more can be read from pb. The result is guaranteed to be NULL-terminated, it will be truncated if buf is too small. Note that the string is not interpreted or validated in any way, it might get truncated in the middle of a sequence for multi-byte encodings.\n\nReturns\n\nnumber of bytes read (is always <= maxlen). If reading ends on EOF or error, the return value will be one more than bytes actually read.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_get_str16le-Tuple{Any, Integer, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_get_str16le","text":"avio_get_str16le(pb, maxlen::Integer, buf, buflen::Integer)\n\nRead a UTF-16 string from pb and convert it to UTF-8. The reading will terminate when either a null or invalid character was encountered or maxlen bytes have been read.\n\nReturns\n\nnumber of bytes read (is always <= maxlen)\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_handshake-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_handshake","text":"avio_handshake(c)\n\nPerform one step of the protocol handshake to accept a new client. This function must be called on a client returned by avio_accept() before using it as a read/write context. It is separate from avio_accept() because it may block. A step of the handshake is defined by places where the application may decide to change the proceedings. For example, on a protocol with a request header and a reply header, each one can constitute a step because the application may use the parameters from the request to change parameters in the reply; or each individual chunk of the request can constitute a step. If the handshake is already finished, avio_handshake() does nothing and returns 0 immediately.\n\nArguments\n\nc: the client context to perform the handshake on\n\nReturns\n\n0 on a complete and successful handshake > 0 if the handshake progressed, but is not complete < 0 for an AVERROR code\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_open-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_open","text":"avio_open(s, url, flags::Integer)\n\nCreate and initialize a AVIOContext for accessing the resource indicated by url.\n\nnote: Note\nWhen the resource indicated by url has been opened in read+write mode, the AVIOContext can be used only for writing.\n\nArguments\n\ns: Used to return the pointer to the created AVIOContext. In case of failure the pointed to value is set to NULL.\nurl: resource to access\nflags: flags which control how the resource indicated by url is to be opened\n\nReturns\n\n= 0 in case of success, a negative value corresponding to an AVERROR code in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_open2-Tuple{Any, Any, Integer, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_open2","text":"avio_open2(s, url, flags::Integer, int_cb, options)\n\nCreate and initialize a AVIOContext for accessing the resource indicated by url.\n\nnote: Note\nWhen the resource indicated by url has been opened in read+write mode, the AVIOContext can be used only for writing.\n\nArguments\n\ns: Used to return the pointer to the created AVIOContext. In case of failure the pointed to value is set to NULL.\nurl: resource to access\nflags: flags which control how the resource indicated by url is to be opened\nint_cb: an interrupt callback to be used at the protocols level\noptions: A dictionary filled with protocol-private options. On return this parameter will be destroyed and replaced with a dict containing options that were not found. May be NULL.\n\nReturns\n\n= 0 in case of success, a negative value corresponding to an AVERROR code in case of failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_open_dir-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_open_dir","text":"avio_open_dir(s, url, options)\n\nOpen directory for reading.\n\nArguments\n\ns: directory read context. Pointer to a NULL pointer must be passed.\nurl: directory to be listed.\noptions: A dictionary filled with protocol-private options. On return this parameter will be destroyed and replaced with a dictionary containing options that were not found. May be NULL.\n\nReturns\n\n=0 on success or negative on error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_open_dyn_buf-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_open_dyn_buf","text":"avio_open_dyn_buf(s)\n\nOpen a write only memory stream.\n\nArguments\n\ns: new IO context\n\nReturns\n\nzero if no error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_pause-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_pause","text":"avio_pause(h, pause::Integer)\n\nPause and resume playing - only meaningful if using a network streaming protocol (e.g. MMS).\n\nArguments\n\nh: IO context from which to call the read_pause function pointer\npause: 1 for pause, 0 for resume\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_print_string_array-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_print_string_array","text":"avio_print_string_array(s, strings)\n\nWrite a NULL terminated array of strings to the context. Usually you don't need to use this function directly but its macro wrapper, avio_print.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_protocol_get_class-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_protocol_get_class","text":"avio_protocol_get_class(name)\n\nGet AVClass by names of available protocols.\n\nReturns\n\nA AVClass of input protocol name or NULL\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_put_str-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_put_str","text":"avio_put_str(s, str)\n\nWrite a NULL-terminated string.\n\nReturns\n\nnumber of bytes written.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_put_str16be-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_put_str16be","text":"avio_put_str16be(s, str)\n\nConvert an UTF-8 string to UTF-16BE and write it.\n\nArguments\n\ns: the AVIOContext\nstr: NULL-terminated UTF-8 string\n\nReturns\n\nnumber of bytes written.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_put_str16le-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_put_str16le","text":"avio_put_str16le(s, str)\n\nConvert an UTF-8 string to UTF-16LE and write it.\n\nArguments\n\ns: the AVIOContext\nstr: NULL-terminated UTF-8 string\n\nReturns\n\nnumber of bytes written.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_r8-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_r8","text":"avio_r8(s)\n\nFunctions for reading from AVIOContext\n\n@{\n\nnote: Note\nreturn 0 if EOF, so you cannot use it if EOF handling is necessary\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_read-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_read","text":"avio_read(s, buf, size::Integer)\n\nRead size bytes from AVIOContext into buf.\n\nReturns\n\nnumber of bytes read or AVERROR\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_read_dir-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_read_dir","text":"avio_read_dir(s, next)\n\nGet next directory entry.\n\nReturned entry must be freed with avio_free_directory_entry(). In particular it may outlive AVIODirContext.\n\nArguments\n\ns: directory read context.\nnext:[out] next entry or NULL when no more entries.\n\nReturns\n\n=0 on success or negative on error. End of list is not considered an error.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_read_partial-Tuple{Any, Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_read_partial","text":"avio_read_partial(s, buf, size::Integer)\n\nRead size bytes from AVIOContext into buf. Unlike avio_read(), this is allowed to read fewer bytes than requested. The missing bytes can be read in the next call. This always tries to read at least 1 byte. Useful to reduce latency in certain cases.\n\nReturns\n\nnumber of bytes read or AVERROR\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_read_to_bprint-Tuple{Any, Any, UInt64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_read_to_bprint","text":"avio_read_to_bprint(h, pb, max_size::Csize_t)\n\nRead contents of h into print buffer, up to max_size bytes, or up to EOF.\n\nReturns\n\n0 for success (max_size bytes read or EOF reached), negative error code otherwise\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_seek-Tuple{Any, Int64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_seek","text":"avio_seek(s, offset::Int64, whence::Integer)\n\nfseek() equivalent for AVIOContext.\n\nReturns\n\nnew position or AVERROR.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_seek_time-Tuple{Any, Integer, Int64, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_seek_time","text":"avio_seek_time(h, stream_index::Integer, timestamp::Int64, flags::Integer)\n\nSeek to a given timestamp relative to some component stream. Only meaningful if using a network streaming protocol (e.g. MMS.).\n\nArguments\n\nh: IO context from which to call the seek function pointers\nstream_index: The stream index that the timestamp is relative to. If stream_index is (-1) the timestamp should be in AV_TIME_BASE units from the beginning of the presentation. If a stream_index >= 0 is used and the protocol does not support seeking based on component streams, the call will fail.\ntimestamp: timestamp in AVStream.time_base units or if there is no stream specified then in AV_TIME_BASE units.\nflags: Optional combination of AVSEEK_FLAG_BACKWARD, AVSEEK_FLAG_BYTE and AVSEEK_FLAG_ANY. The protocol may silently ignore AVSEEK_FLAG_BACKWARD and AVSEEK_FLAG_ANY, but AVSEEK_FLAG_BYTE will fail if used and not supported.\n\nReturns\n\n= 0 on success\n\nSee also\n\nAVInputFormat::read_seek\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_size-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_size","text":"avio_size(s)\n\nGet the filesize.\n\nReturns\n\nfilesize or AVERROR\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_skip-Tuple{Any, Int64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_skip","text":"avio_skip(s, offset::Int64)\n\nSkip given number of bytes forward\n\nReturns\n\nnew position or AVERROR.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_tell-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_tell","text":"avio_tell(s)\n\nftell() equivalent for AVIOContext.\n\nReturns\n\nposition or AVERROR.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avio_write_marker-Tuple{Any, Int64, UInt32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avio_write_marker","text":"avio_write_marker(s, time::Int64, type::AVIODataMarkerType)\n\nMark the written bytestream as a specific type.\n\nZero-length ranges are omitted from the output.\n\nArguments\n\ns: the AVIOContext\ntime: the stream time the current bytestream pos corresponds to (in AV_TIME_BASE units), or AV_NOPTS_VALUE if unknown or not applicable\ntype: the kind of data written starting at the current pos\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avsubtitle_free-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avsubtitle_free","text":"avsubtitle_free(sub)\n\nFree all allocated data in the given subtitle struct.\n\nArguments\n\nsub: AVSubtitle to free.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avutil_configuration-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avutil_configuration","text":"avutil_configuration()\n\nReturn the libavutil build-time configuration.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avutil_license-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avutil_license","text":"avutil_license()\n\nReturn the libavutil license.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avutil_version-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avutil_version","text":"avutil_version()\n\nReturn the LIBAVUTIL_VERSION_INT constant.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_allocVec-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_allocVec","text":"sws_allocVec(length::Integer)\n\nAllocate and return an uninitialized vector with length coefficients.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_alloc_context-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_alloc_context","text":"sws_alloc_context()\n\nAllocate an empty SwsContext and set its fields to default values.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_convertPalette8ToPacked24-Tuple{Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_convertPalette8ToPacked24","text":"sws_convertPalette8ToPacked24(src, dst, num_pixels::Integer, palette)\n\nConvert an 8-bit paletted frame into a frame with a color depth of 24 bits.\n\nWith the palette format \"ABCD\", the destination frame ends up with the format \"ABC\".\n\nArguments\n\nsrc: source frame buffer\ndst: destination frame buffer\nnum_pixels: number of pixels to convert\npalette: array with [256] entries, which must match color arrangement (RGB or BGR) of src\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_convertPalette8ToPacked32-Tuple{Any, Any, Integer, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_convertPalette8ToPacked32","text":"sws_convertPalette8ToPacked32(src, dst, num_pixels::Integer, palette)\n\nConvert an 8-bit paletted frame into a frame with a color depth of 32 bits.\n\nThe output frame will have the same packed format as the palette.\n\nArguments\n\nsrc: source frame buffer\ndst: destination frame buffer\nnum_pixels: number of pixels to convert\npalette: array with [256] entries, which must match color arrangement (RGB or BGR) of src\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_frame_end-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_frame_end","text":"sws_frame_end(c)\n\nFinish the scaling process for a pair of source/destination frames previously submitted with sws_frame_start(). Must be called after all sws_send_slice() and sws_receive_slice() calls are done, before any new sws_frame_start() calls.\n\nArguments\n\nc: The scaling context\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_frame_setup-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_frame_setup","text":"sws_frame_setup(ctx, dst, src)\n\nLike sws_scale_frame, but without actually scaling. It will instead merely initialize internal state that would be required to perform the operation, as well as returning the correct error code for unsupported frame combinations.\n\nArguments\n\nctx: The scaling context.\ndst: The destination frame to consider.\nsrc: The source frame to consider.\n\nReturns\n\n0 on success, a negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_frame_start-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_frame_start","text":"sws_frame_start(c, dst, src)\n\nInitialize the scaling process for a given pair of source/destination frames. Must be called before any calls to sws_send_slice() and sws_receive_slice(). Requires a context that has been previously been initialized with sws_init_context().\n\nThis function will retain references to src and dst, so they must both use refcounted buffers (if allocated by the caller, in case of dst).\n\nThe data buffers may either be already allocated by the caller or left clear, in which case they will be allocated by the scaler. The latter may have performance advantages - e.g. in certain cases some output planes may be references to input planes, rather than copies.\n\nOutput data will be written into this frame in successful sws_receive_slice() calls.\n\nArguments\n\nc: The scaling context\ndst: The destination frame.\nsrc: The source frame. The data buffers must be allocated, but the frame data does not have to be ready at this point. Data availability is then signalled by sws_send_slice().\n\nReturns\n\n0 on success, a negative AVERROR code on failure\n\nSee also\n\nsws_frame_end()\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_freeContext-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_freeContext","text":"sws_freeContext(swsContext)\n\nFree the swscaler context swsContext. If swsContext is NULL, then does nothing.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_free_context-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_free_context","text":"sws_free_context(ctx)\n\nFree the context and everything associated with it, and write NULL to the provided pointer.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_getCachedContext-Tuple{Any, Integer, Integer, Int32, Integer, Integer, Int32, Integer, Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_getCachedContext","text":"sws_getCachedContext(context, srcW::Integer, srcH::Integer, srcFormat::AVPixelFormat, dstW::Integer, dstH::Integer, dstFormat::AVPixelFormat, flags::Integer, srcFilter, dstFilter, param)\n\nCheck if context can be reused, otherwise reallocate a new one.\n\nIf context is NULL, just calls sws_getContext() to get a new context. Otherwise, checks if the parameters are the ones already saved in context. If that is the case, returns the current context. Otherwise, frees context and gets a new context with the new parameters.\n\nBe warned that srcFilter and dstFilter are not checked, they are assumed to remain the same.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_getCoefficients-Tuple{Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_getCoefficients","text":"sws_getCoefficients(colorspace::Integer)\n\nReturn a pointer to yuv<->rgb coefficients for the given colorspace suitable for sws_setColorspaceDetails().\n\nArguments\n\ncolorspace: One of the SWS_CS_* macros. If invalid, SWS_CS_DEFAULT is used.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_getColorspaceDetails-NTuple{8, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_getColorspaceDetails","text":"sws_getColorspaceDetails(c, inv_table, srcRange, table, dstRange, brightness, contrast, saturation)\n\nReturns\n\nA negative error code on error, non negative otherwise. If [LIBSWSCALEVERSIONMAJOR](@ref) < 7, returns -1 if not supported.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_getContext-Tuple{Integer, Integer, Int32, Integer, Integer, Int32, Integer, Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_getContext","text":"sws_getContext(srcW::Integer, srcH::Integer, srcFormat::AVPixelFormat, dstW::Integer, dstH::Integer, dstFormat::AVPixelFormat, flags::Integer, srcFilter, dstFilter, param)\n\nAllocate and return an SwsContext. You need it to perform scaling/conversion operations using sws_scale().\n\nnote: Note\nthis function is to be removed after a saner alternative is written\n\nArguments\n\nsrcW: the width of the source image\nsrcH: the height of the source image\nsrcFormat: the source image format\ndstW: the width of the destination image\ndstH: the height of the destination image\ndstFormat: the destination image format\nflags: specify which algorithm and options to use for rescaling\nparam: extra parameters to tune the used scaler For SWS_BICUBIC param[0] and [1] tune the shape of the basis function, param[0] tunes f(1) and param[1] f´(1) For SWS_GAUSS param[0] tunes the exponent and thus cutoff frequency For SWS_LANCZOS param[0] tunes the width of the window function\n\nReturns\n\na pointer to an allocated context, or NULL in case of error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_getGaussianVec-Tuple{Float64, Float64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_getGaussianVec","text":"sws_getGaussianVec(variance::Cdouble, quality::Cdouble)\n\nReturn a normalized Gaussian curve used to filter stuff quality = 3 is high quality, lower is lower quality.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_get_class-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_get_class","text":"sws_get_class()\n\nGet the AVClass for SwsContext. It can be used in combination with AV_OPT_SEARCH_FAKE_OBJ for examining options.\n\nSee also\n\nav_opt_find().\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_init_context-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_init_context","text":"sws_init_context(sws_context, srcFilter, dstFilter)\n\nInitialize the swscaler context sws_context.\n\nThis function is considered deprecated, and provided only for backwards compatibility with sws_scale() and sws_start_frame(). The preferred way to use libswscale is to set all frame properties correctly and call sws_scale_frame() directly, without explicitly initializing the context.\n\nReturns\n\nzero or positive value on success, a negative value on error\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_isSupportedEndiannessConversion-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_isSupportedEndiannessConversion","text":"sws_isSupportedEndiannessConversion(pix_fmt::AVPixelFormat)\n\nArguments\n\npix_fmt:[in] the pixel format\n\nReturns\n\na positive value if an endianness conversion for pix_fmt is supported, 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_isSupportedInput-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_isSupportedInput","text":"sws_isSupportedInput(pix_fmt::AVPixelFormat)\n\nReturn a positive value if pix_fmt is a supported input format, 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_isSupportedOutput-Tuple{Int32}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_isSupportedOutput","text":"sws_isSupportedOutput(pix_fmt::AVPixelFormat)\n\nReturn a positive value if pix_fmt is a supported output format, 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_is_noop-Tuple{Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_is_noop","text":"sws_is_noop(dst, src)\n\nCheck if a given conversion is a noop. Returns a positive integer if no operation needs to be performed, 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_normalizeVec-Tuple{Any, Float64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_normalizeVec","text":"sws_normalizeVec(a, height::Cdouble)\n\nScale all the coefficients of a so that their sum equals height.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_receive_slice-Tuple{Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_receive_slice","text":"sws_receive_slice(c, slice_start::Integer, slice_height::Integer)\n\nRequest a horizontal slice of the output data to be written into the frame previously provided to sws_frame_start().\n\nArguments\n\nc: The scaling context\nslice_start: first row of the slice; must be a multiple of sws_receive_slice_alignment()\nslice_height: number of rows in the slice; must be a multiple of sws_receive_slice_alignment(), except for the last slice (i.e. when slice_start+slice_height is equal to output frame height)\n\nReturns\n\na non-negative number if the data was successfully written into the output AVERROR(EAGAIN) if more input data needs to be provided before the output can be produced another negative AVERROR code on other kinds of scaling failure\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_receive_slice_alignment-Tuple{Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_receive_slice_alignment","text":"sws_receive_slice_alignment(c)\n\nGet the alignment required for slices. Requires a context that has been previously been initialized with sws_init_context().\n\nArguments\n\nc: The scaling context\n\nReturns\n\nalignment required for output slices requested with sws_receive_slice(). Slice offsets and sizes passed to sws_receive_slice() must be multiples of the value returned from this function.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_scale-Tuple{Any, Any, Any, Integer, Integer, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_scale","text":"sws_scale(c, srcSlice, srcStride, srcSliceY::Integer, srcSliceH::Integer, dst, dstStride)\n\nScale the image slice in srcSlice and put the resulting scaled slice in the image in dst. A slice is a sequence of consecutive rows in an image. Requires a context that has been previously been initialized with sws_init_context().\n\nSlices have to be provided in sequential order, either in top-bottom or bottom-top order. If slices are provided in non-sequential order the behavior of the function is undefined.\n\nArguments\n\nc: the scaling context previously created with sws_getContext()\nsrcSlice: the array containing the pointers to the planes of the source slice\nsrcStride: the array containing the strides for each plane of the source image\nsrcSliceY: the position in the source image of the slice to process, that is the number (counted starting from zero) in the image of the first row of the slice\nsrcSliceH: the height of the source slice, that is the number of rows in the slice\ndst: the array containing the pointers to the planes of the destination image\ndstStride: the array containing the strides for each plane of the destination image\n\nReturns\n\nthe height of the output slice\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_scaleVec-Tuple{Any, Float64}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_scaleVec","text":"sws_scaleVec(a, scalar::Cdouble)\n\nScale all the coefficients of a by the scalar value.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_scale_frame-Tuple{Any, Any, Any}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_scale_frame","text":"sws_scale_frame(c, dst, src)\n\nScale source data from src and write the output to dst.\n\nThis function can be used directly on an allocated context, without setting up any frame properties or calling [swsinitcontext](@ref)(). Such usage is fully dynamic and does not require reallocation if the frame properties change.\n\nAlternatively, this function can be called on a context that has been explicitly initialized. However, this is provided only for backwards compatibility. In this usage mode, all frame properties must be correctly set at init time, and may no longer change after initialization.\n\nArguments\n\nctx: The scaling context.\ndst: The destination frame. The data buffers may either be already allocated by the caller or left clear, in which case they will be allocated by the scaler. The latter may have performance advantages - e.g. in certain cases some (or all) output planes may be references to input planes, rather than copies.\nsrc: The source frame. If the data buffers are set to NULL, then this function behaves identically to sws_frame_setup.\n\nReturns\n\n= 0 on success, a negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_send_slice-Tuple{Any, Integer, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_send_slice","text":"sws_send_slice(c, slice_start::Integer, slice_height::Integer)\n\nIndicate that a horizontal slice of input data is available in the source frame previously provided to sws_frame_start(). The slices may be provided in any order, but may not overlap. For vertically subsampled pixel formats, the slices must be aligned according to subsampling.\n\nArguments\n\nc: The scaling context\nslice_start: first row of the slice\nslice_height: number of rows in the slice\n\nReturns\n\na non-negative number on success, a negative AVERROR code on failure.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_setColorspaceDetails-Tuple{Any, Any, Integer, Any, Vararg{Integer, 4}}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_setColorspaceDetails","text":"sws_setColorspaceDetails(c, inv_table, srcRange::Integer, table, dstRange::Integer, brightness::Integer, contrast::Integer, saturation::Integer)\n\nArguments\n\nc: the scaling context\ndstRange: flag indicating the while-black range of the output (1=jpeg / 0=mpeg)\nsrcRange: flag indicating the while-black range of the input (1=jpeg / 0=mpeg)\ntable: the yuv2rgb coefficients describing the output yuv space, normally ff_yuv2rgb_coeffs[x]\ninv_table: the yuv2rgb coefficients describing the input yuv space, normally ff_yuv2rgb_coeffs[x]\nbrightness: 16.16 fixed point brightness correction\ncontrast: 16.16 fixed point contrast correction\nsaturation: 16.16 fixed point saturation correction\n\nReturns\n\nA negative error code on error, non negative otherwise. If [LIBSWSCALEVERSIONMAJOR](@ref) < 7, returns -1 if not supported.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_test_colorspace-Tuple{UInt32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_test_colorspace","text":"sws_test_colorspace(colorspace::AVColorSpace, output::Integer)\n\nTest if a given color space is supported.\n\nArguments\n\noutput: If 0, test if compatible with the source/input frame; otherwise, with the destination/output frame.\ncolorspace: The colorspace to check.\n\nReturns\n\nA positive integer if supported, 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_test_format-Tuple{Int32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_test_format","text":"sws_test_format(format::AVPixelFormat, output::Integer)\n\nTest if a given pixel format is supported.\n\nArguments\n\noutput: If 0, test if compatible with the source/input frame; otherwise, with the destination/output frame.\nformat: The format to check.\n\nReturns\n\nA positive integer if supported, 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_test_frame-Tuple{Any, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_test_frame","text":"sws_test_frame(frame, output::Integer)\n\nHelper function to run all sws_test_* against a frame, as well as testing the basic frame properties for sanity. Ignores irrelevant properties - for example, AVColorSpace is not checked for RGB frames.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_test_primaries-Tuple{UInt32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_test_primaries","text":"sws_test_primaries(primaries::AVColorPrimaries, output::Integer)\n\nTest if a given set of color primaries is supported.\n\nArguments\n\noutput: If 0, test if compatible with the source/input frame; otherwise, with the destination/output frame.\nprimaries: The color primaries to check.\n\nReturns\n\nA positive integer if supported, 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.sws_test_transfer-Tuple{UInt32, Integer}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.sws_test_transfer","text":"sws_test_transfer(trc::AVColorTransferCharacteristic, output::Integer)\n\nTest if a given color transfer function is supported.\n\nArguments\n\noutput: If 0, test if compatible with the source/input frame; otherwise, with the destination/output frame.\ntrc: The color transfer function to check.\n\nReturns\n\nA positive integer if supported, 0 otherwise.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.swscale_configuration-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.swscale_configuration","text":"swscale_configuration()\n\nReturn the libswscale build-time configuration.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.swscale_license-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.swscale_license","text":"swscale_license()\n\nReturn the libswscale license.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.swscale_version-Tuple{}","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.swscale_version","text":"swscale_version()\n\nlibsws libswscale\n\nColor conversion and scaling library.\n\n@{\n\nReturn the LIBSWSCALE_VERSION_INT constant.\n\n\n\n\n\n","category":"method"},{"location":"ffmpeg_reference/#Types","page":"FFmpeg Reference","title":"Types","text":"","category":"section"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AV3DReferenceDisplay","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AV3DReferenceDisplay","text":"AV3DReferenceDisplay\n\nData structure for single deference display information. It is allocated as a part of AV3DReferenceDisplaysInfo and should be retrieved with av_tdrdi_get_display().\n\nsizeof(AV3DReferenceDisplay) is not a part of the ABI and new fields may be added to it.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AV3DReferenceDisplaysInfo","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AV3DReferenceDisplaysInfo","text":"AV3DReferenceDisplaysInfo\n\nThis structure describes information about the reference display width(s) and reference viewing distance(s) as well as information about the corresponding reference stereo pair(s). See section G.14.3.2.3 of ITU-T H.265 for more information.\n\nnote: Note\nThe struct must be allocated with av_tdrdi_alloc() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVAdler","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVAdler","text":"lavu_adler32 Adler-32\n\nlavu_hash\n\nAdler-32 hash function implementation.\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVAmbientViewingEnvironment","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVAmbientViewingEnvironment","text":"AVAmbientViewingEnvironment\n\nAmbient viewing environment metadata as defined by H.274. The values are saved in AVRationals so that they keep their exactness, while allowing for easy access to a double value with f.ex. av_q2d.\n\nnote: Note\nsizeof(AVAmbientViewingEnvironment) is not part of the public ABI, and it must be allocated using av_ambient_viewing_environment_alloc.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVAppToDevMessageType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVAppToDevMessageType","text":"AVAppToDevMessageType\n\nMessage types used by avdevice_app_to_dev_control_message().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVBPrint","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVBPrint","text":"AVBPrint\n\nBuffer to print data progressively\n\nThe string buffer grows as necessary and is always 0-terminated. The content of the string is never accessed, and thus is encoding-agnostic and can even hold binary data.\n\nSmall buffers are kept in the structure itself, and thus require no memory allocation at all (unless the contents of the buffer is needed after the structure goes out of scope). This is almost as lightweight as declaring a local char buf[512].\n\nThe length of the string can go beyond the allocated size: the buffer is then truncated, but the functions still keep account of the actual total length.\n\nIn other words, AVBPrint.len can be greater than AVBPrint.size and records the total length of what would have been to the buffer if there had been enough memory.\n\nAppend operations do not need to be tested for failure: if a memory allocation fails, data stop being appended to the buffer, but the length is still updated. This situation can be tested with av_bprint_is_complete().\n\nThe AVBPrint.size_max field determines several possible behaviours: - size\\_max = -1 (= UINT_MAX) or any large value will let the buffer be reallocated as necessary, with an amortized linear cost. - size\\_max = 0 prevents writing anything to the buffer: only the total length is computed. The write operations can then possibly be repeated in a buffer with exactly the necessary size (using size\\_init = size\\_max = len + 1). - size\\_max = 1 is automatically replaced by the exact size available in the structure itself, thus ensuring no dynamic memory allocation. The internal buffer is large enough to hold a reasonable paragraph of text, such as the current paragraph.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVBSFContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVBSFContext","text":"AVBSFContext\n\nThe bitstream filter state.\n\nThis struct must be allocated with av_bsf_alloc() and freed with av_bsf_free().\n\nThe fields in the struct will only be changed (by the caller or by the filter) as described in their documentation, and are to be considered immutable otherwise.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVBufferRef","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVBufferRef","text":"AVBufferRef\n\nA reference to a data buffer.\n\nThe size of this struct is not a part of the public ABI and it is not meant to be allocated directly.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVBufferSrcParameters","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVBufferSrcParameters","text":"AVBufferSrcParameters\n\nThis structure contains the parameters describing the frames that will be passed to this filter.\n\nIt should be allocated with av_buffersrc_parameters_alloc() and freed with av_free(). All the allocated fields in it remain owned by the caller.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVCIExy","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVCIExy","text":"AVCIExy\n\nStruct containing chromaticity x and y values for the standard CIE 1931 chromaticity definition.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVCPBProperties","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVCPBProperties","text":"AVCPBProperties\n\nThis structure describes the bitrate properties of an encoded bitstream. It roughly corresponds to a subset the VBV parameters for MPEG-2 or HRD parameters for H.264/HEVC.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVCRC","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVCRC","text":"lavu_crc32 CRC\n\nlavu_hash\n\nCRC (Cyclic Redundancy Check) hash function implementation.\n\nThis module supports numerous CRC polynomials, in addition to the most widely used CRC-32-IEEE. See AVCRCId for a list of available polynomials.\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVChannel","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVChannel","text":"AVChannel\n\nlavu_audio_channels Audio channels\n\nlavu_audio\n\nAudio channel layout utility functions\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVChannelCustom","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVChannelCustom","text":"AVChannelCustom\n\nAn AVChannelCustom defines a single channel within a custom order layout\n\nUnlike most structures in FFmpeg, sizeof(AVChannelCustom) is a part of the public ABI.\n\nNo new fields may be added to it without a major version bump.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVChannelLayout","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVChannelLayout","text":"AVChannelLayout\n\nAn AVChannelLayout holds information about the channel layout of audio data.\n\nA channel layout here is defined as a set of channels ordered in a specific way (unless the channel order is AV_CHANNEL_ORDER_UNSPEC, in which case an AVChannelLayout carries only the channel count). All orders may be treated as if they were AV_CHANNEL_ORDER_UNSPEC by ignoring everything but the channel count, as long as av_channel_layout_check() considers they are valid.\n\nUnlike most structures in FFmpeg, sizeof(AVChannelLayout) is a part of the public ABI and may be used by the caller. E.g. it may be allocated on stack or embedded in caller-defined structs.\n\nAVChannelLayout can be initialized as follows: - default initialization with {0}, followed by setting all used fields correctly; - by assigning one of the predefined AV_CHANNEL_LAYOUT_* initializers; - with a constructor function, such as av_channel_layout_default(), av_channel_layout_from_mask() or av_channel_layout_from_string().\n\nThe channel layout must be uninitialized with av_channel_layout_uninit()\n\nCopying an AVChannelLayout via assigning is forbidden, av_channel_layout_copy() must be used instead (and its return value should be checked)\n\nNo new fields may be added to it without a major version bump, except for new elements of the union fitting in sizeof(uint64_t).\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVChromaLocation","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVChromaLocation","text":"AVChromaLocation\n\nLocation of chroma samples.\n\nIllustration showing the location of the first (top left) chroma sample of the image, the left shows only luma, the right shows the location of the chroma sample, the 2 could be imagined to overlay each other but are drawn separately due to limitations of ASCII\n\n1st 2nd 1st 2nd horizontal luma sample positions v v v v ______ ______1st luma line > |X X ... |3 4 X ... X are luma samples, | |1 2 1-6 are possible chroma positions2nd luma line > |X X ... |5 6 X ... 0 is undefined/unknown position\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVClass","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVClass","text":"AVClass\n\nDescribe the class of an AVClass context structure. That is an arbitrary struct of which the first field is a pointer to an AVClass struct (e.g. AVCodecContext, AVFormatContext etc.).\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVCodec","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVCodec","text":"AVCodec\n\nAVCodec.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVCodecContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVCodecContext","text":"AVCodecContext\n\nmain external API structure. New fields can be added to the end with minor version bumps. Removal, reordering and changes to existing fields require a major version bump. You can use AVOptions (av_opt* / av_set/get()) to access these fields from user applications. The name string for AVOptions options matches the associated command line parameter name and can be found in libavcodec/options_table.h The AVOption/command line parameter names differ in some cases from the C structure field names for historic reasons or brevity. sizeof(AVCodecContext) must not be used outside libav.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVCodecDescriptor","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVCodecDescriptor","text":"AVCodecDescriptor\n\nThis struct describes the properties of a single codec described by an AVCodecID.\n\nSee also\n\navcodec_descriptor_get()\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVCodecID","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVCodecID","text":"AVCodecID\n\nIdentify the syntax and semantics of the bitstream. The principle is roughly: Two decoders with the same ID can decode the same streams. Two encoders with the same ID can encode compatible streams. There may be slight deviations from the principle due to implementation details.\n\nIf you add a codec ID to this list, add it so that 1. no value of an existing codec ID changes (that would break ABI), 2. it is as close as possible to similar codecs\n\nAfter adding new codec IDs, do not forget to add an entry to the codec descriptor list and bump libavcodec minor version.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVCodecParameters","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVCodecParameters","text":"AVCodecParameters\n\nThis struct describes the properties of an encoded stream.\n\nsizeof(AVCodecParameters) is not a part of the public ABI, this struct must be allocated with avcodec_parameters_alloc() and freed with avcodec_parameters_free().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVCodecTag","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVCodecTag","text":"\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVColorPrimaries","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVColorPrimaries","text":"AVColorPrimaries\n\nChromaticity coordinates of the source primaries. These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.1 and ITU-T H.273.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVColorPrimariesDesc","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVColorPrimariesDesc","text":"AVColorPrimariesDesc\n\nStruct that contains both white point location and primaries location, providing the complete description of a color gamut.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVColorRange","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVColorRange","text":"AVColorRange\n\nVisual content value range.\n\nThese values are based on definitions that can be found in multiple specifications, such as ITU-T BT.709 (3.4 - Quantization of RGB, luminance and colour-difference signals), ITU-T BT.2020 (Table 5 - Digital Representation) as well as ITU-T BT.2100 (Table 9 - Digital 10- and 12-bit integer representation). At the time of writing, the BT.2100 one is recommended, as it also defines the full range representation.\n\nCommon definitions: - For RGB and luma planes such as Y in YCbCr and I in ICtCp, 'E' is the original value in range of 0.0 to 1.0. - For chroma planes such as Cb,Cr and Ct,Cp, 'E' is the original value in range of -0.5 to 0.5. - 'n' is the output bit depth. - For additional definitions such as rounding and clipping to valid n bit unsigned integer range, please refer to BT.2100 (Table 9).\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVColorSpace","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVColorSpace","text":"AVColorSpace\n\nYUV colorspace type. These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.3.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVColorTransferCharacteristic","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVColorTransferCharacteristic","text":"AVColorTransferCharacteristic\n\nColor Transfer Characteristic. These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.2.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVContentLightMetadata","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVContentLightMetadata","text":"AVContentLightMetadata\n\nContent light level needed by to transmit HDR over HDMI (CTA-861.3).\n\nTo be used as payload of a AVFrameSideData or AVPacketSideData with the appropriate type.\n\nnote: Note\nThe struct should be allocated with av_content_light_metadata_alloc() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDCT","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDCT","text":"AVDCT\n\nAVDCT context.\n\nnote: Note\nfunction pointers can be NULL if the specific features have been disabled at build time.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDES","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDES","text":"AVDES\n\nlavu_des DES\n\nlavu_crypto\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDOVIColorMetadata","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDOVIColorMetadata","text":"AVDOVIColorMetadata\n\nDolby Vision RPU colorspace metadata parameters.\n\nnote: Note\nsizeof(AVDOVIColorMetadata) is not part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDOVIDataMapping","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDOVIDataMapping","text":"AVDOVIDataMapping\n\nDolby Vision RPU data mapping parameters.\n\nnote: Note\nsizeof(AVDOVIDataMapping) is not part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDOVIDmData","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDOVIDmData","text":"AVDOVIDmData\n\nDolby Vision metadata extension block. Dynamic extension blocks may change from frame to frame, while static blocks are constant throughout the entire sequence.\n\nnote: Note\nsizeof(AVDOVIDmData) is not part of the public API.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDOVIMetadata","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDOVIMetadata","text":"AVDOVIMetadata\n\nCombined struct representing a combination of header, mapping and color metadata, for attaching to frames as side data.\n\nnote: Note\nThe struct must be allocated with av_dovi_metadata_alloc() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDOVINLQParams","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDOVINLQParams","text":"AVDOVINLQParams\n\nCoefficients of the non-linear inverse quantization. For the interpretation of these, see ETSI GS CCM 001.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDOVIRpuDataHeader","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDOVIRpuDataHeader","text":"AVDOVIRpuDataHeader\n\nDolby Vision RPU data header.\n\nnote: Note\nsizeof(AVDOVIRpuDataHeader) is not part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDRMDeviceContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDRMDeviceContext","text":"AVDRMDeviceContext\n\nDRM device.\n\nAllocated as AVHWDeviceContext.hwctx.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDRMFrameDescriptor","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDRMFrameDescriptor","text":"AVDRMFrameDescriptor\n\nDRM frame descriptor.\n\nThis is used as the data pointer for AV_PIX_FMT_DRM_PRIME frames. It is also used by user-allocated frame pools - allocating in AVHWFramesContext.pool must return AVBufferRefs which contain an object of this type.\n\nThe fields of this structure should be set such it can be imported directly by EGL using the EGL_EXT_image_dma_buf_import and EGL_EXT_image_dma_buf_import_modifiers extensions. (Note that the exact layout of a particular format may vary between platforms - we only specify that the same platform should be able to import it.)\n\nThe total number of planes must not exceed AV_DRM_MAX_PLANES, and the order of the planes by increasing layer index followed by increasing plane index must be the same as the order which would be used for the data pointers in the equivalent software format.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDRMLayerDescriptor","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDRMLayerDescriptor","text":"AVDRMLayerDescriptor\n\nDRM layer descriptor.\n\nDescribes a single layer within a frame. This has the structure defined by its format, and will contain one or more planes.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDRMObjectDescriptor","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDRMObjectDescriptor","text":"AVDRMObjectDescriptor\n\nDRM object descriptor.\n\nDescribes a single DRM object, addressing it as a PRIME file descriptor.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDRMPlaneDescriptor","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDRMPlaneDescriptor","text":"AVDRMPlaneDescriptor\n\nDRM plane descriptor.\n\nDescribes a single plane of a layer, which is contained within a single object.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDevToAppMessageType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDevToAppMessageType","text":"AVDevToAppMessageType\n\nMessage types used by avdevice_dev_to_app_control_message().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDeviceInfo","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDeviceInfo","text":"AVDeviceInfo\n\nStructure describes basic parameters of the device.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDeviceInfoList","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDeviceInfoList","text":"AVDeviceInfoList\n\nList of devices.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDictionaryEntry","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDictionaryEntry","text":"AVDictionaryEntry\n\n@}\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDiscard","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDiscard","text":"AVDiscard\n\nlavc_decoding\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDownmixInfo","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDownmixInfo","text":"AVDownmixInfo\n\nThis structure describes optional metadata relevant to a downmix procedure.\n\nAll fields are set by the decoder to the value indicated in the audio bitstream (if present), or to a \"sane\" default otherwise.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDownmixType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDownmixType","text":"AVDownmixType\n\nPossible downmix types.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDurationEstimationMethod","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDurationEstimationMethod","text":"AVDurationEstimationMethod\n\nThe duration of a video can be estimated through various ways, and this enum can be used to know how the duration was estimated.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDynamicHDRPlus","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDynamicHDRPlus","text":"AVDynamicHDRPlus\n\nThis struct represents dynamic metadata for color volume transform - application 4 of SMPTE 2094-40:2016 standard.\n\nTo be used as payload of a AVFrameSideData or AVPacketSideData with the appropriate type.\n\nnote: Note\nThe struct should be allocated with av_dynamic_hdr_plus_alloc() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVDynamicHDRVivid","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVDynamicHDRVivid","text":"AVDynamicHDRVivid\n\nThis struct represents dynamic metadata for color volume transform - CUVA 005.1:2021 standard\n\nTo be used as payload of a AVFrameSideData or AVPacketSideData with the appropriate type.\n\nnote: Note\nThe struct should be allocated with av_dynamic_hdr_vivid_alloc() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVEncryptionInfo","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVEncryptionInfo","text":"AVEncryptionInfo\n\nThis describes encryption info for a packet. This contains frame-specific info for how to decrypt the packet before passing it to the decoder.\n\nThe size of this struct is not part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVEncryptionInitInfo","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVEncryptionInitInfo","text":"AVEncryptionInitInfo\n\nThis describes info used to initialize an encryption key system.\n\nThe size of this struct is not part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFifoCB","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFifoCB","text":"Callback for writing or reading from a FIFO, passed to (and invoked from) the av_fifo__cb() functions. It may be invoked multiple times from a single av_fifo__cb() call and may process less data than the maximum size indicated by nb_elems.\n\nArguments\n\nopaque: the opaque pointer provided to the av_fifo_*_cb() function\nbuf: the buffer for reading or writing the data, depending on which av_fifo_*_cb function is called\nnb_elems: On entry contains the maximum number of elements that can be read from / written into buf. On success, the callback should update it to contain the number of elements actually written.\n\nReturns\n\n0 on success, a negative error code on failure (will be returned from the invoking av_fifo_*_cb() function)\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilmGrainAOMParams","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilmGrainAOMParams","text":"AVFilmGrainAOMParams\n\nThis structure describes how to handle film grain synthesis for AOM codecs.\n\nnote: Note\nThe struct must be allocated as part of AVFilmGrainParams using av_film_grain_params_alloc(). Its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilmGrainH274Params","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilmGrainH274Params","text":"AVFilmGrainH274Params\n\nThis structure describes how to handle film grain synthesis for codecs using the ITU-T H.274 Versatile supplemental enhancement information message.\n\nnote: Note\nThe struct must be allocated as part of AVFilmGrainParams using av_film_grain_params_alloc(). Its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilmGrainParams","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilmGrainParams","text":"AVFilmGrainParams\n\nThis structure describes how to handle film grain synthesis in video for specific codecs. Must be present on every frame where film grain is meant to be synthesised for correct presentation.\n\nnote: Note\nThe struct must be allocated with av_film_grain_params_alloc() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilter","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilter","text":"AVFilter\n\nFilter definition. This defines the pads a filter contains, and all the callback functions used to interact with the filter.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilterChain","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilterChain","text":"AVFilterChain\n\nA filterchain is a list of filter specifications.\n\nCreated as a child of AVFilterGraphSegment by avfilter_graph_segment_parse(). Freed in avfilter_graph_segment_free().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilterContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilterContext","text":"AVFilterContext\n\nAn instance of a filter\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilterFormatsConfig","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilterFormatsConfig","text":"AVFilterFormatsConfig\n\nLists of formats / etc. supported by an end of a link.\n\nThis structure is directly part of AVFilterLink, in two copies: one for the source filter, one for the destination filter.\n\nThese lists are used for negotiating the format to actually be used, which will be loaded into the format and channel_layout members of AVFilterLink, when chosen.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilterGraphSegment","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilterGraphSegment","text":"AVFilterGraphSegment\n\nA parsed representation of a filtergraph segment.\n\nA filtergraph segment is conceptually a list of filterchains, with some supplementary information (e.g. format conversion flags).\n\nCreated by avfilter_graph_segment_parse(). Must be freed with avfilter_graph_segment_free().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilterInOut","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilterInOut","text":"AVFilterInOut\n\nA linked-list of the inputs/outputs of the filter chain.\n\nThis is mainly useful for avfilter_graph_parse() / avfilter_graph_parse2(), where it is used to communicate open (unlinked) inputs and outputs from and to the caller. This struct specifies, per each not connected pad contained in the graph, the filter context and the pad index required for establishing a link.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilterLink","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilterLink","text":"AVFilterLink\n\nA link between two filters. This contains pointers to the source and destination filters between which this link exists, and the indexes of the pads involved. In addition, this link also contains the parameters which have been negotiated and agreed upon between the filter, such as image dimensions, format, etc.\n\nApplications must not normally access the link structure directly. Use the buffersrc and buffersink API instead. In the future, access to the header may be reserved for filters implementation.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilterPadParams","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilterPadParams","text":"AVFilterPadParams\n\nParameters of a filter's input or output pad.\n\nCreated as a child of AVFilterParams by avfilter_graph_segment_parse(). Freed in avfilter_graph_segment_free().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFilterParams","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFilterParams","text":"AVFilterParams\n\nParameters describing a filter to be created in a filtergraph.\n\nCreated as a child of AVFilterGraphSegment by avfilter_graph_segment_parse(). Freed in avfilter_graph_segment_free().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFormatContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFormatContext","text":"AVFormatContext\n\nFormat I/O context. New fields can be added to the end with minor version bumps. Removal, reordering and changes to existing fields require a major version bump. sizeof(AVFormatContext) must not be used outside libav*, use avformat_alloc_context() to create an AVFormatContext.\n\nFields can be accessed through AVOptions (av_opt*), the name string used matches the associated command line parameter name and can be found in libavformat/options_table.h. The AVOption/command line parameter names differ in some cases from the C structure field names for historic reasons or brevity.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFrame","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFrame","text":"AVFrame\n\nThis structure describes decoded (raw) audio or video data.\n\nAVFrame must be allocated using av_frame_alloc(). Note that this only allocates the AVFrame itself, the buffers for the data must be managed through other means (see below). AVFrame must be freed with av_frame_free().\n\nAVFrame is typically allocated once and then reused multiple times to hold different data (e.g. a single AVFrame to hold frames received from a decoder). In such a case, av_frame_unref() will free any references held by the frame and reset it to its original clean state before it is reused again.\n\nThe data described by an AVFrame is usually reference counted through the AVBuffer API. The underlying buffer references are stored in AVFrame.buf / AVFrame.extended_buf. An AVFrame is considered to be reference counted if at least one reference is set, i.e. if AVFrame.buf[0] != NULL. In such a case, every single data plane must be contained in one of the buffers in AVFrame.buf or AVFrame.extended_buf. There may be a single buffer for all the data, or one separate buffer for each plane, or anything in between.\n\nsizeof(AVFrame) is not a part of the public ABI, so new fields may be added to the end with a minor bump.\n\nFields can be accessed through AVOptions, the name string used, matches the C structure field name for fields accessible through AVOptions.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFrameSideData","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFrameSideData","text":"AVFrameSideData\n\nStructure to hold side data for an AVFrame.\n\nsizeof(AVFrameSideData) is not a part of the public ABI, so new fields may be added to the end with a minor bump.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVFrameSideDataType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVFrameSideDataType","text":"AVFrameSideDataType\n\nlavu_frame AVFrame\n\nlavu_data\n\n@{ AVFrame is an abstraction for reference-counted raw multimedia data.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHDRPlusColorTransformParams","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHDRPlusColorTransformParams","text":"AVHDRPlusColorTransformParams\n\nColor transform parameters at a processing window in a dynamic metadata for SMPTE 2094-40.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHDRPlusOverlapProcessOption","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHDRPlusOverlapProcessOption","text":"AVHDRPlusOverlapProcessOption\n\nOption for overlapping elliptical pixel selectors in an image.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHDRPlusPercentile","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHDRPlusPercentile","text":"AVHDRPlusPercentile\n\nRepresents the percentile at a specific percentage in a distribution.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHDRVivid3SplineParams","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHDRVivid3SplineParams","text":"AVHDRVivid3SplineParams\n\nHDR Vivid three spline params.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHDRVividColorToneMappingParams","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHDRVividColorToneMappingParams","text":"AVHDRVividColorToneMappingParams\n\nColor tone mapping parameters at a processing window in a dynamic metadata for CUVA 005.1:2021.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHDRVividColorTransformParams","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHDRVividColorTransformParams","text":"AVHDRVividColorTransformParams\n\nColor transform parameters at a processing window in a dynamic metadata for CUVA 005.1:2021.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHMACType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHMACType","text":"AVHMACType\n\nlavu_hmac HMAC\n\nlavu_crypto\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHWAccel","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHWAccel","text":"AVHWAccel\n\nlavc_hwaccel AVHWAccel\n\nnote: Note\nNothing in this structure should be accessed by the user. At some point in future it will not be externally visible at all.\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHWDeviceContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHWDeviceContext","text":"AVHWDeviceContext\n\nThis struct aggregates all the (hardware/vendor-specific) \"high-level\" state, i.e. state that is not tied to a concrete processing configuration. E.g., in an API that supports hardware-accelerated encoding and decoding, this struct will (if possible) wrap the state that is common to both encoding and decoding and from which specific instances of encoders or decoders can be derived.\n\nThis struct is reference-counted with the AVBuffer mechanism. The av_hwdevice_ctx_alloc() constructor yields a reference, whose data field points to the actual AVHWDeviceContext. Further objects derived from AVHWDeviceContext (such as AVHWFramesContext, describing a frame pool with specific properties) will hold an internal reference to it. After all the references are released, the AVHWDeviceContext itself will be freed, optionally invoking a user-specified callback for uninitializing the hardware state.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHWFramesConstraints","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHWFramesConstraints","text":"AVHWFramesConstraints\n\nThis struct describes the constraints on hardware frames attached to a given device with a hardware-specific configuration. This is returned by av_hwdevice_get_hwframe_constraints() and must be freed by av_hwframe_constraints_free() after use.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHWFramesContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHWFramesContext","text":"AVHWFramesContext\n\nThis struct describes a set or pool of \"hardware\" frames (i.e. those with data not located in normal system memory). All the frames in the pool are assumed to be allocated in the same way and interchangeable.\n\nThis struct is reference-counted with the AVBuffer mechanism and tied to a given AVHWDeviceContext instance. The av_hwframe_ctx_alloc() constructor yields a reference, whose data field points to the actual AVHWFramesContext struct.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVHashContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVHashContext","text":"ffhash.c\n\nThis example is a simple command line application that takes one or more arguments. It demonstrates a typical use of the hashing API with allocation, initialization, updating, and finalizing.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFAmbisonicsMode","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFAmbisonicsMode","text":"AVIAMFAmbisonicsMode\n\n@}\n\nlavu_iamf_audio\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFAnimationType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFAnimationType","text":"AVIAMFAnimationType\n\nlavu_iamf Immersive Audio Model and Formats\n\nlavu_audio\n\nImmersive Audio Model and Formats related functions and defines\n\nlavu_iamf_params Parameter Definition\n\nlavu_iamf\n\n@{ Parameters as defined in section 3.6.1 and 3.8 of IAMF. @}\n\nlavu_iamf_audio Audio Element\n\nlavu_iamf\n\n@{ Audio Elements as defined in section 3.6 of IAMF. @}\n\nlavu_iamf_mix Mix Presentation\n\nlavu_iamf\n\n@{ Mix Presentations as defined in section 3.7 of IAMF. @}\n\nlavu_iamf_params\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFAudioElement","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFAudioElement","text":"AVIAMFAudioElement\n\nInformation on how to combine one or more audio streams, as defined in section 3.6 of IAMF.\n\nnote: Note\nThe struct should be allocated with av_iamf_audio_element_alloc() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFDemixingInfo","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFDemixingInfo","text":"AVIAMFDemixingInfo\n\nDemixing Info Parameter Data as defined in section 3.8.2 of IAMF.\n\nnote: Note\nThis struct's size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFHeadphonesMode","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFHeadphonesMode","text":"AVIAMFHeadphonesMode\n\n@}\n\nlavu_iamf_mix\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFLayer","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFLayer","text":"AVIAMFLayer\n\nA layer defining a Channel Layout in the Audio Element.\n\nWhen AVIAMFAudioElement.audioelementtype \"the parent's Audio Element type\" is AV_IAMF_AUDIO_ELEMENT_TYPE_CHANNEL, this corresponds to an Scalable Channel Layout layer as defined in section 3.6.2 of IAMF. For AV_IAMF_AUDIO_ELEMENT_TYPE_SCENE, it is an Ambisonics channel layout as defined in section 3.6.3 of IAMF.\n\nnote: Note\nThe struct should be allocated with av_iamf_audio_element_add_layer() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFMixGain","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFMixGain","text":"AVIAMFMixGain\n\nMix Gain Parameter Data as defined in section 3.8.1 of IAMF.\n\nnote: Note\nThis struct's size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFMixPresentation","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFMixPresentation","text":"AVIAMFMixPresentation\n\nInformation on how to render and mix one or more AVIAMFAudioElement to generate the final audio output, as defined in section 3.7 of IAMF.\n\nnote: Note\nThe struct should be allocated with av_iamf_mix_presentation_alloc() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFParamDefinition","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFParamDefinition","text":"AVIAMFParamDefinition\n\nParameters as defined in section 3.6.1 of IAMF.\n\nThe struct is allocated by av_iamf_param_definition_alloc() along with an array of subblocks, its type depending on the value of type. This array is placed subblocks_offset bytes after the start of this struct.\n\nnote: Note\nThis struct's size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFReconGain","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFReconGain","text":"AVIAMFReconGain\n\nRecon Gain Info Parameter Data as defined in section 3.8.3 of IAMF.\n\nnote: Note\nThis struct's size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFSubmix","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFSubmix","text":"AVIAMFSubmix\n\nSubmix layout as defined in section 3.7 of IAMF.\n\nnote: Note\nThe struct should be allocated with av_iamf_mix_presentation_add_submix() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFSubmixElement","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFSubmixElement","text":"AVIAMFSubmixElement\n\nSubmix element as defined in section 3.7 of IAMF.\n\nnote: Note\nThe struct should be allocated with av_iamf_submix_add_element() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIAMFSubmixLayout","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIAMFSubmixLayout","text":"AVIAMFSubmixLayout\n\nSubmix layout as defined in section 3.7.6 of IAMF.\n\nnote: Note\nThe struct should be allocated with av_iamf_submix_add_layout() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIOContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIOContext","text":"AVIOContext\n\nBytestream IO Context. New public fields can be added with minor version bumps. Removal, reordering and changes to existing public fields require a major version bump. sizeof(AVIOContext) must not be used outside libav*.\n\nnote: Note\nNone of the function pointers in AVIOContext should be called directly, they should only be set by the client application when implementing custom I/O. Normally these are set to the function pointers specified in avio_alloc_context()\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIODataMarkerType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIODataMarkerType","text":"AVIODataMarkerType\n\nDifferent data types that can be returned via the AVIO write_data_type callback.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIODirEntry","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIODirEntry","text":"AVIODirEntry\n\nDescribes single entry of the directory.\n\nOnly name and type fields are guaranteed be set. Rest of fields are protocol or/and platform dependent and might be unknown.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIODirEntryType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIODirEntryType","text":"AVIODirEntryType\n\nDirectory entry types.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVIOInterruptCB","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVIOInterruptCB","text":"AVIOInterruptCB\n\nCallback for checking whether to abort blocking functions. AVERROR_EXIT is returned in this case by the interrupted function. During blocking operations, callback is called with opaque as parameter. If the callback returns 1, the blocking operation will be aborted.\n\nNo members can be added to this struct without a major bump, if new elements have been added after this struct in AVFormatContext or AVIOContext.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVInputFormat","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVInputFormat","text":"AVInputFormat\n\nlavf_decoding\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVLFG","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVLFG","text":"AVLFG\n\nContext structure for the Lagged Fibonacci PRNG. The exact layout, types and content of this struct may change and should not be accessed directly. Only its sizeof() is guaranteed to stay the same to allow easy instantiation.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVLumaCoefficients","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVLumaCoefficients","text":"AVLumaCoefficients\n\nStruct containing luma coefficients to be used for RGB to YUV/YCoCg, or similar calculations.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVMasteringDisplayMetadata","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVMasteringDisplayMetadata","text":"AVMasteringDisplayMetadata\n\nMastering display metadata capable of representing the color volume of the display used to master the content (SMPTE 2086:2014).\n\nTo be used as payload of a AVFrameSideData or AVPacketSideData with the appropriate type.\n\nnote: Note\nThe struct should be allocated with av_mastering_display_metadata_alloc() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVMediaCodecBuffer","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVMediaCodecBuffer","text":"Opaque structure representing a MediaCodec buffer to render.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVMediaCodecContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVMediaCodecContext","text":"AVMediaCodecContext\n\nThis structure holds a reference to a android/view/Surface object that will be used as output by the decoder.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVMediaCodecDeviceContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVMediaCodecDeviceContext","text":"AVMediaCodecDeviceContext\n\nMediaCodec details.\n\nAllocated as AVHWDeviceContext.hwctx\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVMediaType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVMediaType","text":"AVMediaType\n\nlavu_media Media Type\n\nMedia Type\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVOHCodecDeviceContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVOHCodecDeviceContext","text":"AVOHCodecDeviceContext\n\nOpenHarmony codec device\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVOpenCLDeviceContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVOpenCLDeviceContext","text":"AVOpenCLDeviceContext\n\nOpenCL device details.\n\nAllocated as AVHWDeviceContext.hwctx\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVOpenCLFrameDescriptor","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVOpenCLFrameDescriptor","text":"AVOpenCLFrameDescriptor\n\nOpenCL frame descriptor for pool allocation.\n\nIn user-allocated pools, AVHWFramesContext.pool must return AVBufferRefs with the data pointer pointing at an object of this type describing the planes of the frame.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVOpenCLFramesContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVOpenCLFramesContext","text":"AVOpenCLFramesContext\n\nOpenCL-specific data associated with a frame pool.\n\nAllocated as AVHWFramesContext.hwctx.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVOption","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVOption","text":"AVOption\n\nAVOption\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVOptionArrayDef","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVOptionArrayDef","text":"AVOptionArrayDef\n\nMay be set as default_val for AV_OPT_TYPE_FLAG_ARRAY options.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVOptionRange","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVOptionRange","text":"AVOptionRange\n\nA single allowed range of values, or a single allowed value.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVOptionRanges","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVOptionRanges","text":"AVOptionRanges\n\nList of AVOptionRange structs.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVOptionType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVOptionType","text":"AVOptionType\n\nAn option type determines: - for native access, the underlying C type of the field that an AVOption refers to; - for foreign access, the semantics of accessing the option through this API, e.g. which av_opt_get_() and av_opt_set_() functions can be called, or what format will av_opt_get()/av_opt_set() expect/produce.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVOutputFormat","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVOutputFormat","text":"AVOutputFormat\n\nlavf_encoding\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVPacket","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVPacket","text":"AVPacket\n\nThis structure stores compressed data. It is typically exported by demuxers and then passed as input to decoders, or received as output from encoders and then passed to muxers.\n\nFor video, it should typically contain one compressed frame. For audio it may contain several compressed frames. Encoders are allowed to output empty packets, with no compressed data, containing only side data (e.g. to update some stream parameters at the end of encoding).\n\nThe semantics of data ownership depends on the buf field. If it is set, the packet data is dynamically allocated and is valid indefinitely until a call to av_packet_unref() reduces the reference count to 0.\n\nIf the buf field is not set av_packet_ref() would make a copy instead of increasing the reference count.\n\nThe side data is always allocated with av_malloc(), copied by av_packet_ref() and freed by av_packet_unref().\n\nsizeof(AVPacket) being a part of the public ABI is deprecated. once av_init_packet() is removed, new packets will only be able to be allocated with av_packet_alloc(), and new fields may be added to the end of the struct with a minor bump.\n\nSee also\n\nav_packet_alloc, av_packet_ref, av_packet_unref\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVPacketSideData","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVPacketSideData","text":"AVPacketSideData\n\nThis structure stores auxiliary information for decoding, presenting, or otherwise processing the coded stream. It is typically exported by demuxers and encoders and can be fed to decoders and muxers either in a per packet basis, or as global side data (applying to the entire coded stream).\n\nGlobal side data is handled as follows: - During demuxing, it may be exported through AVCodecParameters.codedsidedata \"AVStream's codec parameters\", which can then be passed as input to decoders through the AVCodecContext.codedsidedata \"decoder context's side data\", for initialization. - For muxing, it can be fed through AVCodecParameters.codedsidedata \"AVStream's codec parameters\", typically the output of encoders through the AVCodecContext.codedsidedata \"encoder context's side data\", for initialization.\n\nPacket specific side data is handled as follows: - During demuxing, it may be exported through AVPacket.sidedata \"AVPacket's side data\", which can then be passed as input to decoders. - For muxing, it can be fed through AVPacket.sidedata \"AVPacket's side data\", typically the output of encoders.\n\nDifferent modules may accept or export different types of side data depending on media type and codec. Refer to AVPacketSideDataType for a list of defined types and where they may be found or used.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVPacketSideDataType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVPacketSideDataType","text":"AVPacketSideDataType\n\nlavc_packet_side_data AVPacketSideData\n\nTypes and functions for working with AVPacketSideData. @{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVPanScan","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVPanScan","text":"AVPanScan\n\nPan Scan area. This specifies the area which should be displayed. Note there may be multiple such areas for one frame.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVPictureStructure","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVPictureStructure","text":"AVPictureStructure\n\nlavc_parsing Frame parsing\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVPictureType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVPictureType","text":"AVPictureType\n\n@} @}\n\nlavu_picture Image related\n\nAVPicture types, pixel formats and basic image planes manipulation.\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVPixFmtDescriptor","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVPixFmtDescriptor","text":"AVPixFmtDescriptor\n\nDescriptor that unambiguously describes how the bits of a pixel are stored in the up to 4 data planes of an image. It also stores the subsampling factors and number of components.\n\nnote: Note\nThis is separate of the colorspace (RGB, YCbCr, YPbPr, JPEG-style YUV and all the YUV variants) AVPixFmtDescriptor just stores how values are stored not what these values represent.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVPixelFormat","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVPixelFormat","text":"AVPixelFormat\n\nPixel format.\n\nnote: Note\nAV_PIX_FMT_RGB32 is handled in an endian-specific manner. An RGBA color is put together as: (A << 24) | (R << 16) | (G << 8) | B This is stored as BGRA on little-endian CPU architectures and ARGB on big-endian CPUs.\n\nnote: Note\nIf the resolution is not a multiple of the chroma subsampling factor then the chroma plane resolution must be rounded up.\n\n\\par When the pixel format is palettized RGB32 (AV_PIX_FMT_PAL8), the palettized image data is stored in AVFrame.data[0]. The palette is transported in AVFrame.data[1], is 1024 bytes long (256 4-byte entries) and is formatted the same as in AV_PIX_FMT_RGB32 described above (i.e., it is also endian-specific). Note also that the individual RGB32 palette components stored in AVFrame.data[1] should be in the range 0..255. This is important as many custom PAL8 video codecs that were designed to run on the IBM VGA graphics adapter use 6-bit palette components.\n\n\\par For all the 8 bits per pixel formats, an RGB32 palette is in data[1] like for pal8. This palette is filled in automatically by the function allocating the picture.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVPrimaryCoefficients","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVPrimaryCoefficients","text":"AVPrimaryCoefficients\n\nStruct defining the red, green, and blue primary locations in terms of CIE 1931 chromaticity x and y.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVProbeData","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVProbeData","text":"AVProbeData\n\nThis structure contains the data a format has to probe a file.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVProducerReferenceTime","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVProducerReferenceTime","text":"AVProducerReferenceTime\n\nThis structure supplies correlation between a packet timestamp and a wall clock production time. The definition follows the Producer Reference Time ('prft') as defined in ISO/IEC 14496-12\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVProfile","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVProfile","text":"AVProfile\n\nAVProfile.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVProgram","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVProgram","text":"AVProgram\n\nNew fields can be added to the end with minor version bumps. Removal, reordering and changes to existing fields require a major version bump. sizeof(AVProgram) must not be used outside libav*.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVRC4","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVRC4","text":"AVRC4\n\nlavu_rc4 RC4\n\nlavu_crypto\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVRTCPSenderReport","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVRTCPSenderReport","text":"AVRTCPSenderReport\n\nRTCP SR (Sender Report) information\n\nThe received sender report information for an RTSP stream, exposed as AV_PKT_DATA_RTCP_SR side data.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVRational","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVRational","text":"AVRational\n\nRational number (pair of numerator and denominator).\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVRefStructOpaque","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVRefStructOpaque","text":"AVRefStructOpaque\n\nThis union is used for all opaque parameters in this API to spare the user to cast const away in case the opaque to use is const-qualified.\n\nThe functions provided by this API with an AVRefStructOpaque come in pairs named foo_c and foo. The foo function accepts void* as opaque and is just a wrapper around the foo_c function; \"_c\" means \"(potentially) const\".\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVRegionOfInterest","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVRegionOfInterest","text":"AVRegionOfInterest\n\nStructure describing a single Region Of Interest.\n\nWhen multiple regions are defined in a single side-data block, they should be ordered from most to least important - some encoders are only capable of supporting a limited number of distinct regions, so will have to truncate the list.\n\nWhen overlapping regions are defined, the first region containing a given area of the frame applies.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVReplayGain","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVReplayGain","text":"AVReplayGain\n\nReplayGain information (see http://wiki.hydrogenaudio.org/index.php?title=ReplayGain_1.0_specification). The size of this struct is a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVRounding","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVRounding","text":"AVRounding\n\nRounding methods.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVSampleFormat","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVSampleFormat","text":"AVSampleFormat\n\nAudio sample formats\n\nThe data described by the sample format is always in native-endian order. Sample values can be expressed by native C types, hence the lack of a signed 24-bit sample format even though it is a common raw audio data format.\nThe floating-point formats are based on full volume being in the range [-1.0, 1.0]. Any values outside this range are beyond full volume level.\nThe data layout as used in av_samples_fill_arrays() and elsewhere in FFmpeg (such as AVFrame in libavcodec) is as follows:\n\n\\par For planar sample formats, each audio channel is in a separate data plane, and linesize is the buffer size, in bytes, for a single plane. All data planes must be the same size. For packed sample formats, only the first data plane is used, and samples for each channel are interleaved. In this case, linesize is the buffer size, in bytes, for the 1 plane.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVSideDataDescriptor","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVSideDataDescriptor","text":"AVSideDataDescriptor\n\nThis struct describes the properties of a side data type. Its instance corresponding to a given type can be obtained from av_frame_side_data_desc().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVSmpte291mAnc8bit","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVSmpte291mAnc8bit","text":"AVSmpte291mAnc8bit\n\nAn ANC packet with an 8-bit payload. This can be decoded from AVSmpte436mCodedAnc::payload.\n\nNote: Some ANC packets need a 10-bit payload, if stored in this struct, the most-significant 2 bits of each sample are discarded.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVSmpte436mAncIterator","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVSmpte436mAncIterator","text":"AVSmpte436mAncIterator\n\nIterator over the ANC packets in a single AV_CODEC_ID_SMPTE_436M_ANC AVPacket's data\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVSmpte436mCodedAnc","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVSmpte436mCodedAnc","text":"AVSmpte436mCodedAnc\n\nAn encoded ANC packet within a single AV_CODEC_ID_SMPTE_436M_ANC AVPacket's data. The repeated section of Table 7 (page 13) of: https://pub.smpte.org/latest/st436/s436m-2006.pdf\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVSmpte436mPayloadSampleCoding","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVSmpte436mPayloadSampleCoding","text":"AVSmpte436mPayloadSampleCoding\n\nPayload Sample Coding from Table 4 (page 10) and Table 7 (page 13) of: https://pub.smpte.org/latest/st436/s436m-2006.pdf\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVSmpte436mWrappingType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVSmpte436mWrappingType","text":"AVSmpte436mWrappingType\n\nWrapping Type from Table 7 (page 13) of: https://pub.smpte.org/latest/st436/s436m-2006.pdf\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVSphericalMapping","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVSphericalMapping","text":"AVSphericalMapping\n\nThis structure describes how to handle spherical videos, outlining information about projection, initial layout, and any other view modifier.\n\nnote: Note\nThe struct must be allocated with av_spherical_alloc() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVSphericalProjection","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVSphericalProjection","text":"AVSphericalProjection\n\nProjection of the video surface(s) on a sphere.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVStereo3D","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVStereo3D","text":"AVStereo3D\n\nStereo 3D type: this structure describes how two videos are packed within a single video surface, with additional information as needed.\n\nnote: Note\nThe struct must be allocated with av_stereo3d_alloc() and its size is not a part of the public ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVStereo3DPrimaryEye","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVStereo3DPrimaryEye","text":"AVStereo3DPrimaryEye\n\nList of possible primary eyes.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVStereo3DType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVStereo3DType","text":"AVStereo3DType\n\nList of possible 3D Types\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVStereo3DView","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVStereo3DView","text":"AVStereo3DView\n\nList of possible view types.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVStream","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVStream","text":"AVStream\n\nStream structure. New fields can be added to the end with minor version bumps. Removal, reordering and changes to existing fields require a major version bump. sizeof(AVStream) must not be used outside libav*.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVStreamGroupLCEVC","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVStreamGroupLCEVC","text":"AVStreamGroupLCEVC\n\nAVStreamGroupLCEVC is meant to define the relation between video streams and a data stream containing LCEVC enhancement layer NALUs.\n\nNo more than one stream of AVCodecParameters.codectype \"codec\\type\" AVMEDIA_TYPE_DATA shall be present, and it must be of AVCodecParameters.codecid \"codec\\id\" AV_CODEC_ID_LCEVC.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVStreamGroupTileGrid","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVStreamGroupTileGrid","text":"AVStreamGroupTileGrid\n\nAVStreamGroupTileGrid holds information on how to combine several independent images on a single canvas for presentation.\n\nThe output should be a AVStreamGroupTileGrid.background \"background\" colored AVStreamGroupTileGrid.codedwidth \"coded\\width\" x AVStreamGroupTileGrid.codedheight \"coded\\height\" canvas where a AVStreamGroupTileGrid.nbtiles \"nb\\tiles\" amount of tiles are placed in the order they appear in the AVStreamGroupTileGrid.offsets \"offsets\" array, at the exact offset described for them. In particular, if two or more tiles overlap, the image with higher index in the AVStreamGroupTileGrid.offsets \"offsets\" array takes priority. Note that a single image may be used multiple times, i.e. multiple entries in AVStreamGroupTileGrid.offsets \"offsets\" may have the same value of idx.\n\nThe following is an example of a simple grid with 3 rows and 4 columns:\n\n+–-+–-+–-+–-+ | 0 | 1 | 2 | 3 | +–-+–-+–-+–-+ | 4 | 5 | 6 | 7 | +–-+–-+–-+–-+ | 8 | 9 |10 |11 | +–-+–-+–-+–-+\n\nAssuming all tiles have a dimension of 512x512, the AVStreamGroupTileGrid.offsets \"offset\" of the topleft pixel of the first AVStreamGroup.streams \"stream\" in the group is \"0,0\", the AVStreamGroupTileGrid.offsets \"offset\" of the topleft pixel of the second AVStreamGroup.streams \"stream\" in the group is \"512,0\", the AVStreamGroupTileGrid.offsets \"offset\" of the topleft pixel of the fifth AVStreamGroup.streams \"stream\" in the group is \"0,512\", the AVStreamGroupTileGrid.offsets \"offset\", of the topleft pixel of the sixth AVStreamGroup.streams \"stream\" in the group is \"512,512\", etc.\n\nThe following is an example of a canvas with overlapping tiles:\n\n+–––––-+ | %%%%% | |***%3%%@@| |**0%%%%2@| |***##1@@@| | ##### | +–––––-+\n\nAssuming a canvas with size 1024x1024 and all tiles with a dimension of 512x512, a possible AVStreamGroupTileGrid.offsets \"offset\" for the topleft pixel of the first AVStreamGroup.streams \"stream\" in the group would be 0x256, the AVStreamGroupTileGrid.offsets \"offset\" for the topleft pixel of the second AVStreamGroup.streams \"stream\" in the group would be 256x512, the AVStreamGroupTileGrid.offsets \"offset\" for the topleft pixel of the third AVStreamGroup.streams \"stream\" in the group would be 512x256, and the AVStreamGroupTileGrid.offsets \"offset\" for the topleft pixel of the fourth AVStreamGroup.streams \"stream\" in the group would be 256x0.\n\nsizeof(AVStreamGroupTileGrid) is not a part of the ABI and may only be allocated by avformat_stream_group_create().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVStreamParseType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVStreamParseType","text":"AVStreamParseType\n\n@}\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVSubtitleType","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVSubtitleType","text":"AVSubtitleType\n\n@}\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVTXFlags","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVTXFlags","text":"AVTXFlags\n\nFlags for av_tx_init()\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVTreeNode","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVTreeNode","text":"lavu_tree AVTree\n\nlavu_data\n\nLow-complexity tree container\n\nInsertion, removal, finding equal, largest which is smaller than and smallest which is larger than, all have O(log n) worst-case complexity. @{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVVAAPIDeviceContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVVAAPIDeviceContext","text":"AVVAAPIDeviceContext\n\nVAAPI connection details.\n\nAllocated as AVHWDeviceContext.hwctx\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVVAAPIFramesContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVVAAPIFramesContext","text":"AVVAAPIFramesContext\n\nVAAPI-specific data associated with a frame pool.\n\nAllocated as AVHWFramesContext.hwctx.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVVAAPIHWConfig","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVVAAPIHWConfig","text":"AVVAAPIHWConfig\n\nVAAPI hardware pipeline configuration details.\n\nAllocated with av_hwdevice_hwconfig_alloc().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVVDPAUContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVVDPAUContext","text":"AVVDPAUContext\n\nThis structure is used to share data between the libavcodec library and the client video application. This structure will be allocated and stored in AVCodecContext.hwaccel_context by av_vdpau_bind_context(). Members can be set by the user once during initialization or through each AVCodecContext.get_buffer() function call. In any case, they must be valid prior to calling decoding functions.\n\nThe size of this structure is not a part of the public ABI and must not be used outside of libavcodec.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVVDPAUDeviceContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVVDPAUDeviceContext","text":"AVVDPAUDeviceContext\n\nThis struct is allocated as AVHWDeviceContext.hwctx\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVVTFramesContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVVTFramesContext","text":"AVVTFramesContext\n\n``\n\nAn API-specific header for AV_HWDEVICE_TYPE_VIDEOTOOLBOX.\n\nThis API supports frame allocation using a native CVPixelBufferPool instead of an AVBufferPool.\n\nIf the API user sets a custom pool, AVHWFramesContext.pool must return AVBufferRefs whose data pointer is a CVImageBufferRef or CVPixelBufferRef. Note that the underlying CVPixelBuffer could be retained by OS frameworks depending on application usage, so it is preferable to let CoreVideo manage the pool using the default implementation.\n\nCurrently AVHWDeviceContext.hwctx are always NULL.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVVideoBlockParams","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVVideoBlockParams","text":"AVVideoBlockParams\n\nData structure for storing block-level encoding information. It is allocated as a part of AVVideoEncParams and should be retrieved with av_video_enc_params_block().\n\nsizeof(AVVideoBlockParams) is not a part of the ABI and new fields may be added to it.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVVideoEncParams","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVVideoEncParams","text":"AVVideoEncParams\n\nVideo encoding parameters for a given frame. This struct is allocated along with an optional array of per-block AVVideoBlockParams descriptors. Must be allocated with av_video_enc_params_alloc().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVVkFrameFlags","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVVkFrameFlags","text":"AVVkFrameFlags\n\nDefines the behaviour of frame allocation.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVWhitepointCoefficients","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVWhitepointCoefficients","text":"Struct defining white point location in terms of CIE 1931 chromaticity x and y.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.AVXTEA","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.AVXTEA","text":"AVXTEA\n\n``\n\nPublic header for libavutil XTEA algorithm\n\nlavu_xtea XTEA\n\nlavu_crypto\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.DiracParseCodes","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.DiracParseCodes","text":"DiracParseCodes\n\nParse code values:\n\nDirac Specification -> 9.6.1 Table 9.1\n\nVC-2 Specification -> 10.4.1 Table 10.1\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.RcOverride","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.RcOverride","text":"RcOverride\n\nlavc_encoding\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.SwsContext","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.SwsContext","text":"SwsContext\n\nMain external API structure. New fields can be added to the end with minor version bumps. Removal, reordering and changes to existing fields require a major version bump. sizeof(SwsContext) is not part of the ABI.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.SwsDither","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.SwsDither","text":"SwsDither\n\n**************************** Flags and quality settings *****************************\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.__JL_Ctag_41","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.__JL_Ctag_41","text":"__JL_Ctag_41\n\nlavfi_buffersrc Buffer source API\n\nlavfi\n\n@{\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.__JL_Ctag_57","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.__JL_Ctag_57","text":"__JL_Ctag_57\n\nFlags for frame cropping.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.__JL_Ctag_64","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.__JL_Ctag_64","text":"__JL_Ctag_64\n\nFlags to apply to frame mappings.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.__JL_Ctag_68","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.__JL_Ctag_68","text":"__JL_Ctag_68\n\n``\n\nAPI-specific header for AV_HWDEVICE_TYPE_DRM.\n\nInternal frame allocation is not currently supported - all frames must be allocated by the user. Thus AVHWFramesContext is always NULL, though this may change if support for frame allocation is added in future.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.__JL_Ctag_71","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.__JL_Ctag_71","text":"__JL_Ctag_71\n\n``\n\nAPI-specific header for AV_HWDEVICE_TYPE_VAAPI.\n\nDynamic frame pools are supported, but note that any pool used as a render target is required to be of fixed size in order to be be usable as an argument to vaCreateContext().\n\nFor user-allocated pools, AVHWFramesContext.pool must return AVBufferRefs with the data pointer set to a VASurfaceID.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.__JL_Ctag_91","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.__JL_Ctag_91","text":"__JL_Ctag_91\n\nGroup type-specific parameters\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.__JL_Ctag_93","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.__JL_Ctag_93","text":"__JL_Ctag_93\n\nDetails about which channels are present in this layout. For AV_CHANNEL_ORDER_UNSPEC, this field is undefined and must not be used.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.__JL_Ctag_94","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.__JL_Ctag_94","text":"__JL_Ctag_94\n\nAn nbtiles sized array of offsets in pixels from the topleft edge of the canvas, indicating where each stream should be placed. It must be allocated with the [`avmalloc`](@ref)() family of functions.\n\ndemuxing: set by libavformat, must not be modified by the caller. - muxing: set by the caller before avformat_write_header().\n\nFreed by libavformat in avformat_free_context().\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.__JL_Ctag_95","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.__JL_Ctag_95","text":"__JL_Ctag_95\n\nNative access only, except when documented otherwise. the default value for scalar options\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.__JL_Ctag_96","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.__JL_Ctag_96","text":"__JL_Ctag_96\n\nAdditional fields may be added both here and in any structure included. If a codec's film grain structure differs slightly over another codec's, fields within may change meaning depending on the type.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_csp_eotf_function","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_csp_eotf_function","text":"Function pointer representing an ITU EOTF transfer for a given reference display configuration.\n\nArguments\n\nLw: The white point luminance of the display, in nits (cd/m^2).\nLb: The black point luminance of the display, in nits (cd/m^2).\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_csp_trc_function","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_csp_trc_function","text":"Function pointer representing a double -> double transfer function that performs either an OETF transfer function, or alternatively an inverse EOTF function (in particular, for SMPTE ST 2084 / PQ). This function inputs linear light, and outputs gamma encoded light.\n\nSee ITU-T H.273 for more information.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_format_control_message","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_format_control_message","text":"Callback used by devices to communicate with application.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_pixelutils_sad_fn","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_pixelutils_sad_fn","text":"Sum of abs(src1[x] - src2[x])\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.av_tx_fn","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.av_tx_fn","text":"Function pointer to a function to perform the transform.\n\nnote: Note\nUsing a different context than the one allocated during av_tx_init() is not allowed.\n\nThe out and in arrays must be aligned to the maximum required by the CPU architecture unless the AV_TX_UNALIGNED flag was set in av_tx_init(). The stride must follow the constraints the transform type has specified.\n\nArguments\n\ns: the transform context\nout: the output array\nin: the input array\nstride: the input or output stride in bytes\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_action_func","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_action_func","text":"A function pointer passed to the AVFilterGraph.execute callback to be executed multiple times, possibly in parallel.\n\nArguments\n\nctx: the filter context the job belongs to\narg: an opaque parameter passed through from AVFilterGraph.execute\njobnr: the index of the job being executed\nnb_jobs: the total number of jobs\n\nReturns\n\n0 on success, a negative AVERROR on error\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.avfilter_execute_func","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.avfilter_execute_func","text":"A function executing multiple jobs, possibly in parallel.\n\nArguments\n\nctx: the filter context to which the jobs belong\nfunc: the function to be called multiple times\narg: the argument to be passed to func\nret: a nb_jobs-sized array to be filled with return values from each invocation of func\nnb_jobs: the number of jobs to execute\n\nReturns\n\n0 on success, a negative AVERROR on error\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#VideoIO.libffmpeg.ff_pad_helper_AVBPrint","page":"FFmpeg Reference","title":"VideoIO.libffmpeg.ff_pad_helper_AVBPrint","text":"ff_pad_helper_AVBPrint\n\nBuffer to print data progressively\n\nThe string buffer grows as necessary and is always 0-terminated. The content of the string is never accessed, and thus is encoding-agnostic and can even hold binary data.\n\nSmall buffers are kept in the structure itself, and thus require no memory allocation at all (unless the contents of the buffer is needed after the structure goes out of scope). This is almost as lightweight as declaring a local char buf[512].\n\nThe length of the string can go beyond the allocated size: the buffer is then truncated, but the functions still keep account of the actual total length.\n\nIn other words, AVBPrint.len can be greater than AVBPrint.size and records the total length of what would have been to the buffer if there had been enough memory.\n\nAppend operations do not need to be tested for failure: if a memory allocation fails, data stop being appended to the buffer, but the length is still updated. This situation can be tested with av_bprint_is_complete().\n\nThe AVBPrint.size_max field determines several possible behaviours: - size\\_max = -1 (= UINT_MAX) or any large value will let the buffer be reallocated as necessary, with an amortized linear cost. - size\\_max = 0 prevents writing anything to the buffer: only the total length is computed. The write operations can then possibly be repeated in a buffer with exactly the necessary size (using size\\_init = size\\_max = len + 1). - size\\_max = 1 is automatically replaced by the exact size available in the structure itself, thus ensuring no dynamic memory allocation. The internal buffer is large enough to hold a reasonable paragraph of text, such as the current paragraph.\n\n\n\n\n\n","category":"type"},{"location":"ffmpeg_reference/#Constants","page":"FFmpeg Reference","title":"Constants","text":"","category":"section"},{"location":"ffmpeg_reference/#See-Also","page":"FFmpeg Reference","title":"See Also","text":"","category":"section"},{"location":"ffmpeg_reference/","page":"FFmpeg Reference","title":"FFmpeg Reference","text":"Reading Videos\nWriting Videos\nLow level functionality\nFFmpeg Official Documentation","category":"page"},{"location":"utilities/#Utilities","page":"Utilities","title":"Utilities","text":"","category":"section"},{"location":"utilities/#Test-Videos","page":"Utilities","title":"Test Videos","text":"","category":"section"},{"location":"utilities/","page":"Utilities","title":"Utilities","text":"A small number of test videos are available through VideoIO.TestVideos. These are short videos in a variety of formats with non-restrictive (public domain or Creative Commons) licenses.","category":"page"},{"location":"utilities/#VideoIO.TestVideos.available","page":"Utilities","title":"VideoIO.TestVideos.available","text":"available()\n\nPrint a list of all available test videos.\n\n\n\n\n\n","category":"function"},{"location":"utilities/#VideoIO.TestVideos.testvideo","page":"Utilities","title":"VideoIO.TestVideos.testvideo","text":"testvideo(name, ops...)\n\nReturns an AVInput object for the given video name. The video will be downloaded if it isn't available.\n\n\n\n\n\n","category":"function"},{"location":"utilities/#VideoIO.TestVideos.download_all","page":"Utilities","title":"VideoIO.TestVideos.download_all","text":"download_all()\n\nDownloads all test videos.\n\n\n\n\n\n","category":"function"},{"location":"utilities/#VideoIO.TestVideos.remove_all","page":"Utilities","title":"VideoIO.TestVideos.remove_all","text":"remove_all()\n\nRemove all test videos.\n\n\n\n\n\n","category":"function"},{"location":"lowlevel/#Low-level-functionality","page":"Low Level Functionality","title":"Low level functionality","text":"","category":"section"},{"location":"lowlevel/#FFMPEG-log-level","page":"Low Level Functionality","title":"FFMPEG log level","text":"","category":"section"},{"location":"lowlevel/","page":"Low Level Functionality","title":"Low Level Functionality","text":"FFMPEG's built-in logging and warning level can be read and set with","category":"page"},{"location":"lowlevel/#VideoIO.loglevel!","page":"Low Level Functionality","title":"VideoIO.loglevel!","text":"loglevel!(loglevel::Integer)\n\nSet FFMPEG log level. Options are:\n\nVideoIO.AVUtil.AV_LOG_QUIET\nVideoIO.AVUtil.AV_LOG_PANIC\nVideoIO.AVUtil.AV_LOG_FATAL\nVideoIO.AVUtil.AV_LOG_ERROR\nVideoIO.AVUtil.AV_LOG_WARNING\nVideoIO.AVUtil.AV_LOG_INFO\nVideoIO.AVUtil.AV_LOG_VERBOSE\nVideoIO.AVUtil.AV_LOG_DEBUG\nVideoIO.AVUtil.AV_LOG_TRACE\n\n\n\n\n\n","category":"function"},{"location":"lowlevel/#VideoIO.loglevel","page":"Low Level Functionality","title":"VideoIO.loglevel","text":"loglevel() -> String\n\nGet FFMPEG log level as a variable name string.\n\n\n\n\n\n","category":"function"},{"location":"lowlevel/#FFMPEG-interface","page":"Low Level Functionality","title":"FFMPEG interface","text":"","category":"section"},{"location":"lowlevel/","page":"Low Level Functionality","title":"Low Level Functionality","text":"Each ffmpeg library has its own VideoIO subpackage:","category":"page"},{"location":"lowlevel/","page":"Low Level Functionality","title":"Low Level Functionality","text":"libavcodec    -> AVCodecs\nlibavdevice   -> AVDevice\nlibavfilter   -> AVFilters\nlibavformat   -> AVFormat\nlibavutil     -> AVUtil\nlibswscale    -> SWScale","category":"page"},{"location":"lowlevel/","page":"Low Level Functionality","title":"Low Level Functionality","text":"The following three files are related to ffmpeg, but currently not exposed:","category":"page"},{"location":"lowlevel/","page":"Low Level Functionality","title":"Low Level Functionality","text":"libswresample -> SWResample\nlibpostproc   -> PostProc   (not wrapped)","category":"page"},{"location":"lowlevel/","page":"Low Level Functionality","title":"Low Level Functionality","text":"After importing VideoIO, you can import and use any of the subpackages directly","category":"page"},{"location":"lowlevel/","page":"Low Level Functionality","title":"Low Level Functionality","text":"import VideoIO\nimport SWResample  # SWResample functions are now available","category":"page"},{"location":"lowlevel/","page":"Low Level Functionality","title":"Low Level Functionality","text":"Note that much of the functionality of these subpackages is not enabled by default, to avoid long compilation times as they load.  To control what is loaded, each library version has a file which imports that's modules files.  For example, ffmpeg's libswscale-v2 files are loaded by VideoIO_PKG_DIR/src/ffmpeg/SWScale/v2/LIBSWSCALE.jl.","category":"page"},{"location":"lowlevel/","page":"Low Level Functionality","title":"Low Level Functionality","text":"Check these files to enable any needed functionality that isn't already enabled. Note that you'll probably need to do this for each version of the package for ffmpeg, and that the interfaces do change some from version to version.","category":"page"},{"location":"lowlevel/","page":"Low Level Functionality","title":"Low Level Functionality","text":"Note that, in general, the low-level functions are not very fun to use, so it is good to focus initially on enabling a nice, higher-level function for these interfaces.","category":"page"},{"location":"#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"This library provides methods for reading and writing video files.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Functionality is based on a dedicated build of ffmpeg, provided via JuliaPackaging/Yggdrasil","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Explore the source at github.com/JuliaIO/VideoIO.jl","category":"page"},{"location":"#Platform-Notes:","page":"Introduction","title":"Platform Notes:","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"ARM: For truly lossless reading & writing, there is a known issue on ARM that results in small precision differences when reading/writing some video files. As such, tests for frame comparison are currently skipped on ARM. Issues/PRs welcome for helping to get this fixed.","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The package can be installed with the Julia package manager. From the Julia REPL, type ] to enter the Pkg REPL mode and run:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"pkg> add VideoIO","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Or, equivalently, via the Pkg API:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> import Pkg; Pkg.add(\"VideoIO\")","category":"page"},{"location":"reading/#Video-Reading","page":"Reading Videos","title":"Video Reading","text":"","category":"section"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"Note: Reading of audio streams is not yet implemented","category":"page"},{"location":"reading/#Reading-Video-Files","page":"Reading Videos","title":"Reading Video Files","text":"","category":"section"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"VideoIO contains a simple high-level interface which allows reading of video frames from a supported video file (or from a camera device, shown later).","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"The simplest form will load the entire video into memory as a vector of image arrays.","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"using VideoIO\nVideoIO.load(\"video.mp4\")","category":"page"},{"location":"reading/#VideoIO.load","page":"Reading Videos","title":"VideoIO.load","text":"load(filename::String, args...; kwargs...)\n\nLoad video file filename into memory as vector of image arrays, setting args and kwargs on the openvideo process.\n\n\n\n\n\n","category":"function"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"Frames can be read sequentially until the end of the file:","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"using VideoIO\n\n# Construct a AVInput object to access the video and audio streams in a video container\n# io = VideoIO.open(video_file)\nio = VideoIO.testvideo(\"annie_oakley\") # for testing purposes\n\n# Access the video stream in an AVInput, and return a VideoReader object:\nf = VideoIO.openvideo(io) # you can also use a file name, instead of a AVInput\n\nimg = read(f)\n\nwhile !eof(f)\n    read!(f, img)\n    # Do something with frames\nend\nclose(f)","category":"page"},{"location":"reading/#VideoIO.openvideo","page":"Reading Videos","title":"VideoIO.openvideo","text":"openvideo(file[, video_stream = 1]; <keyword arguments>) -> reader\nopenvideo(f, ...)\n\nOpen file and create an object to read and decode video stream number video_stream. file can either be a AVInput created by VideoIO.open, the name of a file as an AbstractString, or instead an IO object. However, support for IO objects is incomplete, and does not currently work with common video containers such as *.mp4 files.\n\nFrames can be read from the reader with read or read!, or alternatively by using the iterator interface provided for reader. To close the reader, simply use close. Seeking within the reader can be accomplished using seek, seekstart. Frames can be skipped with skipframe, or skipframes. The current time in the video stream can be accessed with gettime. Details about the frame dimension can be found with out_frame_size. The total number of frames can be found with counttotalframes.\n\nIf called with a single argument function as the first argument, the reader will be passed to the function, and will be closed once the call returns whether or not an error occurred.\n\nThe decoder options and conversion to Julia arrays is controlled by the keyword arguments listed below.\n\nKeyword arguments\n\ntranscode::Bool = true: Determines whether decoded frames are transferred into a Julia matrix with easily interpretable element type, or instead returned as raw byte buffers.\ntarget_format::Union{Nothing, Cint} = nothing: Determines the target pixel format that decoded frames will be transformed into before being transferred to an output array. This can either by a VideoIO.AV_PIX_FMT_* value corresponding to a FFmpeg AVPixelFormat, and must then also be a format supported by the VideoIO, or instead nothing, in which case the format will be automatically chosen by FFmpeg. This list of currently supported pixel formats, and the matrix element type that each pixel format corresponds with, are elements of VideoIO.VIO_PIX_FMT_DEF_ELTYPE_LU.\npix_fmt_loss_flags = 0: Loss flags to control how transfer pixel format is chosen. Only valid if target_format = nothing. Flags must correspond to FFmpeg loss flags.\ntarget_colorspace_details = nothing: Information about the color space of output Julia arrays. If nothing, then this will correspond to a best-effort interpretation of Colors.jl for the corresponding element type. To override these defaults, create a VideoIO.VioColorspaceDetails object using the appropriate AVCOL_ definitions from FFmpeg, or use VideoIO.VioColorspaceDetails() to use the FFmpeg defaults. To avoid rescaling limited color range data (mpeg) to full color range output (jpeg), then set this to VideoIO.VioColorspaceDetails() to avoid additional scaling by sws_scale.\nallow_vio_gray_transform = true: Instead of using sws_scale for gray data, use a more accurate color space transformation implemented in VideoIO if allow_vio_gray_gransform = true. Otherwise, use sws_scale.\nswscale_options::OptionsT = (;): A Namedtuple, or Dict{Symbol, Any} of options for the swscale object used to perform color space scaling. Options must correspond with options for FFmpeg's scaler filter.\nsws_color_options::OptionsT = (;): Additional keyword arguments passed to sws_setColorspaceDetails.\nthread_count::Union{Nothing, Int} = Sys.CPU_THREADS: The number of threads the codec is allowed to use or nothing for default codec behavior. Defaults to Sys.CPU_THREADS.\n\n\n\n\n\n","category":"function"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"Alternatively, you can open the video stream in a file directly with VideoIO.openvideo(filename), without making an intermediate AVInput object, if you only need the video.","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"VideoIO also provides an iterator interface for VideoReader, which behaves like other mutable iterators in Julia (e.g. Channels). If iteration is stopped early, for example with a break statement, then it can be resumed in the same spot by iterating on the same VideoReader object. Consequently, if you have already iterated over all the frames of a VideoReader object, then it will be empty for further iteration unless its position in the video is changed with seek.","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"using VideoIO\n\nf = VideoIO.openvideo(\"video.mp4\")\nfor img in f\n    # Do something with img\nend\n# Alternatively use collect(f) to get all of the frames\n\n# Further iteration will show that f is now empty\n@assert isempty(f)\n\nclose(f)","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"Seeking through the video can be achieved via seek(f, seconds::Float64) and seekstart(f) to return to the start.","category":"page"},{"location":"reading/#Base.seek","page":"Reading Videos","title":"Base.seek","text":"seek(reader::VideoReader, seconds)\n\nSeeks into the parent AVInput using this video stream's index. See [seek] for AVInput.\n\n\n\n\n\nseek(avin::AVInput, seconds::AbstractFloat, video_stream::Integer=1)\n\nSeek through the container format avin so that the next frame returned by the stream indicated by video_stream will have a timestamp greater than or equal to seconds.\n\n\n\n\n\n","category":"function"},{"location":"reading/#Base.seekstart","page":"Reading Videos","title":"Base.seekstart","text":"seekstart(reader::VideoReader)\n\nSeek to time zero of the parent AVInput using reader's stream index. See seekstart for AVInput objects.\n\n\n\n\n\nseekstart(avin::AVInput{T}, video_stream_index=1) where T <: AbstractString\n\nSeek to time zero of AVInput object.\n\n\n\n\n\n","category":"function"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"Frames can be skipped without reading frame content via skipframe(f) and skipframes(f, n)","category":"page"},{"location":"reading/#VideoIO.skipframe","page":"Reading Videos","title":"VideoIO.skipframe","text":"skipframe(s::VideoReader; throwEOF=true)\n\nSkip the next frame. If End of File is reached, EOFError thrown if throwEOF=true. Otherwise returns true if EOF reached, false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"reading/#VideoIO.skipframes","page":"Reading Videos","title":"VideoIO.skipframes","text":"skipframes(s::VideoReader, n::Int; throwEOF=true) -> n\n\nSkip the next n frames. If End of File is reached and throwEOF=true, a EOFError will be thrown. Returns the number of frames that were skipped.\n\n\n\n\n\n","category":"function"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"Total available frame count is available via counttotalframes(f)","category":"page"},{"location":"reading/#VideoIO.counttotalframes","page":"Reading Videos","title":"VideoIO.counttotalframes","text":"counttotalframes(reader) -> n::Int\n\nCount the total number of frames in the video by seeking to start, skipping through each frame, and seeking back to the start.\n\nFor a faster alternative that relies on video container metadata, try get_number_frames.\n\n\n\n\n\n","category":"function"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"The video framerate can be read via framerate(f)","category":"page"},{"location":"reading/#VideoIO.framerate","page":"Reading Videos","title":"VideoIO.framerate","text":"framerate(f::VideoReader)\n\nRead the framerate of a VideoReader object.\n\n\n\n\n\n","category":"function"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"!!! note H264 videos encoded with crf>0 have been observed to have 4-fewer frames available for reading.","category":"page"},{"location":"reading/#Changing-the-target-pixel-format-for-reading","page":"Reading Videos","title":"Changing the target pixel format for reading","text":"","category":"section"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"It can be helpful to be explicit in which pixel format you wish to read frames as. Here a grayscale video is read and parsed into a Vector(Array{UInt8}}","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"f = VideoIO.openvideo(filename, target_format=VideoIO.AV_PIX_FMT_GRAY8)\n\nwhile !eof(f)\n    img = reinterpret(UInt8, read(f))\nend\nclose(f)","category":"page"},{"location":"reading/#Reading-Camera-Output","page":"Reading Videos","title":"Reading Camera Output","text":"","category":"section"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"Frames can be read iteratively","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"using VideoIO\ncam = VideoIO.opencamera()\nfps = VideoIO.framerate(cam)\nfor i in 1:100\n    img = read(cam)\n    sleep(1/fps)\nend","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"To change settings such as the frame rate or resolution of the captured frames, set the appropriate value in the options positional argument.","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"julia> opts = VideoIO.DEFAULT_CAMERA_OPTIONS\nVideoIO.AVDict with 2 entries:\n  \"framerate\"    => \"30\"\n  \"pixel_format\" => \"uyvy422\"\n\njulia> opts[\"framerate\"] = \"24\"\n\"24\"\n\njulia> opts[\"video_size\"] = \"640x480\"\n\"640x480\"\n\njulia> opencamera(VideoIO.DEFAULT_CAMERA_DEVICE[], VideoIO.DEFAULT_CAMERA_FORMAT[], opts)\nVideoReader(...)","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"Or more simply, change the default. For example:","category":"page"},{"location":"reading/","page":"Reading Videos","title":"Reading Videos","text":"julia> VideoIO.DEFAULT_CAMERA_OPTIONS[\"video_size\"] = \"640x480\"\n\njulia> VideoIO.DEFAULT_CAMERA_OPTIONS[\"framerate\"] = 30\n\njulia> julia> opencamera()\nVideoReader(...)","category":"page"},{"location":"reading/#Video-Properties-and-Metadata","page":"Reading Videos","title":"Video Properties & Metadata","text":"","category":"section"},{"location":"reading/#VideoIO.get_start_time","page":"Reading Videos","title":"VideoIO.get_start_time","text":"get_start_time(file::String) -> DateTime\n\nReturn the starting date & time of the video file. Note that if the starting date & time are missing, this function will return the Unix epoch (00:00 1st January 1970).\n\n\n\n\n\n","category":"function"},{"location":"reading/#VideoIO.get_time_duration","page":"Reading Videos","title":"VideoIO.get_time_duration","text":"get_time_duration(file::String) -> (DateTime, Microsecond)\n\nReturn the starting date & time as well as the duration of the video file. Note that if the starting date & time are missing, this function will return the Unix epoch (00:00 1st January 1970).\n\n\n\n\n\n","category":"function"},{"location":"reading/#VideoIO.get_duration","page":"Reading Videos","title":"VideoIO.get_duration","text":"get_duration(file::String) -> Float64\n\nReturn the duration of the video file in seconds (float).\n\n\n\n\n\n","category":"function"},{"location":"reading/#VideoIO.get_number_frames","page":"Reading Videos","title":"VideoIO.get_number_frames","text":"get_number_frames(file [, streamno])\n\nQuery the the container file for the number of frames in video stream streamno if applicable, instead returning nothing if the container does not report the number of frames. Will not decode the video to count the number of frames in a video.\n\n\n\n\n\n","category":"function"},{"location":"writing/#Writing-Videos","page":"Writing Videos","title":"Writing Videos","text":"","category":"section"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"Note: Writing of audio streams is not yet implemented","category":"page"},{"location":"writing/#Single-step-Encoding","page":"Writing Videos","title":"Single-step Encoding","text":"","category":"section"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"Videos can be encoded directly from image stack using VideoIO.save(filename::String, imgstack::Array) where imgstack is an array of image arrays with identical type and size.","category":"page"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"The entire image stack can be encoded in a single step:","category":"page"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"import VideoIO\nencoder_options = (crf=23, preset=\"medium\")\nVideoIO.save(\"video.mp4\", imgstack, framerate=30, encoder_options=encoder_options)","category":"page"},{"location":"writing/#VideoIO.save","page":"Writing Videos","title":"VideoIO.save","text":"save(filename::String, imgstack; ...)\n\nCreate a video container filename and encode the set of frames imgstack into it. imgstack must be an iterable of matrices and each frame must have the same dimensions and element type.\n\nEncoding options, restrictions on frame size and element type, and other details are described in open_video_out. All keyword arguments are passed to open_video_out.\n\nSee also: open_video_out, write, close_video_out!\n\n\n\n\n\n","category":"function"},{"location":"writing/#Iterative-Encoding","page":"Writing Videos","title":"Iterative Encoding","text":"","category":"section"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"Alternatively, videos can be encoded iteratively within custom loops.","category":"page"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"using VideoIO\nframestack = map(x->rand(UInt8, 100, 100), 1:100) #vector of 2D arrays\n\nencoder_options = (crf=23, preset=\"medium\")\nframerate=24\nopen_video_out(\"video.mp4\", framestack[1], framerate=framerate, encoder_options=encoder_options) do writer\n    for frame in framestack\n        write(writer, frame)\n    end\nend","category":"page"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"An example saving a series of png files as a video:","category":"page"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"using VideoIO, ProgressMeter, FileIO\n\ndir = \"\" #path to directory holding images\nimgnames = filter(x->occursin(\".png\",x), readdir(dir)) # Populate list of all .pngs\nintstrings =  map(x->split(x,\".\")[1], imgnames) # Extract index from filenames\np = sortperm(parse.(Int, intstrings)) #sort files numerically\nimgnames = imgnames[p]\n\nencoder_options = (crf=23, preset=\"medium\")\n\nfirstimg = load(joinpath(dir, imgnames[1]))\nopen_video_out(\"video.mp4\", firstimg, framerate=24, encoder_options=encoder_options) do writer\n    @showprogress \"Encoding video frames..\" for i in eachindex(imgnames)\n        img = load(joinpath(dir, imgnames[i]))\n        write(writer, img)\n    end\nend","category":"page"},{"location":"writing/#VideoIO.open_video_out","page":"Writing Videos","title":"VideoIO.open_video_out","text":"open_video_out(filename, ::Type{T}, sz::NTuple{2, Integer};\n               <keyword arguments>) -> writer\nopen_video_out(filename, first_img::Matrix; ...)\nopen_video_out(f, ...; ...)\n\nOpen file filename and prepare to encode a video stream into it, returning object writer that can be used to encode frames. The size and element type of the video can either be specified by passing the first frame of the movie first_img, which will not be encoded, or instead the element type T and 2-tuple size sz. If the size is explicitly specified, the first element will be the height, and the second width, unless keyword argument scanline_major = true, in which case the order is reversed. Both height and width must be even. The element type T must be one of the supported element types, which is any key of VideoIO.VIO_DEF_ELTYPE_PIX_FMT_LU, or instead the Normed or Unsigned type for a corresponding Gray element type. The container type will be inferred from filename.\n\nFrames are encoded with write, which must use frames with the same size, element type, and obey the same value of scanline_major. The video must be closed once all frames are encoded with close_video_out!.\n\nIf called with a function as the first argument, f, then the function will be called with the writer object writer as its only argument. This writer object will be closed once the call is complete, regardless of whether or not an error occurred.\n\nKeyword arguments\n\ncodec_name::Union{AbstractString, Nothing} = nothing: Name of the codec to use. Must be a name accepted by FFmpeg, and compatible with the chosen container type, or nothing, in which case the codec will be automatically selected by FFmpeg based on the container.\nframerate::Real = 24: Framerate of the resulting video.\nscanline_major::Bool = false: If false, then Julia arrays are assumed to have frame height in the first dimension, and frame width on the second. If true, then pixels that adjacent to eachother in the same scanline (i.e. horizontal line of the video) are assumed to be adjacent to eachother in memory. scanline_major = true videos must be StridedArrays with unit stride in the first dimension. For normal arrays, this corresponds to a matrix where frame width is in the first dimension, and frame height is in the second.\ncontainer_options::OptionsT = (;): A NamedTuple or Dict{Symbol, Any} of options for the container. Must correspond to option names and values accepted by FFmpeg.\ncontainer_private_options::OptionsT = (;): A NamedTuple or Dict{Symbol, Any} of private options for the container. Must correspond to private options names and values accepted by FFmpeg for the chosen container type.\nencoder_options::OptionsT = (;): A NamedTuple or Dict{Symbol, Any} of options for the encoder context. Must correspond to option names and values accepted by FFmpeg.\nencoder_private_options::OptionsT = (;): A NamedTuple or Dict{Symbol, Any} of private options for the encoder context. Must correspond to private option names and values accepted by FFmpeg for the chosen codec specified by codec_name.\nswscale_options::OptionsT = (;): A Namedtuple, or Dict{Symbol, Any} of options for the swscale object used to perform color space scaling. Options must correspond with options for FFmpeg's scaler filter.\ntarget_pix_fmt::Union{Nothing, Cint} = nothing: The pixel format that will be used to input data into the encoder. This can either by a VideoIO.AV_PIX_FMT_* value corresponding to a FFmpeg AVPixelFormat, and must then be a format supported by the encoder, or instead nothing, in which case it will be chosen automatically by FFmpeg.\npix_fmt_loss_flags = 0: Loss flags to control how encoding pixel format is chosen. Only valid if target_pix_fmt = nothing. Flags must correspond to FFmpeg loss flags.\ninput_colorspace_details = nothing: Information about the color space of input Julia arrays. If nothing, then this will correspond to a best-effort interpretation of Colors.jl for the corresponding element type. To override these defaults, create a VideoIO.VioColorspaceDetails object using the appropriate AVCOL_ definitions from FFmpeg, or use VideoIO.VioColorspaceDetails() to use the FFmpeg defaults. If data in the input Julia arrays is already in the mpeg color range, then set this to VideoIO.VioColorspaceDetails() to avoid additional scaling by sws_scale.\nallow_vio_gray_transform = true: Instead of using sws_scale for gray data, use a more accurate color space transformation implemented in VideoIO if allow_vio_gray_transform = true. Otherwise, use sws_scale.\nsws_color_options::OptionsT = (;): Additional keyword arguments passed to sws_setColorspaceDetails.\nthread_count::Union{Nothing, Int} = nothing: The number of threads the codec is allowed to use, or nothing for default codec behavior. Defaults to nothing.\n\nSee also: write, close_video_out!\n\n\n\n\n\n","category":"function"},{"location":"writing/#Base.write-Tuple{VideoIO.VideoWriter, Any, Int64}","page":"Writing Videos","title":"Base.write","text":"write(writer::VideoWriter, img)\nwrite(writer::VideoWriter, img, index)\n\nPrepare frame img for encoding, encode it, mux it, and either cache it or write it to the file described by writer. img must be the same size and element type as the size and element type that was used to create writer. If index is provided, it must start at zero and increment monotonically.\n\n\n\n\n\n","category":"method"},{"location":"writing/#VideoIO.close_video_out!","page":"Writing Videos","title":"VideoIO.close_video_out!","text":"close_video_out!(writer::VideoWriter)\n\nWrite all frames cached in writer to the video container that it describes, and then close the file. Once all frames in a video have been added to writer, then it must be closed with this function to flush any cached frames to the file, and then finally close the file and release resources associated with writer.\n\n\n\n\n\n","category":"function"},{"location":"writing/#Supported-Colortypes","page":"Writing Videos","title":"Supported Colortypes","text":"","category":"section"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"Encoding of the following image element color types currently supported:","category":"page"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"UInt8\nGray{N0f8}\nRGB{N0f8}","category":"page"},{"location":"writing/#Encoder-Options","page":"Writing Videos","title":"Encoder Options","text":"","category":"section"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"The encoder_options keyword argument allows control over FFmpeg encoding options. Optional fields can be found here.","category":"page"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"More details about options specific to h264 can be found here.","category":"page"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"Some example values for the encoder_options keyword argument are:","category":"page"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"Goal encoder_options value\nPerceptual compression, h264 default. Best for most cases (crf=23, preset=\"medium\")\nLossless compression. Fastest, largest file size (crf=0, preset=\"ultrafast\")\nLossless compression. Slowest, smallest file size (crf=0, preset=\"veryslow\")\nDirect control of bitrate and frequency of intra frames (every 10) (bit_rate = 400000, gop_size = 10, max_b_frames = 1)","category":"page"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"If a hyphenated parameter is needed, it can be added using var\"param-name\" = value.","category":"page"},{"location":"writing/#Lossless-Encoding","page":"Writing Videos","title":"Lossless Encoding","text":"","category":"section"},{"location":"writing/#Lossless-RGB","page":"Writing Videos","title":"Lossless RGB","text":"","category":"section"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"If lossless encoding of RGB{N0f8} is required, true lossless requires passing codec_name = \"libx264rgb\" to the function to avoid the lossy RGB->YUV420 conversion, as well as adding crf=0 in encoder_options.","category":"page"},{"location":"writing/#Lossless-Grayscale","page":"Writing Videos","title":"Lossless Grayscale","text":"","category":"section"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"If lossless encoding of Gray{N0f8} or UInt8 is required, crf=0 should be set, as well as color_range=2 to ensure full 8-bit pixel color representation. i.e. (color_range=2, crf=0, preset=\"medium\")","category":"page"},{"location":"writing/#Encoding-Performance","page":"Writing Videos","title":"Encoding Performance","text":"","category":"section"},{"location":"writing/","page":"Writing Videos","title":"Writing Videos","text":"See util/lossless_video_encoding_testing.jl for testing of losslessness, speed, and compression as a function of h264 encoding preset, for 3 example videos.","category":"page"}]
}
